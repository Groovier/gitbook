<!DOCTYPE html><html><head>
    <meta charset="utf-8"><meta name="keywords" content="极客时间,IT,职业教育,知识付费,二叉树,极客Live,极客搜索,互联网,前端开发,后端开发,编程语言,人工智能,区块链,技术大会,技术管理,产品,研发,测试,运维,数据库,架构,微服务,实战,技术专家,Java,iOS,Android,Linux,Go" id="metakeywords"><meta name="description" content="极客时间是一款由极客邦科技倾力打造的面向IT领域的知识服务产品,旨在帮助用户提升技术认知.板块包含专栏文章、视频课程、新闻、资讯、直播、图书、商城等。内容覆盖IT从业者的全生命周期知识技能图谱,邀请左耳朵耗子、王争、杨晓峰、winter,丁奇等顶级技术和行业专家为你讲述技术本质,解读科技动态." id="metadesc"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,viewport-fit=cover"><meta name="format-detection" content="telephone=no"><title>极客时间 | 数据分析实战45讲</title><style data-savepage-href="https://static001.geekbang.org/static/time/css/app.e30427d82748c1a9d53a048cf510f63c.css">html{color:#333;-webkit-text-size-adjust:100%;-ms-text-size-adjust:100%;text-rendering:optimizelegibility;font-family:Helvetica Neue,PingFang SC,Verdana,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif}html.borderbox *,html.borderbox :after,html.borderbox :before{box-sizing:border-box}article,aside,blockquote,body,button,code,dd,details,dl,dt,fieldset,figcaption,figure,footer,form,h1,h2,h3,h4,h5,h6,header,hr,input,legend,li,menu,nav,ol,p,pre,section,td,textarea,th,ul{margin:0;padding:0}article,aside,details,figcaption,figure,footer,header,menu,nav,section{display:block}audio,canvas,video{display:inline-block}body,button,input,select,textarea{font:300 1em/1.8 PingFang SC,Lantinghei SC,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,Helvetica,sans-serif}button::-moz-focus-inner,input::-moz-focus-inner{padding:0;border:0}table{border-collapse:collapse;border-spacing:0}fieldset,img{border:0}blockquote{position:relative;color:#999;font-weight:400;border-left:1px solid #1abc9c;padding-left:1em;margin:1em 3em 1em 2em}@media only screen and (max-width:640px){blockquote{margin:1em 0}}abbr,acronym{border-bottom:1px dotted;font-variant:normal}abbr{cursor:help}del{text-decoration:line-through}address,caption,cite,code,dfn,em,th,var{font-style:normal;font-weight:400}ol,ul{list-style:none}caption,th{text-align:left}q:after,q:before{content:""}sub,sup{font-size:75%;line-height:0;position:relative}:root sub,:root sup{vertical-align:baseline}sup{top:-.5em}sub{bottom:-.25em}a{color:#1abc9c}a:hover{text-decoration:underline}.typo a{border-bottom:1px solid #1abc9c}.typo a:hover{border-bottom-color:#555;color:#555}.typo a:hover,a,ins{text-decoration:none}.typo-u,u{text-decoration:underline}mark{background:#fffdd1;border-bottom:1px solid #ffedce;padding:2px;margin:0 5px}code,pre,pre tt{font-family:Courier,Courier New,monospace}pre{background:hsla(0,0%,97%,.7);border:1px solid #ddd;padding:1em 1.5em;display:block;-webkit-overflow-scrolling:touch}hr{border:none;border-bottom:1px solid #cfcfcf;margin-bottom:.8em;height:10px}.typo-small,figcaption,small{font-size:.9em;color:#888}b,strong{font-weight:700;color:#000}[draggable]{cursor:move}.clearfix:after,.clearfix:before{content:"";display:table}.clearfix:after{clear:both}.clearfix{zoom:1}.textwrap,.textwrap td,.textwrap th{word-wrap:break-word;word-break:break-all}.textwrap-table{table-layout:fixed}.serif{font-family:Palatino,Optima,Georgia,serif}.typo-dl,.typo-form,.typo-hr,.typo-ol,.typo-p,.typo-pre,.typo-table,.typo-ul,.typo dl,.typo form,.typo hr,.typo ol,.typo p,.typo pre,.typo table,.typo ul,blockquote{margin-bottom:1rem}h1,h2,h3,h4,h5,h6{font-family:PingFang SC,Helvetica Neue,Verdana,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#000;line-height:1.35}.typo-h1,.typo-h2,.typo-h3,.typo-h4,.typo-h5,.typo-h6,.typo h1,.typo h2,.typo h3,.typo h4,.typo h5,.typo h6{margin-top:1.2em;margin-bottom:.6em;line-height:1.35}.typo-h1,.typo h1{font-size:2em}.typo-h2,.typo h2{font-size:1.8em}.typo-h3,.typo h3{font-size:1.6em}.typo-h4,.typo h4{font-size:1.4em}.typo-h5,.typo-h6,.typo h5,.typo h6{font-size:1.2em}.typo-ul,.typo ul{margin-left:1.3em;list-style:disc}.typo-ol,.typo ol{list-style:decimal;margin-left:1.9em}.typo-ol ol,.typo-ol ul,.typo-ul ol,.typo-ul ul,.typo li ol,.typo li ul{margin-bottom:.8em;margin-left:2em}.typo-ol ul,.typo-ul ul,.typo li ul{list-style:circle}.typo-table td,.typo-table th,.typo table caption,.typo table td,.typo table th{border:1px solid #ddd;padding:.5em 1em;color:#666}.typo-table th,.typo table th{background:#fbfbfb}.typo-table thead th,.typo table thead th{background:hsla(0,0%,95%,.7)}.typo table caption{border-bottom:none}.typo-input,.typo-textarea{-webkit-appearance:none;border-radius:0}.typo-em,.typo em,caption,legend{color:#000;font-weight:inherit}.typo-em{position:relative}.typo-em:after{position:absolute;top:.65em;left:0;width:100%;overflow:hidden;white-space:nowrap;content:"\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB"}.typo img{max-width:100%}.common-content{font-weight:400;color:#353535;line-height:1.75rem;white-space:normal;word-break:normal;font-size:1rem}.common-content img{display:block;max-width:100%;background-color:#eee}.common-content audio,.common-content video{width:100%;background-color:#eee}.common-content center,.common-content font{margin-top:1rem;display:inline-block}.common-content center{width:100%}.common-content pre{margin-top:1rem;padding-left:0;padding-right:0;position:relative;overflow:hidden}.common-content pre code{font-size:.8rem;font-family:Consolas,Liberation Mono,Menlo,monospace,Courier;display:block;width:100%;box-sizing:border-box;padding-left:1rem;padding-right:1rem;overflow-x:auto}.common-content hr{border:none;margin-top:1.5rem;margin-bottom:1.5rem;border-top:1px solid #f5f5f5;height:1px;background:none}.common-content b,.common-content h1,.common-content h2,.common-content h3,.common-content h4,.common-content h5,.common-content strong{font-weight:700}.common-content h1,.common-content h2{font-size:1.125rem;margin-bottom:.45rem}.common-content h3,.common-content h4,.common-content h5{font-size:1rem;margin-bottom:.45rem}.common-content p{font-weight:400;color:#353535;margin-top:.15rem}.common-content .orange{color:#ff5a05}.common-content .reference{font-size:1rem;color:#888}.custom-rich-content h1{margin-top:0;font-weight:400;font-size:15.25px;border-bottom:1px solid #eee;line-height:2.8}.custom-rich-content li,.custom-rich-content p{font-size:14px;color:#888;line-height:1.6}table.hljs-ln{margin-bottom:0;border-spacing:0;border-collapse:collapse}table.hljs-ln,table.hljs-ln tbody,table.hljs-ln td,table.hljs-ln tr{box-sizing:border-box}table.hljs-ln td{padding:0;border:0}table.hljs-ln td.hljs-ln-numbers{min-width:15px;color:rgba(27,31,35,.3);text-align:right;white-space:nowrap;cursor:pointer;user-select:none}table.hljs-ln td.hljs-ln-code,table.hljs-ln td.hljs-ln-numbers{font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;font-size:12px;line-height:20px;vertical-align:top}table.hljs-ln td.hljs-ln-code{position:relative;padding-right:10px;padding-left:10px;overflow:visible;color:#24292e;word-wrap:normal;white-space:pre}video::-webkit-media-controls{overflow:hidden!important}video::-webkit-media-controls-enclosure{width:calc(100% + 32px);margin-left:auto}.button-cancel{color:#888;border:1px solid #888;border-radius:3px;margin-right:12px}.button-cancel,.button-primary{-ms-flex-positive:1;flex-grow:1;height:35px;display:inline-block;font-size:15px;text-align:center;line-height:36px}.button-primary{color:#fff;background-color:#fa8919;border-radius:3px}.gkui-message-content-wrap .gkui-message-close .defaultClose:after,.gkui-message-content-wrap .gkui-message-close .defaultClose:before{transition:all .3s ease}.gkui-message-content-wrap{position:relative;text-align:center}.gkui-message-content-wrap .gkui-message-content{display:inline-block;overflow:hidden;padding:10px 16px;margin-bottom:6px;background:#fff;font-size:14px;line-height:14px;border-radius:3px;box-shadow:0 1px 6px rgba(0,0,0,.2);pointer-events:all}.gkui-message-content-wrap .gkui-message-loading-prefix{display:inline-block;margin-right:4px;transform:translateY(2px)}.gkui-message-content-wrap .gkui-message-close{display:inline-block;margin-left:4px;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.gkui-message-content-wrap .gkui-message-close .defaultClose{display:inline-block;position:relative;width:10px;height:10px}.gkui-message-content-wrap .gkui-message-close .defaultClose:after,.gkui-message-content-wrap .gkui-message-close .defaultClose:before{position:absolute;top:5px;right:0;display:block;content:"";width:12px;height:1px;background:#8a8a8a}.gkui-message-content-wrap .gkui-message-close .defaultClose:before{transform:rotate(45deg)}.gkui-message-content-wrap .gkui-message-close .defaultClose:after{transform:rotate(-45deg)}.gkui-message-content-wrap .gkui-message-close .defaultClose:hover:after,.gkui-message-content-wrap .gkui-message-close .defaultClose:hover:before{background:#333}.fade-up-enter-active,.fade-up-leave-active{transition:all .4s ease}.fade-up-enter,.fade-up-leave-to{opacity:0;transform:translateY(-50%)}.fade-up-leave-to{height:0}.gkui-message-content-wrap .gkui-message-info{border:1px solid #ddd}.gkui-message-content-wrap .gkui-message-success{border:1px solid #666;background:#666;color:#fff}.gkui-message-content-wrap .gkui-message-error{border:1px solid rgba(0,0,0,.7);background-color:rgba(0,0,0,.7);color:#fff}.iconfont{font-family:iconfont!important;font-size:16px;font-style:normal;-webkit-font-smoothing:antialiased;-webkit-text-stroke-width:.2px;-moz-osx-font-smoothing:grayscale}html{background:#fff;min-height:100%;-webkit-tap-highlight-color:rgba(0,0,0,0)}body{width:100%}body.fixed{overflow:hidden;position:fixed;width:100vw;height:100vh}i{font-style:normal}a{word-wrap:break-word;-webkit-tap-highlight-color:rgba(0,0,0,0)}a:hover{text-decoration:none}.fade-enter-active,.fade-leave-active{transition:opacity .3s}.MathJax,.MathJax_CHTML,.MathJax_MathContainer,.MathJax_MathML,.MathJax_PHTML,.MathJax_PlainSource,.MathJax_SVG{outline:0}.ios-app-switch .js-audit{display:none}.gkui--modal-block-scroll{position:absolute;overflow:hidden;width:100vw}#gkui-modal-controller{width:100%}#gkui-modal-controller,.gkui-modal-layer{position:fixed;left:0;top:0;z-index:90000}.gkui-modal-layer{right:0;bottom:0;background-color:rgba(55,55,55,.3)}.fade-enter-active,.fade-leave-active{transition:all .3s ease}.fade-enter,.fade-leave-to{opacity:0}.gkui-message-list[data-v-99cd8b4a]{position:fixed;top:0;left:0;width:100%;pointer-events:none}._2sRsF5RP_0{position:relative}._loading_wrap_{position:fixed;width:100vw;height:100vh;top:50%;left:50%;transform:translate(-50%,-50%);z-index:999}._loading_div_class_,._loading_wrap_{display:-ms-flexbox;display:flex;-ms-flex-pack:center;justify-content:center;-ms-flex-align:center;align-items:center}._loading_div_class_{word-wrap:break-word;padding:.5rem .75rem;text-align:center;z-index:9999;font-size:.6rem;max-width:60%;color:#fff;border-radius:.25rem;-ms-flex-direction:column;flex-direction:column}._loading_div_class_ .message{color:#353535;font-size:16px;line-height:3}.spinner{animation:circle-rotator 1.4s linear infinite}.spinner *{line-height:0;box-sizing:border-box}@keyframes circle-rotator{0%{transform:rotate(0deg)}to{transform:rotate(270deg)}}.path{stroke-dasharray:187;stroke-dashoffset:0;transform-origin:center;animation:circle-dash 1.4s ease-in-out infinite,circle-colors 5.6s ease-in-out infinite}@keyframes circle-colors{0%{stroke:#fa8919}to{stroke:#fa8919}}@keyframes circle-dash{0%{stroke-dashoffset:187}50%{stroke-dashoffset:46.75;transform:rotate(135deg)}to{stroke-dashoffset:187;transform:rotate(450deg)}}.confirm-box-wrapper,.confirm-box-wrapper .mask{position:absolute;top:0;left:0;right:0;bottom:0}.confirm-box-wrapper .mask{background:rgba(0,0,0,.6)}.confirm-box-wrapper .confirm-box{position:fixed;top:50%;left:50%;width:267px;background:#fff;transform:translate(-50%,-50%);border-radius:7px}.confirm-box-wrapper .confirm-box .head{margin:0 18px;font-size:18px;text-align:center;line-height:65px;border-bottom:1px solid #d9d9d9}.confirm-box-wrapper .confirm-box .body{padding:18px;padding-bottom:0;color:#353535;font-size:12.5px;max-height:150px;overflow:auto}.confirm-box-wrapper .confirm-box .foot{display:-ms-flexbox;display:flex;-ms-flex-direction:row;flex-direction:row;padding:18px}.confirm-box-wrapper .confirm-box .foot .button-cancel{border:1px solid #d9d9d9}.hljs{display:block;overflow-x:auto;padding:.5em;color:#333;background:#f8f8f8}.hljs-comment,.hljs-quote{color:#998;font-style:italic}.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#333;font-weight:700}.hljs-literal,.hljs-number,.hljs-tag .hljs-attr,.hljs-template-variable,.hljs-variable{color:teal}.hljs-doctag,.hljs-string{color:#d14}.hljs-section,.hljs-selector-id,.hljs-title{color:#900;font-weight:700}.hljs-subst{font-weight:400}.hljs-class .hljs-title,.hljs-type{color:#458;font-weight:700}.hljs-attribute,.hljs-name,.hljs-tag{color:navy;font-weight:400}.hljs-link,.hljs-regexp{color:#009926}.hljs-bullet,.hljs-symbol{color:#990073}.hljs-built_in,.hljs-builtin-name{color:#0086b3}.hljs-meta{color:#999;font-weight:700}.hljs-deletion{background:#fdd}.hljs-addition{background:#dfd}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}</style><style type="text/css">.hljs-ln{border-collapse:collapse}.hljs-ln td{padding:0}.hljs-ln-n:before{content:attr(data-line-number)}</style><style type="text/css">._3ADRghFH_0{background:#000}._21xvFvr7_0{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}._3O_7qs2p_0{opacity:0}._2q1SuvsS_0{opacity:1}._20-cXID6_0{max-width:46.25rem;min-height:100vh;margin:0 auto;background:#fff;-webkit-transition:background-color .3s ease;transition:background-color .3s ease}._20-cXID6_0 .PYIrCCrf_0{color:#888}._20-cXID6_0 ._1EUVUUrC_0,._20-cXID6_0 .PYIrCCrf_0{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;height:35px;display:inline-block;font-size:15px;text-align:center;line-height:36px}._20-cXID6_0 ._1EUVUUrC_0{color:#fff;background-color:#fa8919;font-weight:500}._20-cXID6_0 ._2QmGFWqF_0{padding-left:22px;padding-right:15px}._20-cXID6_0 ._3lTiSebX_0{color:#fa8919;font-size:15px;font-weight:600;line-height:24px;border-radius:5px;padding:12px;background-color:#f6f7fb;margin-top:20px}._20-cXID6_0 ._3lTiSebX_0 ._7OuU9_xM_0{font-size:12px}._20-cXID6_0 ._50pDbNcP_0{padding-top:22px;padding-bottom:82px}._20-cXID6_0 .vJXgmLTi_0{color:#353535;font-weight:700;line-height:30px;font-size:22px;display:-webkit-box;-webkit-line-clamp:2;-webkit-box-orient:vertical;overflow:hidden;text-overflow:ellipsis}._20-cXID6_0 ._2LbT9q3y_0{color:#888;font-size:13px;font-weight:400;margin-top:4px;margin-bottom:12px}._20-cXID6_0 ._2LbT9q3y_0 ._3FoXPaWx_0{margin-top:10px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;-webkit-box-align:center;-ms-flex-align:center;align-items:center;overflow:hidden}._20-cXID6_0 ._2LbT9q3y_0 ._3FoXPaWx_0 .YLYfWxsg_0{color:#404040;font-size:15px;font-weight:400;min-width:0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}._20-cXID6_0 ._2LbT9q3y_0 ._3FoXPaWx_0 .nJKayDbe_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-left:10px;height:23px;border-radius:23px;font-size:13px;font-weight:400;color:#fa8919;padding-left:10px;padding-right:6px;background:#fbf5ee;white-space:nowrap}._20-cXID6_0 ._2LbT9q3y_0 ._3FoXPaWx_0 .nJKayDbe_0 ._2k8p2GLU_0{margin-left:2px;font-size:12px;-webkit-transform:scale(.7);transform:scale(.7)}._20-cXID6_0 ._3Jbcj4Iu_0._3BZBHEhm_0 video-webkit-media-controls-fullscreen-button{display:none}._20-cXID6_0 ._1-ZfmNK8_0{border-radius:6px;vertical-align:top;margin-bottom:24px;width:100%}._20-cXID6_0 ._3IatBmhv_0{margin-top:0}._20-cXID6_0 ._22WJb59B_0{color:#b2b2b2;padding-bottom:20px;font-size:13px;font-weight:400}._20-cXID6_0 ._22WJb59B_0 ._3ODTLCec_0{font-size:15px}._20-cXID6_0 ._3c2GGLul_0{width:100%;margin:20px 0}._20-cXID6_0 ._3EKy7lL9_0{overflow:hidden;padding-top:10px;margin-bottom:-30px}._20-cXID6_0 ._3EKy7lL9_0 a._1EUVUUrC_0{float:right;height:20px;font-size:12px;line-height:20px;padding:4px 8px;cursor:pointer}._20-cXID6_0 ._1qhD3bdE_0{padding-top:32px;border-top:10px solid #f6f7fb;-webkit-transition:border-top .3s ease;transition:border-top .3s ease;position:relative}._20-cXID6_0 ._1qhD3bdE_0 h2{color:#404040;position:relative;z-index:1;margin-bottom:1rem;font-weight:700;font-size:19px}._20-cXID6_0 ._1qhD3bdE_0 ._2FC_cD1O_0{font-size:16px;margin-left:5px}._20-cXID6_0 ._2-nZIZjB_0{position:absolute;z-index:2;background:#fa8919;font-size:13px;color:#fff;text-align:center;height:28px;width:80px;line-height:28px;-webkit-box-shadow:4px 5px 20px 1px rgba(250,137,25,.24);box-shadow:4px 5px 20px 1px rgba(250,137,25,.24);border-radius:28px;right:22px;top:32px}._20-cXID6_0 .YGjSYR8B_0{z-index:10;cursor:pointer}._20-cXID6_0 ._2DmyW7ex_0{cursor:pointer;padding-top:24px;padding-bottom:24px;position:relative}._20-cXID6_0 ._2DmyW7ex_0:before{content:" ";height:.5px;background:#e8e8e8;position:absolute;top:0;left:0;-webkit-box-sizing:border-box;box-sizing:border-box;left:22px;right:22px}._20-cXID6_0 ._2DmyW7ex_0 ._1M5b-cvc_0{height:38px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center}._20-cXID6_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3l55W_ak_0{-webkit-box-flex:0;-ms-flex:0 0 62px;flex:0 0 62px;text-align:center;color:#888;font-size:14px;border-radius:10px;height:22px;line-height:22px;background:#f6f7fb;font-weight:400}._20-cXID6_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3Ov-zF0e_0{margin-left:10px;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;color:#888;font-size:15px;height:22px;line-height:22px;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;font-weight:400}.ZphmEful_0{height:60px;background:transparent}._2zq_fmRg_0{font-size:15px;color:#888;line-height:24px;border-left:3px solid #e8e8e8;padding-left:15px}._3uTMOfKI_0,._24nFYvU9_0{-webkit-transition:all .3s ease;transition:all .3s ease}._3WwMT2EY_0 ._1uEolA82_0,._9b3gTd1B_0 ._2NnvkXgw_0{-webkit-transform:translateX(-508px);transform:translateX(-508px)}._3WwMT2EY_0 ._2NnvkXgw_0,._9b3gTd1B_0 ._1uEolA82_0{-webkit-transform:translateX(508px);transform:translateX(508px)}._3BZBHEhm_0 ._2LbT9q3y_0{font-weight:700}._3BZBHEhm_0 ._2DmyW7ex_0:before{height:1px}@media only screen and (max-width:769px){._15u7cU5H_0{display:none!important}}@media only screen and (min-width:740px){._3ADRghFH_0{background:#fff}}.g78dTtKm_0{background:#f6f0e0}.g78dTtKm_0 ._1qhD3bdE_0{border-top:10px solid #efe6cf}.g78dTtKm_0 ._2DmyW7ex_0:before{background:#e5d8b5}.g78dTtKm_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3l55W_ak_0{background:#efe6cf}.g78dTtKm_0 ._3lTiSebX_0{background-color:#efe6cf}._3uMzBYfb_0{background:#353535}._3uMzBYfb_0 ._2LbT9q3y_0,._3uMzBYfb_0 .vJXgmLTi_0{color:silver}._3uMzBYfb_0 ._1qhD3bdE_0{border-top:10px solid #3e3e3e}._3uMzBYfb_0 ._2DmyW7ex_0:before{background:#4c4c4c}._3uMzBYfb_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3l55W_ak_0{background:#3e3e3e;color:silver}._3uMzBYfb_0 ._1qhD3bdE_0 h2,._3uMzBYfb_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3Ov-zF0e_0{color:silver}._3uMzBYfb_0 ._3lTiSebX_0{background-color:#3e3e3e}._25ls2Q2l_0{margin-bottom:24px}._4ikL8tnR_0{padding-top:40px!important}.gpDqvVI7_0{position:fixed;top:0;bottom:0;width:100%;z-index:-1}</style><style type="text/css">._352wsGxH_0{height:63px}.Wz6esVdU_0{width:100%;height:63px;background:#fff;position:fixed;top:0;left:0;z-index:20;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 13px;-webkit-box-shadow:0 2px 3px 0 hsla(0,0%,89%,.38);box-shadow:0 2px 3px 0 hsla(0,0%,89%,.38)}.{height:40px;width:110px;background-size:110px;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;cursor:pointer}._1k9ecCKw_0{width:30px;height:30px;padding-top:4px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:start;-ms-flex-pack:start;justify-content:start;font-size:14px;color:#444;margin-left:10px;cursor:pointer}._1U_jCCZU_0{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}._3oCJiu8W_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:0 13px;background:#fbf5ee;border-radius:15px;height:30px}._7Xrmrbox_0,.gBs4U5qC_0,.JjI7sqpW_0{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;color:#fa8919;font-size:13px;font-weight:500;cursor:pointer}.JjI7sqpW_0{font-size:14px}._3lsV2-l9_0{height:13px;width:1px;background:#fa8919;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;margin-left:10px;margin-right:10px}._1UaW_Eq1_0{position:fixed;top:0;bottom:0;left:0;right:0;z-index:21;background:#fff;-webkit-transform:translateY(-20px);transform:translateY(-20px);opacity:0;visibility:hidden;-webkit-transition:all .3s ease;transition:all .3s ease}._1UaW_Eq1_0._2mIjHHvm_0{-webkit-transform:translateY(0);transform:translateY(0);opacity:1;visibility:visible}._1qHJ5OLn_0{height:63px;-ms-flex-align:center;padding-left:15px;padding-right:15px;-webkit-box-shadow:0 2px 3px 0 hsla(0,0%,89%,.38);box-shadow:0 2px 3px 0 hsla(0,0%,89%,.38)}._1qHJ5OLn_0,._2FYmyQEJ_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;align-items:center}._2FYmyQEJ_0{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;height:35px;-ms-flex-align:center;border-radius:20px;padding-left:20px;padding-right:20px}._1CLulytQ_0{font-size:14px;color:#b2b2b2}._1reF0JJk_0{height:20px;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;margin-left:10px}._1reF0JJk_0 input{background:transparent;border:0;color:#353535;height:20px;line-height:20px;font-size:14px;width:100%;vertical-align:top;outline:none}._33xQ4nNG_0{font-size:16px;font-weight:400;color:#b2b2b2;height:30px;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;margin-left:20px}._1y_WRr3L_0{font-size:18px}._1y_WRr3L_0 ._2HnUZhdg_0{color:#888;font-weight:400;padding-left:28px;height:63px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-bottom:1px solid #eee}._1y_WRr3L_0 ._2HnUZhdg_0._1r7t-t9P_0{color:#fa8919}._3IeMxVb7_0{position:absolute;bottom:40px;left:0;width:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-ms-flex-pack:distribute;justify-content:space-around}._3IeMxVb7_0 ._2HnUZhdg_0{position:relative;padding-top:46px;color:#888}._3IeMxVb7_0 ._339_Pvt6_0{position:absolute;color:#c3c3c3;height:46px;width:100%;display:-webkit-box;display:-ms-flexbox;display:flex;font-size:36px;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;top:0;left:0}</style><style type="text/css">._2SACi4xg_0{line-height:0}._2SACi4xg_0 img{vertical-align:top;margin-left:20px;opacity:.5}</style><style type="text/css">._1Bg5E78Y_0{width:100%;height:60px;background:#fff;-webkit-transition:background-color .3s ease;transition:background-color .3s ease;-webkit-box-sizing:border-box;box-sizing:border-box;padding-left:18px;padding-right:12px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;border-radius:6px 30px 30px 6px;-webkit-box-shadow:0 3px 25px 4px rgba(140,163,191,.14);box-shadow:0 3px 25px 4px rgba(140,163,191,.14)}._1Bg5E78Y_0 ._2Ha38TVL_0{border-radius:50%;width:40px;height:40px;-webkit-box-shadow:0 1px 3px 2px rgba(0,0,0,.1);box-shadow:0 1px 3px 2px rgba(0,0,0,.1);position:relative}._1Bg5E78Y_0 ._1iA2uC1V_0{background-repeat:no-repeat;background-position:0 0;background-size:300px;background-color:#fff;border-radius:50%;width:40px;height:40px;position:absolute;top:0;left:0}._1Bg5E78Y_0 ._1WF5YSBJ_0{background:rgba(0,0,0,.15)}._1Bg5E78Y_0 ._2Kms_g0F_0{width:40px;height:40px;line-height:40px;text-align:center;border-radius:50%;z-index:2;position:relative}._1Bg5E78Y_0 .MH1rcCm7_0 ._2Kms_g0F_0{color:#fff;margin-left:2px}._1Bg5E78Y_0 ._1KuRDTHn_0 ._2Kms_g0F_0{color:#fff}._1Bg5E78Y_0 .MH1rcCm7_0 ._1iA2uC1V_0{-webkit-animation:HvzpPu2i_0 4s linear infinite;animation:HvzpPu2i_0 4s linear infinite;-webkit-animation-play-state:paused;animation-play-state:paused}._1Bg5E78Y_0 ._1KuRDTHn_0 ._1iA2uC1V_0{-webkit-animation:HvzpPu2i_0 4s linear infinite;animation:HvzpPu2i_0 4s linear infinite;-webkit-animation-play-state:running;animation-play-state:running}._1Bg5E78Y_0 ._1qj_iPD7_0{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;overflow:hidden;margin-right:10px}._1Bg5E78Y_0 ._1qj_iPD7_0 h3{color:#404040;font-size:15.25px;margin:0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}._1Bg5E78Y_0 ._1qj_iPD7_0 p{margin:0;margin-top:.125rem;font-size:12px;font-weight:500;line-height:1rem;color:#999}._1Bg5E78Y_0 ._3PhVtlEa_0{width:20px;height:20px;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;position:relative;color:#999;font-size:18px;line-height:20px;text-align:center;margin-right:20px}._1Bg5E78Y_0 ._1l6e3976_0{width:10px;height:10px;line-height:10px;text-align:center;position:absolute;bottom:-3px;right:-5px;color:#6c0;background:#fff;font-size:10px;-webkit-transition:background-color .2s ease;transition:background-color .2s ease}._1W0qSnju_0{-webkit-box-shadow:0 3px 25px 4px hsla(42,28%,65%,.14);box-shadow:0 3px 25px 4px hsla(42,28%,65%,.14)}._1W0qSnju_0,._1W0qSnju_0 ._1l6e3976_0{background:#f6f0e0}._1W0qSnju_0 ._2Ha38TVL_0{-webkit-box-shadow:0 1px 2px 2px hsla(42,28%,65%,.14);box-shadow:0 1px 2px 2px hsla(42,28%,65%,.14)}._2SRR-E_O_0{background:#4d4d4d;-webkit-box-shadow:none;box-shadow:none}._2SRR-E_O_0 ._3PhVtlEa_0{color:#fff}._2SRR-E_O_0 ._1l6e3976_0{background:#4d4d4d}._2SRR-E_O_0 ._1qj_iPD7_0 h3,._2SRR-E_O_0 ._1qj_iPD7_0 p{color:silver}._2vBNygJQ_0 ._1qj_iPD7_0 p{font-weight:700}@-webkit-keyframes HvzpPu2i_0{to{-webkit-transform:rotate(1turn);transform:rotate(1turn)}}@keyframes HvzpPu2i_0{to{-webkit-transform:rotate(1turn);transform:rotate(1turn)}}</style><style type="text/css">._29HP61GA_0{font-weight:400;color:#353535;line-height:1.76;white-space:normal;word-break:normal;font-size:17px;-webkit-transition:background-color .3s ease;transition:background-color .3s ease}._29HP61GA_0 .MathJax_Display{overflow:auto}._29HP61GA_0 .poster{position:fixed;left:-10000px;top:-10000px;overflow:hidden;padding:1rem;background:#ececec}._29HP61GA_0 .richcontent-pre-copy{font-size:13px;color:#888;position:absolute;right:1em;top:.5em;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}._29HP61GA_0 .richcontent-pre-copy .iconfont{font-size:12px;margin-right:.2em}._29HP61GA_0 a{color:#fa8919;border-bottom:1px solid #fa8919}._29HP61GA_0 img{display:block;max-width:100%;position:relative;left:50%;-webkit-transform:translateX(-50%);transform:translateX(-50%);background-color:#eee;vertical-align:top;border-radius:0}._29HP61GA_0 audio,._29HP61GA_0 video{width:100%;background-color:#eee}._29HP61GA_0 pre{margin-top:16px;padding:34px 0 0;margin-bottom:30px;position:relative;border-radius:6px;background:rgba(246,247,251,.749);border:0}._29HP61GA_0 pre code{font-size:12px;font-family:Consolas,Liberation Mono,Menlo,monospace,Courier;display:block;-webkit-box-sizing:border-box;box-sizing:border-box;margin-left:16px;margin-right:16px;overflow-x:scroll}._29HP61GA_0 pre code:after{content:"";height:30px;width:100%;display:block}._29HP61GA_0 hr{border:none;margin-top:1.5rem;margin-bottom:1.5rem;border-top:1px solid #f5f5f5;height:1px;background:none}._29HP61GA_0 h1,._29HP61GA_0 h2,._29HP61GA_0 h3,._29HP61GA_0 h4,._29HP61GA_0 h5{margin-bottom:20px;margin-top:0;font-weight:700;color:#353535}._29HP61GA_0 b,._29HP61GA_0 strong{font-weight:700;color:#353535}._29HP61GA_0 h1{font-size:21px}._29HP61GA_0 h2{font-size:20px}._29HP61GA_0 h3{font-size:19px}._29HP61GA_0 h4{font-size:18px}._29HP61GA_0 h5{font-size:17px}._29HP61GA_0 center,._29HP61GA_0 p{font-weight:400;color:#353535;margin-top:0;margin-bottom:30px;word-break:break-word}._29HP61GA_0 center{text-align:center}._29HP61GA_0 blockquote{margin-top:0;margin-bottom:34px;border-left:3px solid #e8e8e8;padding-left:17px;color:#353535}._29HP61GA_0 blockquote p{margin-top:0;margin-bottom:0}._29HP61GA_0 ol,._29HP61GA_0 ul{margin-bottom:30px}._29HP61GA_0 ol p,._29HP61GA_0 ul p{margin-top:0;margin-bottom:0}._29HP61GA_0 ol{list-style:decimal;margin-left:20px}._29HP61GA_0 ul li{padding-left:17px;position:relative;margin-bottom:10px}._29HP61GA_0 ul li:after{content:"";height:6px;width:6px;border-radius:50%;background:#353535;position:absolute;top:10px;left:0}._29HP61GA_0 .orange{color:#fa8919}._29HP61GA_0 .reference{color:#888}._29HP61GA_0 .m-right{text-align:right}._29HP61GA_0 .m-center{text-align:center;display:block}._29HP61GA_0 .m-gray{color:#888}._29HP61GA_0 .m-small{font-size:15px}._29HP61GA_0 table.hljs-ln{margin-bottom:0;border-spacing:0;border-collapse:collapse}._29HP61GA_0 table.hljs-ln,._29HP61GA_0 table.hljs-ln tbody,._29HP61GA_0 table.hljs-ln td,._29HP61GA_0 table.hljs-ln tr{-webkit-box-sizing:border-box;box-sizing:border-box}._29HP61GA_0 table.hljs-ln td{padding:0;border:0}._29HP61GA_0 table.hljs-ln td.hljs-ln-numbers{min-width:15px;font-size:12px;color:rgba(27,31,35,.3);text-align:right;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}._29HP61GA_0 table.hljs-ln td.hljs-ln-code,._29HP61GA_0 table.hljs-ln td.hljs-ln-numbers{font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;line-height:20px;vertical-align:top}._29HP61GA_0 table.hljs-ln td.hljs-ln-code{position:relative;padding-right:10px;padding-left:10px;overflow:visible;font-size:13px;color:#666;word-wrap:normal;white-space:pre}._2gMcXXSK_0{font-size:15px}._2gMcXXSK_0 h1{font-size:19px}._2gMcXXSK_0 h2{font-size:18px}._2gMcXXSK_0 h3{font-size:17px}._2gMcXXSK_0 h4{font-size:16px}._2gMcXXSK_0 h5{font-size:15px}._2gMcXXSK_0 p{margin-bottom:26px}._2gMcXXSK_0 blockquote{margin-bottom:30px}._2gMcXXSK_0 ol,._2gMcXXSK_0 ul{margin-bottom:26px}._2gMcXXSK_0 .m-small{font-size:13px}._1-IhkAAb_0{font-size:19px}._1-IhkAAb_0 h1{font-size:23px}._1-IhkAAb_0 h2{font-size:22px}._1-IhkAAb_0 h3{font-size:21px}._1-IhkAAb_0 h4{font-size:20px}._1-IhkAAb_0 h5{font-size:19px}._1-IhkAAb_0 .m-small{font-size:17px}._1Xjr5LRK_0 table.hljs-ln td.hljs-ln-code,._1Xjr5LRK_0 table.hljs-ln td.hljs-ln-numbers{font-family:monospace}._1XhbM4Sp_0 pre{background:hsla(43,50%,87%,.749)}._1XhbM4Sp_0 blockquote{border-color:#efe6cf}._2wERfXHe_0 h1,._2wERfXHe_0 h2,._2wERfXHe_0 h3,._2wERfXHe_0 h4,._2wERfXHe_0 h5,._2wERfXHe_0 p{color:silver}._2wERfXHe_0 blockquote{border-color:#3e3e3e}._2wERfXHe_0 li,._2wERfXHe_0 strong{color:silver}._2wERfXHe_0 pre{background:rgba(62,62,62,.749)}._2wERfXHe_0 center{color:silver}._2wERfXHe_0 img{opacity:.9}._2wERfXHe_0 ul li:after{background:silver}._2wERfXHe_0 table.hljs-ln td.hljs-ln-numbers{color:#b2b2b2}._2wERfXHe_0 table.hljs-ln td.hljs-ln-code{color:silver}</style><style type="text/css">.reJj6Thl_0{list-style-position:inside;width:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin-top:40px}.reJj6Thl_0 a{border-bottom:none}.reJj6Thl_0 ._2273kGdT_0{width:35px;height:35px;-ms-flex-negative:0;flex-shrink:0;border-radius:50%}.reJj6Thl_0:last-child ._2CG0SquK_0{border-bottom:none}.reJj6Thl_0 ._2CG0SquK_0{margin-left:.5rem;-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;padding-bottom:25px;border-bottom:.5px solid #e8e8e8;-webkit-transition:border-bottom .3s ease;transition:border-bottom .3s ease;overflow:hidden}.reJj6Thl_0 ._2CG0SquK_0 ._304R4gla_0{width:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;padding-bottom:10px}.reJj6Thl_0 ._2CG0SquK_0 ._3M6kV3zb_0{color:#4c4c4c;font-size:16px;font-weight:400;white-space:normal;word-break:normal;line-height:1.6;overflow:hidden;display:-webkit-box;-webkit-line-clamp:5;-webkit-box-orient:vertical}.reJj6Thl_0 ._2CG0SquK_0 ._3D2NkqD6_0{overflow:auto;-webkit-line-clamp:unset}.reJj6Thl_0 ._2CG0SquK_0 ._1H1Z49Dr_0{color:#888;font-size:11px;line-height:1;margin-top:4px}.reJj6Thl_0 ._2CG0SquK_0 ._18Dng5rT_0{color:#353535;font-size:14px;font-weight:700;height:20px;line-height:20px}.reJj6Thl_0 ._1bkbsnjg_0{height:15px;line-height:15px;width:30px;overflow:hidden;font-size:10px;color:#fff;background:#cbcbcb;text-align:center;display:inline-block;border-radius:3px;vertical-align:top;margin-top:2px}.reJj6Thl_0 ._2eMTs2JE_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:26px}.reJj6Thl_0 ._1YQBH3WC_0{color:#999;font-size:13px;margin-left:42px;width:20px;text-align:center}.reJj6Thl_0 ._13n1j2Zp_0{color:#999;font-size:11px;width:20px;margin-left:38px;text-align:center}.reJj6Thl_0 ._2P4B1Hdm_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;font-size:15.25px;text-decoration:none}.reJj6Thl_0 ._2P4B1Hdm_0 i{color:#999;display:inline-block;font-size:15px;margin-right:4px;height:27px;width:15px;margin-top:-2px}.reJj6Thl_0 ._2P4B1Hdm_0 i._2A421P4G_0background-size:15px}.reJj6Thl_0 ._2P4B1Hdm_0 span{color:#888;font-size:13px;font-weight:400}.reJj6Thl_0 ._2P4B1Hdm_0 span._2A421P4G_0{color:#fa8919}.reJj6Thl_0 ._2r3UB1GX_0{font-size:13px;color:#b2b2b2;height:16px;padding-top:8px}.reJj6Thl_0 ._2r3UB1GX_0 span{font-weight:500}.reJj6Thl_0 ._2r3UB1GX_0 i,.reJj6Thl_0 ._2r3UB1GX_0 span{height:16px;line-height:16px;display:inline-block;vertical-align:top}.reJj6Thl_0 ._2xNIY4NG_0{margin-top:10px}.reJj6Thl_0 ._2xNIY4NG_0 ._33BLbmw4_0{color:#888;font-size:14px;font-weight:400;white-space:normal;word-break:normal;background:#f6f7fb;-webkit-transition:background .3s ease;transition:background .3s ease;border-radius:10px;padding:18px;overflow-x:scroll}.reJj6Thl_0 ._2xNIY4NG_0 ._1H1Z49Dr_0{color:#888;font-size:9px}._0X_LEcd_0 ._2xNIY4NG_0 ._33BLbmw4_0{background:#efe6cf}.cGm0Q9aA_0 ._2CG0SquK_0{border-bottom:1px solid #4c4c4c}.cGm0Q9aA_0 ._2CG0SquK_0 ._1H1Z49Dr_0,.cGm0Q9aA_0 ._2CG0SquK_0 ._3M6kV3zb_0,.cGm0Q9aA_0 ._2CG0SquK_0 ._18Dng5rT_0{color:silver}.cGm0Q9aA_0 ._2xNIY4NG_0 ._33BLbmw4_0{color:silver;background:#3e3e3e}.cGm0Q9aA_0 ._1YQBH3WC_0,.cGm0Q9aA_0 ._2P4B1Hdm_0 i,.cGm0Q9aA_0 ._2P4B1Hdm_0 span,.cGm0Q9aA_0 ._13n1j2Zp_0{color:#999}._2Gn7zqLg_0 ._1bkbsnjg_0{line-height:18px}</style>
    <script id="savepage-contentloaders" type="application/javascript">
      "use strict"
      savepage_ContentLoaders();
      function savepage_ContentLoaders()
      {
        var resourceMimeType = new Array();
        var resourceBase64Data = new Array();
        var resourceBlobUrl = new Array();
        window.addEventListener("DOMContentLoaded",
        function(event)
        {
          savepage_ShadowLoader(5);
          savepage_ResourceLoader(5);
          document.getElementById('savepage-contentloaders').remove();
        },false);
        function savepage_ShadowLoader(c){createShadowDOMs(0,document.documentElement);function createShadowDOMs(a,b){var i;if(b.localName=="iframe"||b.localName=="frame"){if(a<c){try{if(b.contentDocument.documentElement!=null){createShadowDOMs(a+1,b.contentDocument.documentElement)}}catch(e){}}}else{if(b.children.length>=1&&b.children[0].localName=="template"&&b.children[0].hasAttribute("data-savepage-shadowroot")){b.attachShadow({mode:"open"}).appendChild(b.children[0].content);b.removeChild(b.children[0]);for(i=0;i<b.shadowRoot.children.length;i++)if(b.shadowRoot.children[i]!=null)createShadowDOMs(a,b.shadowRoot.children[i])}for(i=0;i<b.children.length;i++)if(b.children[i]!=null)createShadowDOMs(a,b.children[i])}}}
        function savepage_ResourceLoader(f){createBlobURLs();replaceReferences(0,document.documentElement);function createBlobURLs(){var i,j,binaryString,blobData;var a=new Array();for(i=0;i<resourceMimeType.length;i++){if(typeof resourceMimeType[i]!="undefined"){binaryString=atob(resourceBase64Data[i]);resourceBase64Data[i]="";a.length=0;for(j=0;j<binaryString.length;j++){a[j]=binaryString.charCodeAt(j)}blobData=new Blob([new Uint8Array(a)],{type:resourceMimeType[i]});resourceMimeType[i]="";resourceBlobUrl[i]=window.URL.createObjectURL(blobData)}}}function replaceReferences(a,b){var i,regex1,regex2,csstext,blobData;regex1=/url\(\s*((?:"[^"]+")|(?:'[^']+')|(?:[^\s)]+))\s*\)/gi;regex2=/data:[^;]*;if(b.hasAttribute("style")){csstext=b.style.cssText;b.style.cssText=csstext.replace(regex1,replaceCSSRef)}if(b.localName=="style"){csstext=b.textContent;b.textContent=csstext.replace(regex1,replaceCSSRef)}else if(b.localName=="link"&&(b.rel.toLowerCase()=="icon"||b.rel.toLowerCase()=="shortcut icon")){if(b.href!="")b.href=b.href.replace(regex2,replaceRef)}else if(b.localName=="body"){if(b.background!="")b.background=b.background.replace(regex2,replaceRef)}else if(b.localName=="img"){if(b.src!="")b.src=b.src.replace(regex2,replaceRef)}else if(b.localName=="input"&&b.type.toLowerCase()=="image"){if(b.src!="")b.src=b.src.replace(regex2,replaceRef)}else if(b.localName=="audio"){if(b.src!=""){b.src=b.src.replace(regex2,replaceRef);b.load()}}else if(b.localName=="video"){if(b.src!=""){b.src=b.src.replace(regex2,replaceRef);b.load()}if(b.poster!="")b.poster=b.poster.replace(regex2,replaceRef)}else if(b.localName=="source"){if(b.src!=""){b.src=b.src.replace(regex2,replaceRef);b.parentElement.load()}}else if(b.localName=="track"){if(b.src!="")b.src=b.src.replace(regex2,replaceRef)}else if(b.localName=="object"){if(b.data!="")b.data=b.data.replace(regex2,replaceRef)}else if(b.localName=="embed"){if(b.src!="")b.src=b.src.replace(regex2,replaceRef)}if(b.localName=="iframe"||b.localName=="frame"){if(a<f){if(b.hasAttribute("data-savepage-sameorigin")){blobData=new Blob([decodeURIComponent(b.src.substr(29))],{type:"text/html;charset=utf-8"});b.onload=function(){try{if(b.contentDocument.documentElement!=null){replaceReferences(a+1,b.contentDocument.documentElement)}}catch(e){}};b.src=window.URL.createObjectURL(blobData)}}}else{if(b.shadowRoot!=null){for(i=0;i<b.shadowRoot.children.length;i++)if(b.shadowRoot.children[i]!=null)replaceReferences(a,b.shadowRoot.children[i])}for(i=0;i<b.children.length;i++)if(b.children[i]!=null)replaceReferences(a,b.children[i])}}function replaceCSSRef(a,b,c,d){var e=new Array();e=b.match(/data:[^;]*;resource=(\d+);base64,/i);if(e!=null)return"url("+resourceBlobUrl[+e[1]]+")";else return a}function replaceRef(a,b,c,d){return resourceBlobUrl[+b]}}
        
        
      }
    </script>
    
    <meta name="savepage-title" content="极客时间 | 数据分析实战45讲">
    <meta name="savepage-date" content="Wed Jun 05 2019 03:32:36 GMT+0800 (中国标准时间)">
    <meta name="savepage-state" content="Standard Items; Used resource loader; Retained cross-origin frames; Removed unsaved URLs; Max frame depth = 5; Max resource size = 50MB; Max resource time = 10s;">
    <meta name="savepage-version" content="15.0">
    <meta name="savepage-comments" content="">
    <meta name="savepage-resourceloader" content=""></head><body><div id="app"><div class="_3ADRghFH_0" style="background-color: rgb(255, 255, 255);"><div class="gpDqvVI7_0" style="background-color: rgb(255, 255, 255);"></div> <div class="_20-cXID6_0" style="opacity: 1;"><div class="_3O_7qs2p_0 _2q1SuvsS_0"> <!----> <div class="_50pDbNcP_0"><h1 class="vJXgmLTi_0 _2QmGFWqF_0">
        21丨朴素贝叶斯分类（下）：如何对文档进行分类？
      </h1> <div class="_2LbT9q3y_0 _2QmGFWqF_0"><span>2019-01-30</span> <span>陈旸</span> <div class="_3FoXPaWx_0"><span class="YLYfWxsg_0">数据分析实战45讲</span> <div class="nJKayDbe_0"><span>进入课程</span> <div class="_2k8p2GLU_0 iconfont"></div></div></div></div> <div class="_3Jbcj4Iu_0 _2QmGFWqF_0"><img src="https://static001.geekbang.org/resource/image/07/cd/07e32e9a279dc5c554f28583b84a06cd.jpg"  class="_1-ZfmNK8_0"> <div class="_2SACi4xg_0"></div> <!----> <div class="_1Bg5E78Y_0 _25ls2Q2l_0"><div class="_1qj_iPD7_0"><h3>讲述：陈旸</h3> <p><span style="margin-right: 3px;">时长</span><span style="margin-right: 10px;">14:22</span><span style="margin-right: 3px;">大小</span><span>13.17M</span></p></div> <!----> <div class="_2Ha38TVL_0 MH1rcCm7_0"> <div class="_1iA2uC1V_0 _1WF5YSBJ_0"></div> <div class="iconfont _2Kms_g0F_0"></div></div> <audio title="21丨朴素贝叶斯分类（下）：如何对文档进行分类？" src="https://res001.geekbang.org//media/audio/ee/e3/eec0c33f4d835287d62cc89d4c1e58e3/ld/ld.m3u8" ></audio></div> <div class="_3IatBmhv_0"><div class="_29HP61GA_0"><p>我们上一节讲了朴素贝叶斯的工作原理，今天我们来讲下这些原理是如何指导实际业务的。</p><p>朴素贝叶斯分类最适合的场景就是文本分类、情感分析和垃圾邮件识别。其中情感分析和垃圾邮件识别都是通过文本来进行判断。从这里你能看出来，这三个场景本质上都是文本分类，这也是朴素贝叶斯最擅长的地方。所以朴素贝叶斯也常用于自然语言处理 NLP 的工具。</p><p>今天我带你一起使用朴素贝叶斯做下文档分类的项目，最重要的工具就是 sklearn 这个机器学习神器。</p><h2>sklearn 机器学习包</h2><p>sklearn 的全称叫 Scikit-learn，它给我们提供了 3 个朴素贝叶斯分类算法，分别是高斯朴素贝叶斯（GaussianNB）、多项式朴素贝叶斯（MultinomialNB）和伯努利朴素贝叶斯（BernoulliNB）。</p><p>这三种算法适合应用在不同的场景下，我们应该根据特征变量的不同选择不同的算法：</p><p><strong>高斯朴素贝叶斯</strong>：特征变量是连续变量，符合高斯分布，比如说人的身高，物体的长度。</p><p><strong>多项式朴素贝叶斯</strong>：特征变量是离散变量，符合多项分布，在文档分类中特征变量体现在一个单词出现的次数，或者是单词的 TF-IDF 值等。</p><p><strong>伯努利朴素贝叶斯</strong>：特征变量是布尔变量，符合 0/1 分布，在文档分类中特征是单词是否出现。</p><!-- [[[read_end]]] --><p>伯努利朴素贝叶斯是以文件为粒度，如果该单词在某文件中出现了即为 1，否则为 0。而多项式朴素贝叶斯是以单词为粒度，会计算在某个文件中的具体次数。而高斯朴素贝叶斯适合处理特征变量是连续变量，且符合正态分布（高斯分布）的情况。比如身高、体重这种自然界的现象就比较适合用高斯朴素贝叶斯来处理。而文本分类是使用多项式朴素贝叶斯或者伯努利朴素贝叶斯。</p><h2>什么是 TF-IDF 值呢？</h2><p>我在多项式朴素贝叶斯中提到了“词的 TF-IDF 值”，如何理解这个概念呢？</p><p>TF-IDF 是一个统计方法，用来评估某个词语对于一个文件集或文档库中的其中一份文件的重要程度。</p><p>TF-IDF 实际上是两个词组 Term Frequency 和 Inverse Document Frequency 的总称，两者缩写为 TF 和 IDF，分别代表了词频和逆向文档频率。</p><p><strong>词频 TF</strong>计算了一个单词在文档中出现的次数，它认为一个单词的重要性和它在文档中出现的次数呈正比。</p><p><strong>逆向文档频率 IDF</strong>，是指一个单词在文档中的区分度。它认为一个单词出现在的文档数越少，就越能通过这个单词把该文档和其他文档区分开。IDF 越大就代表该单词的区分度越大。</p><p><strong>所以 TF-IDF 实际上是词频 TF 和逆向文档频率 IDF 的乘积</strong>。这样我们倾向于找到 TF 和 IDF 取值都高的单词作为区分，即这个单词在一个文档中出现的次数多，同时又很少出现在其他文档中。这样的单词适合用于分类。</p><h2>TF-IDF 如何计算</h2><p>首先我们看下词频 TF 和逆向文档概率 IDF 的公式。</p><p><img src="https://static001.geekbang.org/resource/image/bc/4d/bc31ff1f31f9cd26144404221f705d4d.png"  alt=""></p><p><img src="https://static001.geekbang.org/resource/image/b7/65/b7ad53560f61407e6964e7436da14365.png"  alt=""></p><p>为什么 IDF 的分母中，单词出现的文档数要加 1 呢？因为有些单词可能不会存在文档中，为了避免分母为 0，统一给单词出现的文档数都加 1。</p><p><strong>TF-IDF=TF*IDF。</strong></p><p>你可以看到，TF-IDF 值就是 TF 与 IDF 的乘积, 这样可以更准确地对文档进行分类。比如“我”这样的高频单词，虽然 TF 词频高，但是 IDF 值很低，整体的 TF-IDF 也不高。</p><p>我在这里举个例子。假设一个文件夹里一共有 10 篇文档，其中一篇文档有 1000 个单词，“this”这个单词出现 20 次，“bayes”出现了 5 次。“this”在所有文档中均出现过，而“bayes”只在 2 篇文档中出现过。我们来计算一下这两个词语的 TF-IDF 值。</p><p>针对“this”，计算 TF-IDF 值：</p><p><img src="https://static001.geekbang.org/resource/image/63/12/63abe3ce8aa0ea4a78ba537b5504df12.png"  alt=""></p><p><img src="https://static001.geekbang.org/resource/image/b5/7e/b5ac88c4e2a71cc2d4ceef4c01e0ba7e.png"  alt=""></p><p>所以 TF-IDF=0.02*(-0.0414)=-8.28e-4。</p><p>针对“bayes”，计算 TF-IDF 值：</p><p><img src="https://static001.geekbang.org/resource/image/3b/8d/3bbe56a7b76513604bfe6b39b890dd8d.png"  alt=""></p><p><img src="https://static001.geekbang.org/resource/image/1e/2e/1e8b7465b9949fe071e95aede172a52e.png"  alt=""></p><p>TF-IDF=0.005*0.5229=2.61e-3。</p><p>很明显“bayes”的 TF-IDF 值要大于“this”的 TF-IDF 值。这就说明用“bayes”这个单词做区分比单词“this”要好。</p><p><strong>如何求 TF-IDF</strong></p><p>在 sklearn 中我们直接使用 TfidfVectorizer 类，它可以帮我们计算单词 TF-IDF 向量的值。在这个类中，取 sklearn 计算的对数 log 时，底数是 e，不是 10。</p><p>下面我来讲下如何创建 TfidfVectorizer 类。</p><h2>TfidfVectorizer 类的创建：</h2><p>创建 TfidfVectorizer 的方法是：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">TfidfVectorizer(stop_words=stop_words, token_pattern=token_pattern)</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>我们在创建的时候，有两个构造参数，可以自定义停用词 stop_words 和规律规则 token_pattern。需要注意的是传递的数据结构，停用词 stop_words 是一个列表 List 类型，而过滤规则 token_pattern 是正则表达式。</p><p>什么是停用词？停用词就是在分类中没有用的词，这些词一般词频 TF 高，但是 IDF 很低，起不到分类的作用。为了节省空间和计算时间，我们把这些词作为停用词 stop words，告诉机器这些词不需要帮我计算。</p><p><img src="https://static001.geekbang.org/resource/image/04/e9/040723cc99b36e8ad7e45aa31e0690e9.png"  alt=""><br>
当我们创建好 TF-IDF 向量类型时，可以用 fit_transform 帮我们计算，返回给我们文本矩阵，该矩阵表示了每个单词在每个文档中的 TF-IDF 值。</p><p><img src="https://static001.geekbang.org/resource/image/0d/43/0d2263fbc97beb520680382f08656b43.png"  alt=""><br>
在我们进行 fit_transform 拟合模型后，我们可以得到更多的 TF-IDF 向量属性，比如，我们可以得到词汇的对应关系（字典类型）和向量的 IDF 值，当然也可以获取设置的停用词 stop_words。</p><p><img src="https://static001.geekbang.org/resource/image/a4/6b/a42780a5bca0531e75a294b4e2fe356b.png"  alt=""><br>
举个例子，假设我们有 4 个文档：</p><p>文档 1：this is the bayes document；</p><p>文档 2：this is the second second document；</p><p>文档 3：and the third one；</p><p>文档 4：is this the document。</p><p>现在想要计算文档里都有哪些单词，这些单词在不同文档中的 TF-IDF 值是多少呢？</p><p>首先我们创建 TfidfVectorizer 类：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.feature_extraction.text import TfidfVectorizer</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">tfidf_vec = TfidfVectorizer()</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>然后我们创建 4 个文档的列表 documents，并让创建好的 tfidf_vec 对 documents 进行拟合，得到 TF-IDF 矩阵：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">documents = [</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">    'this is the bayes document',</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">    'this is the second second document',</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">    'and the third one',</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">    'is this the document'</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">]</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">tfidf_matrix = tfidf_vec.fit_transform(documents)</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>输出文档中所有不重复的词：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">print('不重复的词:', tfidf_vec.get_feature_names())</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>运行结果</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">不重复的词: ['and', 'bayes', 'document', 'is', 'one', 'second', 'the', 'third', 'this']</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>输出每个单词对应的 id 值：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">print('每个单词的 ID:', tfidf_vec.vocabulary_)</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>运行结果</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">每个单词的 ID: {'this': 8, 'is': 3, 'the': 6, 'bayes': 1, 'document': 2, 'second': 5, 'and': 0, 'third': 7, 'one': 4}</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>输出每个单词在每个文档中的 TF-IDF 值，向量里的顺序是按照词语的 id 顺序来的：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">print('每个单词的 tfidf 值:', tfidf_matrix.toarray())</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>运行结果：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">每个单词的 tfidf 值: [[0.         0.63314609 0.40412895 0.40412895 0.         0.</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">  0.33040189 0.         0.40412895]</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> [0.         0.         0.27230147 0.27230147 0.         0.85322574</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">  0.22262429 0.         0.27230147]</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> [0.55280532 0.         0.         0.         0.55280532 0.</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">  0.28847675 0.55280532 0.        ]</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> [0.         0.         0.52210862 0.52210862 0.         0.</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">  0.42685801 0.         0.52210862]]</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><h2>如何对文档进行分类</h2><p>如果我们要对文档进行分类，有两个重要的阶段：</p><p><img src="https://static001.geekbang.org/resource/image/25/c3/257e01f173e8bc78b37b71b2358ff7c3.jpg"  alt=""></p><ol>
<li>
<p><strong>基于分词的数据准备</strong>，包括分词、单词权重计算、去掉停用词；</p>
</li>
<li>
<p><strong>应用朴素贝叶斯分类进行分类</strong>，首先通过训练集得到朴素贝叶斯分类器，然后将分类器应用于测试集，并与实际结果做对比，最终得到测试集的分类准确率。</p>
</li>
</ol><p>下面，我分别对这些模块进行介绍。</p><p><strong>模块 1：对文档进行分词</strong></p><p>在准备阶段里，最重要的就是分词。那么如果给文档进行分词呢？英文文档和中文文档所使用的分词工具不同。</p><p>在英文文档中，最常用的是 NTLK 包。NTLK 包中包含了英文的停用词 stop words、分词和标注方法。</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">import nltk</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">word_list = nltk.word_tokenize(text) # 分词</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">nltk.pos_tag(word_list) # 标注单词的词性</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>在中文文档中，最常用的是 jieba 包。jieba 包中包含了中文的停用词 stop words 和分词方法。</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">import jieba</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">word_list = jieba.cut (text) # 中文分词</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p><strong>模块 2：加载停用词表</strong></p><p>我们需要自己读取停用词表文件，从网上可以找到中文常用的停用词保存在 stop_words.txt，然后利用 Python 的文件读取函数读取文件，保存在 stop_words 数组中。</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">stop_words = [line.strip().decode('utf-8') for line in io.open('stop_words.txt').readlines()]</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p><strong>模块 3：计算单词的权重</strong></p><p>这里我们用到 sklearn 里的 TfidfVectorizer 类，上面我们介绍过它使用的方法。</p><p>直接创建 TfidfVectorizer 类，然后使用 fit_transform 方法进行拟合，得到 TF-IDF 特征空间 features，你可以理解为选出来的分词就是特征。我们计算这些特征在文档上的特征向量，得到特征空间 features。</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">tf = TfidfVectorizer(stop_words=stop_words, max_df=0.5)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">features = tf.fit_transform(train_contents)</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>这里 max_df 参数用来描述单词在文档中的最高出现率。假设 max_df=0.5，代表一个单词在 50% 的文档中都出现过了，那么它只携带了非常少的信息，因此就不作为分词统计。</p><p>一般很少设置 min_df，因为 min_df 通常都会很小。</p><p><strong>模块 4：生成朴素贝叶斯分类器</strong></p><p>我们将特征训练集的特征空间 train_features，以及训练集对应的分类 train_labels 传递给贝叶斯分类器 clf，它会自动生成一个符合特征空间和对应分类的分类器。</p><p>这里我们采用的是多项式贝叶斯分类器，其中 alpha 为平滑参数。为什么要使用平滑呢？因为如果一个单词在训练样本中没有出现，这个单词的概率就会被计算为 0。但训练集样本只是整体的抽样情况，我们不能因为一个事件没有观察到，就认为整个事件的概率为 0。为了解决这个问题，我们需要做平滑处理。</p><p>当 alpha=1 时，使用的是 Laplace 平滑。Laplace 平滑就是采用加 1 的方式，来统计没有出现过的单词的概率。这样当训练样本很大的时候，加 1 得到的概率变化可以忽略不计，也同时避免了零概率的问题。</p><p>当 0&lt;alpha&lt;1 时，使用的是 Lidstone 平滑。对于 Lidstone 平滑来说，alpha 越小，迭代次数越多，精度越高。我们可以设置 alpha 为 0.001。</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 多项式贝叶斯分类器</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.naive_bayes import MultinomialNB  </div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">clf = MultinomialNB(alpha=0.001).fit(train_features, train_labels)</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p><strong>模块 5：使用生成的分类器做预测</strong></p><p>首先我们需要得到测试集的特征矩阵。</p><p>方法是用训练集的分词创建一个 TfidfVectorizer 类，使用同样的 stop_words 和 max_df，然后用这个 TfidfVectorizer 类对测试集的内容进行 fit_transform 拟合，得到测试集的特征矩阵 test_features。</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">test_tf = TfidfVectorizer(stop_words=stop_words, max_df=0.5, vocabulary=train_vocabulary)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">test_features=test_tf.fit_transform(test_contents)</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>然后我们用训练好的分类器对新数据做预测。</p><p>方法是使用 predict 函数，传入测试集的特征矩阵 test_features，得到分类结果 predicted_labels。predict 函数做的工作就是求解所有后验概率并找出最大的那个。</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">predicted_labels=clf.predict(test_features)</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p><strong>模块 6：计算准确率</strong></p><p>计算准确率实际上是对分类模型的评估。我们可以调用 sklearn 中的 metrics 包，在 metrics 中提供了 accuracy_score 函数，方便我们对实际结果和预测的结果做对比，给出模型的准确率。</p><p>使用方法如下：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn import metrics</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">print metrics.accuracy_score(test_labels, predicted_labels)</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><h2>数据挖掘神器 sklearn</h2><p>从数据挖掘的流程来看，一般包括了获取数据、数据清洗、模型训练、模型评估和模型部署这几个过程。</p><p>sklearn 中包含了大量的数据挖掘算法，比如三种朴素贝叶斯算法，我们只需要了解不同算法的适用条件，以及创建时所需的参数，就可以用模型帮我们进行训练。在模型评估中，sklearn 提供了 metrics 包，帮我们对预测结果与实际结果进行评估。</p><p>在文档分类的项目中，我们针对文档的特点，给出了基于分词的准备流程。一般来说 NTLK 包适用于英文文档，而 jieba 适用于中文文档。我们可以根据文档选择不同的包，对文档提取分词。这些分词就是贝叶斯分类中最重要的特征属性。基于这些分词，我们得到分词的权重，即特征矩阵。</p><p>通过特征矩阵与分类结果，我们就可以创建出朴素贝叶斯分类器，然后用分类器进行预测，最后预测结果与实际结果做对比即可以得到分类器在测试集上的准确率。</p><p><img src="https://static001.geekbang.org/resource/image/2e/6e/2e2962ddb7e85a71e0cecb9c6d13306e.png"  alt=""></p><h2>练习题</h2><p>我已经讲了中文文档分类中的 6 个关键的模块，最后，我给你留一道对中文文档分类的练习题吧。</p><p>我将中文文档数据集上传到了 GitHub 上，<a href="https://github.com/cystanford/text_classification">点击这里下载</a>。</p><p>数据说明：</p><ol>
<li>文档共有 4 种类型：女性、体育、文学、校园；</li>
</ol><p><img src="https://static001.geekbang.org/resource/image/67/28/67abc1783f7c4e7cd69194fafc514328.png"  alt=""></p><ol>
<li>训练集放到 train 文件夹里，测试集放到 test 文件夹里，停用词放到 stop 文件夹里。</li>
</ol><p><img src="https://static001.geekbang.org/resource/image/0c/0f/0c374e3501cc28a24687bc030733050f.png"  alt=""><br>
请使用朴素贝叶斯分类对训练集进行训练，并对测试集进行验证，并给出测试集的准确率。</p><p>最后你不妨思考一下，假设我们要判断一个人的性别，是通过身高、体重、鞋码、外貌等属性进行判断的，如果我们用朴素贝叶斯做分类，适合使用哪种朴素贝叶斯分类器？停用词的作用又是什么？</p><p>欢迎你在评论区进行留言，与我分享你的答案。也欢迎点击“请朋友读”，把这篇文章分享给你的朋友或者同事。</p><p><img src="https://static001.geekbang.org/resource/image/48/96/48cb89aa8c4858bbc18df3b3ac414496.jpg"  alt=""></p></div></div> <!----> 
        </div></div> <div class="_2DmyW7ex_0 _2QmGFWqF_0"><div class="_1M5b-cvc_0"><div class="_3l55W_ak_0">上一篇</div> <div class="_3Ov-zF0e_0">20丨朴素贝叶斯分类（上）：如何让机器判断男女？</div></div> <div class="_1M5b-cvc_0"><div class="_3l55W_ak_0">下一篇</div> <div class="_3Ov-zF0e_0">22丨SVM（上）：如何用一根棍子将蓝红两色球分开？</div></div></div> <div class="_1qhD3bdE_0 _2QmGFWqF_0"><div class="iconfont _2-nZIZjB_0"> 写留言</div> <h2><span class="_2FC_cD1O_0">(34)</span></h2> <ul><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/14/a3/f9/9180d6d1.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>szm</span> <!----></div> <div class="_1H1Z49Dr_0">2019-01-30</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">24</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">需要完整代码，不然看不明白！</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/11/02/82/abed70a0.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>北方</span> <!----></div> <div class="_1H1Z49Dr_0">2019-02-14</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">16</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">#!/usr/bin/env python<br># -*- coding:utf8 -*-<br># __author__ = '北方姆Q'<br># __datetime__ = 2019/2/14 14:04<br><br>import os<br>import jieba<br>from sklearn.feature_extraction.text import TfidfVectorizer<br>from sklearn.naive_bayes import MultinomialNB<br>from sklearn import metrics<br><br>LABEL_MAP = {'体育': 0, '女性': 1, '文学': 2, '校园': 3}<br># 加载停用词<br>with open('./text classification/stop/stopword.txt', 'rb') as f:<br>    STOP_WORDS = [line.strip() for line in f.readlines()]<br><br><br>def load_data(base_path):<br>    """<br>    :param base_path: 基础路径<br>    :return: 分词列表，标签列表<br>    """<br>    documents = []<br>    labels = []<br><br>    for root, dirs, files in os.walk(base_path):    # 循环所有文件并进行分词打标<br>        for file in files:<br>            label = root.split('\\')[-1]        # 因为windows上路径符号自动转成\了，所以要转义下<br>            labels.append(label)<br>            filename = os.path.join(root, file)<br>            with open(filename, 'rb') as f:     # 因为字符集问题因此直接用二进制方式读取<br>                content = f.read()<br>                word_list = list(jieba.cut(content))<br>                words = [wl for wl in word_list]<br>                documents.append(' '.join(words))<br>    return documents, labels<br><br><br>def train_fun(td, tl, testd, testl):<br>    """<br>    构造模型并计算测试集准确率，字数限制变量名简写<br>    :param td: 训练集数据<br>    :param tl: 训练集标签<br>    :param testd: 测试集数据<br>    :param testl: 测试集标签<br>    :return: 测试集准确率<br>    """<br>    # 计算矩阵<br>    tt = TfidfVectorizer(stop_words=STOP_WORDS, max_df=0.5)<br>    tf = tt.fit_transform(td)<br>    # 训练模型<br>    clf = MultinomialNB(alpha=0.001).fit(tf, tl)<br>    # 模型预测<br>    test_tf = TfidfVectorizer(stop_words=STOP_WORDS, max_df=0.5, vocabulary=tt.vocabulary_)<br>    test_features = test_tf.fit_transform(testd)<br>    predicted_labels = clf.predict(test_features)<br>    # 获取结果<br>    x = metrics.accuracy_score(testl, predicted_labels)<br>    return x<br><br><br># text classification与代码同目录下<br>train_documents, train_labels = load_data('./text classification/train')<br>test_documents, test_labels = load_data('./text classification/test')<br>x = train_fun(train_documents, train_labels, test_documents, test_labels)<br>print(x)</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>Python</span> <!----></div> <div class="_1H1Z49Dr_0">2019-01-30</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">15</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">老师，能不能在答疑的时候给这道题的完整代码看看</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/10/28/9c/73e76b19.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>姜戈</span> <!----></div> <div class="_1H1Z49Dr_0">2019-01-30</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">9</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">看过很多朴素贝叶斯原理和分类的讲解文章，很少能像前辈这样既有理论，又有实战的讲解，让大家既了解了理论知识，又有相应实际的操作经验可学，真的好棒，这个专栏，必须多多点赞，为老师加油！！！</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIlShPdVFbIaUu0wtcuSrlkG9r5zBedPuuN4Pyichof0QnMvr4J0G4kykyA4cgrlYibZ6wZ6NJNevFQ/132" src="" class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>池边的树</span> <!----></div> <div class="_1H1Z49Dr_0">2019-02-12</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">4</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">https://github.com/yourSprite/AnalysisExcercise/tree/master/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/16/50/91/0dd2b8ce.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>听妈妈的话</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-21</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">3</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0"># 由于评论不支持markdown，代码放在https://pastebin.com/kqjXgy0c<br><br>train_contents=[]<br>train_labels=[]<br>test_contents=[]<br>test_labels=[]<br>#  导入文件<br>import os<br>import io<br>start=os.listdir(r'text classification/train')<br>for item in start:<br>    test_path='text classification/test/'+item+'/'<br>    train_path='text classification/train/'+item+'/'<br>    for file in os.listdir(test_path):<br>        with open(test_path+file,encoding="GBK") as f:<br>            test_contents.append(f.readline())<br>            #print(test_contents)<br>            test_labels.append(item)<br>    for file in os.listdir(train_path):<br>        with open(train_path+file,encoding='gb18030', errors='ignore') as f:<br>            train_contents.append(f.readline())<br>            train_labels.append(item)<br>print(len(train_contents),len(test_contents))<br><br># 导入stop word<br>import jieba<br>from sklearn import metrics<br>from sklearn.naive_bayes import MultinomialNB  <br>stop_words = [line.strip() for line in io.open('text classification/stop/stopword.txt').readlines()]<br><br># 分词方式使用jieba,计算单词的权重<br>tf = TfidfVectorizer(tokenizer=jieba.cut,stop_words=stop_words, max_df=0.5)<br>train_features = tf.fit_transform(train_contents)<br>print(train_features.shape)<br><br>模块 4：生成朴素贝叶斯分类器<br># 多项式贝叶斯分类器<br>clf = MultinomialNB(alpha=0.001).fit(train_features, train_labels)<br><br>模块 5：使用生成的分类器做预测<br>test_tf = TfidfVectorizer(tokenizer=jieba.cut,stop_words=stop_words, max_df=0.5, vocabulary=tf.vocabulary_)<br>test_features=test_tf.fit_transform(test_contents)<br><br>print(test_features.shape)<br>predicted_labels=clf.predict(test_features)<br>print(metrics.accuracy_score(test_labels, predicted_labels))<br><br># 最终结果0.925</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJAeZ2VCia2y3bW9N7EMfgBqX8WClXUydwaXDPcK7Bm3XaMnMKx7q5ffA0UuTeJmEusxtQAibf8djCA/132" src="" class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>上官</span> <!----></div> <div class="_1H1Z49Dr_0">2019-01-31</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">3</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0 _3D2NkqD6_0">print('不重复的词:', tfidf_vec.get_feature_names())<br>运行结果：  不重复的词: ['and', 'bayes', 'document', 'is', 'one', 'second', 'the', 'third', 'this']<br>这明明就是打印所有词啊，有重复的啊<br></div> <!----> <!----></div></li><li class="reJj6Thl_0"><img  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>Jack</span> <!----></div> <div class="_1H1Z49Dr_0">2019-02-14</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">2</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">#!/usr/bin/env python<br># coding: utf-8<br><br>import os<br>import jieba<br>import pandas as pd<br>from sklearn.feature_extraction.text import TfidfVectorizer<br>from sklearn.naive_bayes import MultinomialNB<br># 1. 加载数据<br># 加载停用词表<br>l_stopWords = set()<br>with open('./text_classification/text_classification/stop/stopword.txt', 'r') as l_f:<br>    for l_line in l_f:<br>        l_stopWords.add(l_line.strip())<br><br>l_labelMap = {'体育': 0, '女性': 1, '文学': 2, '校园': 3}<br># 加载训练数据和测试数据<br>def LoadData(filepath):<br>    l_documents = []<br>    l_labels = []<br>    for root, dirs, files in os.walk(filepath):<br>        for l_file in files:<br>            l_label = root.split('/')[-1]<br>            l_filename = os.path.join(root, l_file)<br>            <br>            with open(l_filename, 'r') as l_f:<br>                l_content = l_f.read()<br>                l_wordlist = list(jieba.cut(l_content))<br>                l_words = [item for item in l_wordlist if item not in l_stopWords]<br>                l_documents.append(' '.join(l_words))<br>                l_labels.append(l_labelMap[l_label])<br>                <br>    return l_documents, l_labels<br><br>l_trainDocuments, l_trainLabels = LoadData('./text_classification/text_classification/train')<br>l_testDocuments, l_testLabels = LoadData('./text_classification/text_classification/test')<br><br># # 2. 计算权重矩阵<br>l_tfidfVec = TfidfVectorizer(max_df=0.5)<br>l_tfidfMatrix = l_tfidfVec.fit_transform(l_trainDocuments)<br><br># for item in l_tfidfVec.get_feature_names():<br>#     print item<br># print l_tfidfVec.get_feature_names()<br># print l_tfidfVec.vocabulary_<br>print l_tfidfMatrix.toarray().shape<br><br># # 3. 朴素贝叶斯模型<br># ## 3.1 模型训练<br>l_clf = MultinomialNB(alpha=0.001)<br>l_clf.fit(l_tfidfMatrix, l_trainLabels)<br><br># ## 3.2 模型预测<br>l_testTfidf = TfidfVectorizer(max_df=0.5, vocabulary=l_tfidfVec.vocabulary_)<br>l_testFeature = l_testTfidf.fit_transform(l_testDocuments)<br>l_hats = l_clf.predict(l_testFeature)<br><br># ## 3.3 模型评估<br>from sklearn.metrics import accuracy_score<br>print accuracy_score(l_hats, l_testLabels)</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/14/c1/1f/cc77944d.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>叮当猫</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-16</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">1</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">#-coding=utf-8<br>import os<br>import pandas as pd<br>import jieba<br>from sklearn import metrics<br>from sklearn.naive_bayes import MultinomialNB<br>from sklearn.feature_extraction.text import TfidfVectorizer<br><br>def load_data(path):<br>    l_labels = []<br>    l_documents = []<br>    #os.walk返回三元组(root, dirs, files)<br>    #root指的是当前正在遍历的这个文件夹本身的地址<br>    #dirs是一个list，内容是该文件夹中所有的目录的名字<br>    #files是一个list，内容是该文件夹中所有的文件，不包含子目录<br>    for root, dirs, files in os.walk(path):<br>        print root, dirs, files<br>        for l_file in files:<br>            l_label = root.split('/')[-1]<br>            l_filepath =  os.path.join(root, l_file)<br>            with open(l_filepath, 'r') as l_f:<br>                l_content = l_f.read()<br>                l_words = ' '.join(list(jieba.cut(l_content)) )<br>                l_labels.append(l_label)<br>                l_documents.append(l_words)<br>    return l_documents, l_labels<br><br>#第一步：对文档进行分词<br>train_documents, train_labels = load_data('./text classification/train/')<br>test_documents, test_labels = load_data('./text classification/test/')<br><br>#第二步：加载停用词<br>STOP_WORDS = [line.strip() for line in open('./text classification/stop/stopword.txt' ,'r').readlines()]<br><br>#第三步：计算单词的权重<br>tf = TfidfVectorizer(stop_words=STOP_WORDS, max_df=0.5)<br>train_features = tf.fit_transform(train_documents)<br><br>#第四步：生成朴素贝叶斯分类器<br>clf = MultinomialNB(alpha=0.001).fit(train_features, train_labels)<br><br>#第五步：使用生成的分类器做预测<br>test_tf = TfidfVectorizer(stop_words=STOP_WORDS, max_df=0.5, vocabulary=tf.vocabulary_)<br>test_features = test_tf.fit_transform(test_documents)<br><br>predict_labels = clf.predict(test_features)<br><br>#第六步：计算准确率<br>print metrics.accuracy_score(test_labels, predict_labels)</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>wzhan366</span> <!----></div> <div class="_1H1Z49Dr_0">2019-02-06</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">1</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">建议 大家先做英文版本，因为中文的unicode encode和decode不是很好弄，不利于中间步骤的可视化。如果对代码有疑惑，可以试试这个pipeline， sklearn 的。 不过，这个没有用NTLK。</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/da/55/df35904f.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>王小王</span> <!----></div> <div class="_1H1Z49Dr_0">2019-02-02</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">1</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">能不能讲解下本堂课的练习题？</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/14/a1/74/3dfa4436.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>Rickie</span> <!----></div> <div class="_1H1Z49Dr_0">2019-01-30</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">1</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">老师，token_pattern里的正则中（?u)是什么意思呀？</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/12/a3/87/0cb915e2.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>滢</span> <!----></div> <div class="_1H1Z49Dr_0">2019-04-17</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">最后面的代码太乱，很多都不知道从哪里来的，无法顺着看下去~~~</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>王彬成</span> <!----></div> <div class="_1H1Z49Dr_0">2019-04-05</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0"># -*- coding:utf8 -*-<br># 系统：mac <br><br># 1. 加载数据<br># 加载停用词表<br><br>l_stopWords = [line.strip() for line in open('./text_classification-master/text classification/stop/stopword.txt', 'r', encoding='utf-8').readlines()]  <br>   <br>l_labelMap = {'体育': 0, '女性': 1, '文学': 2, '校园': 3}<br># 加载训练数据和测试数据<br>def LoadData(filepath):<br>    l_documents = []<br>    l_labels = []<br>    <br>    for root, dirs, files in os.walk(filepath):<br>        for l_file in files:<br>            if l_file=='.DS_Store':<br>                continue<br>            l_label = root.split('/')[-1]<br>            l_filename = os.path.join(root, l_file)<br>            <br>            with open(l_filename, 'r',encoding='gbk') as l_f:<br>                try:<br>                    l_content = l_f.read()<br>                except Exception as err:<br>                    print(err)<br>                    print(l_filename)<br>                    continue<br>                generator = jieba.cut(l_content)<br>                words = ' '.join(generator)<br>                l_wordlist=words.split(' ')<br>                l_words = [item for item in l_wordlist if item not in l_stopWords]<br>                l_documents.append(' '.join(l_words))<br>                l_labels.append(l_labelMap[l_label])<br>                <br>    return l_documents, l_labels<br><br>l_trainDocuments, l_trainLabels = LoadData('./text_classification-master/text classification/train')<br>l_testDocuments, l_testLabels = LoadData('./text_classification-master/text classification/test')<br><br># # 2. 计算权重矩阵<br>l_tfidfVec = TfidfVectorizer(max_df=0.5)<br>l_tfidfMatrix = l_tfidfVec.fit_transform(l_trainDocuments)<br><br>print (l_tfidfMatrix.toarray().shape)<br><br># # 3. 朴素贝叶斯模型<br># ## 3.1 模型训练<br>l_clf = MultinomialNB(alpha=0.001)<br>l_clf.fit(l_tfidfMatrix, l_trainLabels)<br><br># ## 3.2 模型预测<br>l_testTfidf = TfidfVectorizer(max_df=0.5, vocabulary=l_tfidfVec.vocabulary_)<br>l_testFeature = l_testTfidf.fit_transform(l_testDocuments)<br>l_hats = l_clf.predict(l_testFeature)<br><br># ## 3.3 模型评估<br>from sklearn.metrics import accuracy_score<br>print (accuracy_score(l_hats, l_testLabels))</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/16/50/91/0dd2b8ce.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>听妈妈的话</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-21</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">我的代码位于：https://pastebin.com/kqjXgy0c ，最终结果0.925<br>注意: 中文分词，TfidfVectorizer增加一个参数：tokenizer=jieba.cut,（来自github jieba issue: https://github.com/fxsjy/jieba/issues/332）<br><br><br>train_contents=[]<br>train_labels=[]<br>test_contents=[]<br>test_labels=[]<br>#  导入文件<br>import os<br>import io<br>start=os.listdir(r'text classification/train')<br>for item in start:<br>    test_path='text classification/test/'+item+'/'<br>    train_path='text classification/train/'+item+'/'<br>    for file in os.listdir(test_path):<br>        with open(test_path+file,encoding="GBK") as f:<br>            test_contents.append(f.readline())<br>            #print(test_contents)<br>            test_labels.append(item)<br>    for file in os.listdir(train_path):<br>        with open(train_path+file,encoding='gb18030', errors='ignore') as f:<br>            train_contents.append(f.readline())<br>            train_labels.append(item)<br>print(len(train_contents),len(test_contents))<br> <br># 导入stop word<br>import jieba<br>from sklearn import metrics<br>from sklearn.naive_bayes import MultinomialNB  <br>stop_words = [line.strip() for line in io.open('text classification/stop/stopword.txt').readlines()]<br> <br># 分词方式使用jieba,计算单词的权重<br>tf = TfidfVectorizer(tokenizer=jieba.cut,stop_words=stop_words, max_df=0.5)<br>train_features = tf.fit_transform(train_contents)<br>print(train_features.shape)<br> <br>模块 4：生成朴素贝叶斯分类器<br># 多项式贝叶斯分类器<br>clf = MultinomialNB(alpha=0.001).fit(train_features, train_labels)<br> <br>模块 5：使用生成的分类器做预测<br>test_tf = TfidfVectorizer(tokenizer=jieba.cut,stop_words=stop_words, max_df=0.5, vocabulary=tf.vocabulary_)<br>test_features=test_tf.fit_transform(test_contents)<br> <br>print(test_features.shape)<br>predicted_labels=clf.predict(test_features)<br>print(metrics.accuracy_score(test_labels, predicted_labels))<br> <br># 最终结果0.925<br><br></div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/11/2d/9e/fc2b8d02.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>以圭</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-18</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">老师，请问一下代码中的train_labels需要去重吗？word_list 和 train_contents的关系是什么？word_list需要去重吗？features 和 train_features 的关系是什么？</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/14/de/17/a3b8f785.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>小莫</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-10</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">老师，完整代码能贴出来吗？</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/10/60/de/5c67895a.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>周飞</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-10</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">#!/usr/bin/env python<br># -*- coding:utf8 -*-<br>import os<br>import jieba<br>from sklearn.feature_extraction.text import TfidfVectorizer<br>from sklearn.naive_bayes import MultinomialNB<br>from sklearn import metrics<br><br><br>def load_data(base_path):    <br>    documents = []<br>    labels = []<br>    for root, dirs, files in os.walk(base_path): # 循环所有文件并进行分词打标        <br>        for file in files:<br>            label = root.split('\\')[-1] # 因为windows上路径符号自动转成\了，所以要转义下<br>            labels.append(label)<br>            filename = os.path.join(root, file)<br>            with open(filename, 'rb') as f: # 因为字符集问题因此直接用二进制方式读取<br>                content = f.read()<br>                word_list = list(jieba.cut(content))                <br>                words = [wl for wl in word_list]<br>                documents.append(' '.join(words))<br>    return documents, labels<br><br>train_contents, train_labels = load_data('./text_classification/train')<br>test_contents, test_labels = load_data('./text_classification/test')<br>stop_words = []<br><br>import io<br>stop_words = [line.strip().encode('utf-8') for line in io.open('./text_classification/stop/stopword.txt').readlines()]<br><br><br><br>tf = TfidfVectorizer(stop_words=stop_words, max_df=0.5)<br>train_features = tf.fit_transform(train_contents)<br># 多项式贝叶斯分类器<br> <br>clf = MultinomialNB(alpha=0.001).fit(train_features, train_labels)<br><br>test_tf = TfidfVectorizer(stop_words=stop_words, max_df=0.5, vocabulary=tf.vocabulary_)<br>test_features=test_tf.fit_transform(test_contents)<br>predicted_labels=clf.predict(test_features)<br>print (metrics.accuracy_score(test_labels, predicted_labels))<br><br>不知道为什么 结果是0。<br><br><br><br><br><br><br><br><br></div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>三硝基甲苯</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-10</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">import jieba<br>import glob<br>import io<br>from sklearn.feature_extraction.text import TfidfVectorizer<br>from sklearn.naive_bayes import MultinomialNB<br>from sklearn import metrics<br><br>classification = ["campus", "female", "sports", "literature"]<br>train_files_list = []<br>test_files_list = []<br>trainpathprefix = "./text_classification/train/"<br>testpathprefix = "./text_classification/test/"<br>pathsuffix = "/*.txt"<br>train_label = []<br>test_label = []<br>train_docments = []<br>test_docments = []<br>stopword_path = './text_classification/stop/stopword.txt'<br><br>for i in classification:<br>    trainpathstr = trainpathprefix + i + pathsuffix<br>    testpathstr = testpathprefix + i + pathsuffix<br>    trainpathlist = glob.glob(trainpathstr)<br>    lentrainlist = len(trainpathlist)<br>    train_label += [i for j in range(lentrainlist)]<br>    testpathlist = glob.glob(testpathstr)<br>    lentestlist = len(testpathlist)<br>    test_label += [i for j in range(lentestlist)]<br>    train_files_list += trainpathlist<br>    test_files_list += testpathlist<br><br>for i in train_files_list:<br>    f = open(i, 'r')<br>    content = f.readlines()[0]<br>    contentlist = list(jieba.cut(content))<br>    contentwithspace = " ".join(contentlist)<br>    train_docments.append(contentwithspace)<br><br>for i in test_files_list:<br>    f = open(i, 'r')<br>    content = f.readlines()[0]<br>    contentlist = list(jieba.cut(content))<br>    contentwithspace = ' '.join(contentlist)<br>    test_docments.append(contentwithspace)<br><br>stopwords = [l.strip('\n') for l in io.open(stopword_path, encoding='utf-8').readlines()]<br>train_tf = TfidfVectorizer(stop_words=stopwords, max_df=0.5)<br>train_features = train_tf.fit_transform(train_docments)<br>clf = MultinomialNB(alpha=0.001).fit(train_features, train_label)<br>test_tf = TfidfVectorizer(stop_words=stopwords, max_df=0.5, vocabulary=train_tf.vocabulary_)<br>test_features = test_tf.fit_transform(test_docments)<br>predicted_labels = clf.predict(test_features)<br>print(metrics.accuracy_score(test_label, predicted_labels))<br>运动的300.txt文件因为字符问题手动修改了一下。</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>YoungDou</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-08</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">ValueError: dimension mismatch  提示，还有编码问题，无法解决</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li></ul></div></div> <!----></div> <!----></div></div> </div><!----></body></html>