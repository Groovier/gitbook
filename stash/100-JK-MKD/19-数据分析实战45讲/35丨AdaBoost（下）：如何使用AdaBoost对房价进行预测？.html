<!DOCTYPE html><html><head>
    <meta charset="utf-8"><meta name="keywords" content="极客时间,IT,职业教育,知识付费,二叉树,极客Live,极客搜索,互联网,前端开发,后端开发,编程语言,人工智能,区块链,技术大会,技术管理,产品,研发,测试,运维,数据库,架构,微服务,实战,技术专家,Java,iOS,Android,Linux,Go" id="metakeywords"><meta name="description" content="极客时间是一款由极客邦科技倾力打造的面向IT领域的知识服务产品,旨在帮助用户提升技术认知.板块包含专栏文章、视频课程、新闻、资讯、直播、图书、商城等。内容覆盖IT从业者的全生命周期知识技能图谱,邀请左耳朵耗子、王争、杨晓峰、winter,丁奇等顶级技术和行业专家为你讲述技术本质,解读科技动态." id="metadesc"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,viewport-fit=cover"><meta name="format-detection" content="telephone=no"><title>极客时间 | 数据分析实战45讲</title><style data-savepage-href="https://static001.geekbang.org/static/time/css/app.e30427d82748c1a9d53a048cf510f63c.css">html{color:#333;-webkit-text-size-adjust:100%;-ms-text-size-adjust:100%;text-rendering:optimizelegibility;font-family:Helvetica Neue,PingFang SC,Verdana,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif}html.borderbox *,html.borderbox :after,html.borderbox :before{box-sizing:border-box}article,aside,blockquote,body,button,code,dd,details,dl,dt,fieldset,figcaption,figure,footer,form,h1,h2,h3,h4,h5,h6,header,hr,input,legend,li,menu,nav,ol,p,pre,section,td,textarea,th,ul{margin:0;padding:0}article,aside,details,figcaption,figure,footer,header,menu,nav,section{display:block}audio,canvas,video{display:inline-block}body,button,input,select,textarea{font:300 1em/1.8 PingFang SC,Lantinghei SC,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,Helvetica,sans-serif}button::-moz-focus-inner,input::-moz-focus-inner{padding:0;border:0}table{border-collapse:collapse;border-spacing:0}fieldset,img{border:0}blockquote{position:relative;color:#999;font-weight:400;border-left:1px solid #1abc9c;padding-left:1em;margin:1em 3em 1em 2em}@media only screen and (max-width:640px){blockquote{margin:1em 0}}abbr,acronym{border-bottom:1px dotted;font-variant:normal}abbr{cursor:help}del{text-decoration:line-through}address,caption,cite,code,dfn,em,th,var{font-style:normal;font-weight:400}ol,ul{list-style:none}caption,th{text-align:left}q:after,q:before{content:""}sub,sup{font-size:75%;line-height:0;position:relative}:root sub,:root sup{vertical-align:baseline}sup{top:-.5em}sub{bottom:-.25em}a{color:#1abc9c}a:hover{text-decoration:underline}.typo a{border-bottom:1px solid #1abc9c}.typo a:hover{border-bottom-color:#555;color:#555}.typo a:hover,a,ins{text-decoration:none}.typo-u,u{text-decoration:underline}mark{background:#fffdd1;border-bottom:1px solid #ffedce;padding:2px;margin:0 5px}code,pre,pre tt{font-family:Courier,Courier New,monospace}pre{background:hsla(0,0%,97%,.7);border:1px solid #ddd;padding:1em 1.5em;display:block;-webkit-overflow-scrolling:touch}hr{border:none;border-bottom:1px solid #cfcfcf;margin-bottom:.8em;height:10px}.typo-small,figcaption,small{font-size:.9em;color:#888}b,strong{font-weight:700;color:#000}[draggable]{cursor:move}.clearfix:after,.clearfix:before{content:"";display:table}.clearfix:after{clear:both}.clearfix{zoom:1}.textwrap,.textwrap td,.textwrap th{word-wrap:break-word;word-break:break-all}.textwrap-table{table-layout:fixed}.serif{font-family:Palatino,Optima,Georgia,serif}.typo-dl,.typo-form,.typo-hr,.typo-ol,.typo-p,.typo-pre,.typo-table,.typo-ul,.typo dl,.typo form,.typo hr,.typo ol,.typo p,.typo pre,.typo table,.typo ul,blockquote{margin-bottom:1rem}h1,h2,h3,h4,h5,h6{font-family:PingFang SC,Helvetica Neue,Verdana,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#000;line-height:1.35}.typo-h1,.typo-h2,.typo-h3,.typo-h4,.typo-h5,.typo-h6,.typo h1,.typo h2,.typo h3,.typo h4,.typo h5,.typo h6{margin-top:1.2em;margin-bottom:.6em;line-height:1.35}.typo-h1,.typo h1{font-size:2em}.typo-h2,.typo h2{font-size:1.8em}.typo-h3,.typo h3{font-size:1.6em}.typo-h4,.typo h4{font-size:1.4em}.typo-h5,.typo-h6,.typo h5,.typo h6{font-size:1.2em}.typo-ul,.typo ul{margin-left:1.3em;list-style:disc}.typo-ol,.typo ol{list-style:decimal;margin-left:1.9em}.typo-ol ol,.typo-ol ul,.typo-ul ol,.typo-ul ul,.typo li ol,.typo li ul{margin-bottom:.8em;margin-left:2em}.typo-ol ul,.typo-ul ul,.typo li ul{list-style:circle}.typo-table td,.typo-table th,.typo table caption,.typo table td,.typo table th{border:1px solid #ddd;padding:.5em 1em;color:#666}.typo-table th,.typo table th{background:#fbfbfb}.typo-table thead th,.typo table thead th{background:hsla(0,0%,95%,.7)}.typo table caption{border-bottom:none}.typo-input,.typo-textarea{-webkit-appearance:none;border-radius:0}.typo-em,.typo em,caption,legend{color:#000;font-weight:inherit}.typo-em{position:relative}.typo-em:after{position:absolute;top:.65em;left:0;width:100%;overflow:hidden;white-space:nowrap;content:"\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB"}.typo img{max-width:100%}.common-content{font-weight:400;color:#353535;line-height:1.75rem;white-space:normal;word-break:normal;font-size:1rem}.common-content img{display:block;max-width:100%;background-color:#eee}.common-content audio,.common-content video{width:100%;background-color:#eee}.common-content center,.common-content font{margin-top:1rem;display:inline-block}.common-content center{width:100%}.common-content pre{margin-top:1rem;padding-left:0;padding-right:0;position:relative;overflow:hidden}.common-content pre code{font-size:.8rem;font-family:Consolas,Liberation Mono,Menlo,monospace,Courier;display:block;width:100%;box-sizing:border-box;padding-left:1rem;padding-right:1rem;overflow-x:auto}.common-content hr{border:none;margin-top:1.5rem;margin-bottom:1.5rem;border-top:1px solid #f5f5f5;height:1px;background:none}.common-content b,.common-content h1,.common-content h2,.common-content h3,.common-content h4,.common-content h5,.common-content strong{font-weight:700}.common-content h1,.common-content h2{font-size:1.125rem;margin-bottom:.45rem}.common-content h3,.common-content h4,.common-content h5{font-size:1rem;margin-bottom:.45rem}.common-content p{font-weight:400;color:#353535;margin-top:.15rem}.common-content .orange{color:#ff5a05}.common-content .reference{font-size:1rem;color:#888}.custom-rich-content h1{margin-top:0;font-weight:400;font-size:15.25px;border-bottom:1px solid #eee;line-height:2.8}.custom-rich-content li,.custom-rich-content p{font-size:14px;color:#888;line-height:1.6}table.hljs-ln{margin-bottom:0;border-spacing:0;border-collapse:collapse}table.hljs-ln,table.hljs-ln tbody,table.hljs-ln td,table.hljs-ln tr{box-sizing:border-box}table.hljs-ln td{padding:0;border:0}table.hljs-ln td.hljs-ln-numbers{min-width:15px;color:rgba(27,31,35,.3);text-align:right;white-space:nowrap;cursor:pointer;user-select:none}table.hljs-ln td.hljs-ln-code,table.hljs-ln td.hljs-ln-numbers{font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;font-size:12px;line-height:20px;vertical-align:top}table.hljs-ln td.hljs-ln-code{position:relative;padding-right:10px;padding-left:10px;overflow:visible;color:#24292e;word-wrap:normal;white-space:pre}video::-webkit-media-controls{overflow:hidden!important}video::-webkit-media-controls-enclosure{width:calc(100% + 32px);margin-left:auto}.button-cancel{color:#888;border:1px solid #888;border-radius:3px;margin-right:12px}.button-cancel,.button-primary{-ms-flex-positive:1;flex-grow:1;height:35px;display:inline-block;font-size:15px;text-align:center;line-height:36px}.button-primary{color:#fff;background-color:#fa8919;border-radius:3px}.gkui-message-content-wrap .gkui-message-close .defaultClose:after,.gkui-message-content-wrap .gkui-message-close .defaultClose:before{transition:all .3s ease}.gkui-message-content-wrap{position:relative;text-align:center}.gkui-message-content-wrap .gkui-message-content{display:inline-block;overflow:hidden;padding:10px 16px;margin-bottom:6px;background:#fff;font-size:14px;line-height:14px;border-radius:3px;box-shadow:0 1px 6px rgba(0,0,0,.2);pointer-events:all}.gkui-message-content-wrap .gkui-message-loading-prefix{display:inline-block;margin-right:4px;transform:translateY(2px)}.gkui-message-content-wrap .gkui-message-close{display:inline-block;margin-left:4px;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.gkui-message-content-wrap .gkui-message-close .defaultClose{display:inline-block;position:relative;width:10px;height:10px}.gkui-message-content-wrap .gkui-message-close .defaultClose:after,.gkui-message-content-wrap .gkui-message-close .defaultClose:before{position:absolute;top:5px;right:0;display:block;content:"";width:12px;height:1px;background:#8a8a8a}.gkui-message-content-wrap .gkui-message-close .defaultClose:before{transform:rotate(45deg)}.gkui-message-content-wrap .gkui-message-close .defaultClose:after{transform:rotate(-45deg)}.gkui-message-content-wrap .gkui-message-close .defaultClose:hover:after,.gkui-message-content-wrap .gkui-message-close .defaultClose:hover:before{background:#333}.fade-up-enter-active,.fade-up-leave-active{transition:all .4s ease}.fade-up-enter,.fade-up-leave-to{opacity:0;transform:translateY(-50%)}.fade-up-leave-to{height:0}.gkui-message-content-wrap .gkui-message-info{border:1px solid #ddd}.gkui-message-content-wrap .gkui-message-success{border:1px solid #666;background:#666;color:#fff}.gkui-message-content-wrap .gkui-message-error{border:1px solid rgba(0,0,0,.7);background-color:rgba(0,0,0,.7);color:#fff}.iconfont{font-family:iconfont!important;font-size:16px;font-style:normal;-webkit-font-smoothing:antialiased;-webkit-text-stroke-width:.2px;-moz-osx-font-smoothing:grayscale}html{background:#fff;min-height:100%;-webkit-tap-highlight-color:rgba(0,0,0,0)}body{width:100%}body.fixed{overflow:hidden;position:fixed;width:100vw;height:100vh}i{font-style:normal}a{word-wrap:break-word;-webkit-tap-highlight-color:rgba(0,0,0,0)}a:hover{text-decoration:none}.fade-enter-active,.fade-leave-active{transition:opacity .3s}.MathJax,.MathJax_CHTML,.MathJax_MathContainer,.MathJax_MathML,.MathJax_PHTML,.MathJax_PlainSource,.MathJax_SVG{outline:0}.ios-app-switch .js-audit{display:none}.gkui--modal-block-scroll{position:absolute;overflow:hidden;width:100vw}#gkui-modal-controller{width:100%}#gkui-modal-controller,.gkui-modal-layer{position:fixed;left:0;top:0;z-index:90000}.gkui-modal-layer{right:0;bottom:0;background-color:rgba(55,55,55,.3)}.fade-enter-active,.fade-leave-active{transition:all .3s ease}.fade-enter,.fade-leave-to{opacity:0}.gkui-message-list[data-v-99cd8b4a]{position:fixed;top:0;left:0;width:100%;pointer-events:none}._2sRsF5RP_0{position:relative}._loading_wrap_{position:fixed;width:100vw;height:100vh;top:50%;left:50%;transform:translate(-50%,-50%);z-index:999}._loading_div_class_,._loading_wrap_{display:-ms-flexbox;display:flex;-ms-flex-pack:center;justify-content:center;-ms-flex-align:center;align-items:center}._loading_div_class_{word-wrap:break-word;padding:.5rem .75rem;text-align:center;z-index:9999;font-size:.6rem;max-width:60%;color:#fff;border-radius:.25rem;-ms-flex-direction:column;flex-direction:column}._loading_div_class_ .message{color:#353535;font-size:16px;line-height:3}.spinner{animation:circle-rotator 1.4s linear infinite}.spinner *{line-height:0;box-sizing:border-box}@keyframes circle-rotator{0%{transform:rotate(0deg)}to{transform:rotate(270deg)}}.path{stroke-dasharray:187;stroke-dashoffset:0;transform-origin:center;animation:circle-dash 1.4s ease-in-out infinite,circle-colors 5.6s ease-in-out infinite}@keyframes circle-colors{0%{stroke:#fa8919}to{stroke:#fa8919}}@keyframes circle-dash{0%{stroke-dashoffset:187}50%{stroke-dashoffset:46.75;transform:rotate(135deg)}to{stroke-dashoffset:187;transform:rotate(450deg)}}.confirm-box-wrapper,.confirm-box-wrapper .mask{position:absolute;top:0;left:0;right:0;bottom:0}.confirm-box-wrapper .mask{background:rgba(0,0,0,.6)}.confirm-box-wrapper .confirm-box{position:fixed;top:50%;left:50%;width:267px;background:#fff;transform:translate(-50%,-50%);border-radius:7px}.confirm-box-wrapper .confirm-box .head{margin:0 18px;font-size:18px;text-align:center;line-height:65px;border-bottom:1px solid #d9d9d9}.confirm-box-wrapper .confirm-box .body{padding:18px;padding-bottom:0;color:#353535;font-size:12.5px;max-height:150px;overflow:auto}.confirm-box-wrapper .confirm-box .foot{display:-ms-flexbox;display:flex;-ms-flex-direction:row;flex-direction:row;padding:18px}.confirm-box-wrapper .confirm-box .foot .button-cancel{border:1px solid #d9d9d9}.hljs{display:block;overflow-x:auto;padding:.5em;color:#333;background:#f8f8f8}.hljs-comment,.hljs-quote{color:#998;font-style:italic}.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#333;font-weight:700}.hljs-literal,.hljs-number,.hljs-tag .hljs-attr,.hljs-template-variable,.hljs-variable{color:teal}.hljs-doctag,.hljs-string{color:#d14}.hljs-section,.hljs-selector-id,.hljs-title{color:#900;font-weight:700}.hljs-subst{font-weight:400}.hljs-class .hljs-title,.hljs-type{color:#458;font-weight:700}.hljs-attribute,.hljs-name,.hljs-tag{color:navy;font-weight:400}.hljs-link,.hljs-regexp{color:#009926}.hljs-bullet,.hljs-symbol{color:#990073}.hljs-built_in,.hljs-builtin-name{color:#0086b3}.hljs-meta{color:#999;font-weight:700}.hljs-deletion{background:#fdd}.hljs-addition{background:#dfd}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}</style><style type="text/css">.hljs-ln{border-collapse:collapse}.hljs-ln td{padding:0}.hljs-ln-n:before{content:attr(data-line-number)}</style><style type="text/css">._3ADRghFH_0{background:#000}._21xvFvr7_0{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}._3O_7qs2p_0{opacity:0}._2q1SuvsS_0{opacity:1}._20-cXID6_0{max-width:46.25rem;min-height:100vh;margin:0 auto;background:#fff;-webkit-transition:background-color .3s ease;transition:background-color .3s ease}._20-cXID6_0 .PYIrCCrf_0{color:#888}._20-cXID6_0 ._1EUVUUrC_0,._20-cXID6_0 .PYIrCCrf_0{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;height:35px;display:inline-block;font-size:15px;text-align:center;line-height:36px}._20-cXID6_0 ._1EUVUUrC_0{color:#fff;background-color:#fa8919;font-weight:500}._20-cXID6_0 ._2QmGFWqF_0{padding-left:22px;padding-right:15px}._20-cXID6_0 ._3lTiSebX_0{color:#fa8919;font-size:15px;font-weight:600;line-height:24px;border-radius:5px;padding:12px;background-color:#f6f7fb;margin-top:20px}._20-cXID6_0 ._3lTiSebX_0 ._7OuU9_xM_0{font-size:12px}._20-cXID6_0 ._50pDbNcP_0{padding-top:22px;padding-bottom:82px}._20-cXID6_0 .vJXgmLTi_0{color:#353535;font-weight:700;line-height:30px;font-size:22px;display:-webkit-box;-webkit-line-clamp:2;-webkit-box-orient:vertical;overflow:hidden;text-overflow:ellipsis}._20-cXID6_0 ._2LbT9q3y_0{color:#888;font-size:13px;font-weight:400;margin-top:4px;margin-bottom:12px}._20-cXID6_0 ._2LbT9q3y_0 ._3FoXPaWx_0{margin-top:10px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;-webkit-box-align:center;-ms-flex-align:center;align-items:center;overflow:hidden}._20-cXID6_0 ._2LbT9q3y_0 ._3FoXPaWx_0 .YLYfWxsg_0{color:#404040;font-size:15px;font-weight:400;min-width:0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}._20-cXID6_0 ._2LbT9q3y_0 ._3FoXPaWx_0 .nJKayDbe_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-left:10px;height:23px;border-radius:23px;font-size:13px;font-weight:400;color:#fa8919;padding-left:10px;padding-right:6px;background:#fbf5ee;white-space:nowrap}._20-cXID6_0 ._2LbT9q3y_0 ._3FoXPaWx_0 .nJKayDbe_0 ._2k8p2GLU_0{margin-left:2px;font-size:12px;-webkit-transform:scale(.7);transform:scale(.7)}._20-cXID6_0 ._3Jbcj4Iu_0._3BZBHEhm_0 video-webkit-media-controls-fullscreen-button{display:none}._20-cXID6_0 ._1-ZfmNK8_0{border-radius:6px;vertical-align:top;margin-bottom:24px;width:100%}._20-cXID6_0 ._3IatBmhv_0{margin-top:0}._20-cXID6_0 ._22WJb59B_0{color:#b2b2b2;padding-bottom:20px;font-size:13px;font-weight:400}._20-cXID6_0 ._22WJb59B_0 ._3ODTLCec_0{font-size:15px}._20-cXID6_0 ._3c2GGLul_0{width:100%;margin:20px 0}._20-cXID6_0 ._3EKy7lL9_0{overflow:hidden;padding-top:10px;margin-bottom:-30px}._20-cXID6_0 ._3EKy7lL9_0 a._1EUVUUrC_0{float:right;height:20px;font-size:12px;line-height:20px;padding:4px 8px;cursor:pointer}._20-cXID6_0 ._1qhD3bdE_0{padding-top:32px;border-top:10px solid #f6f7fb;-webkit-transition:border-top .3s ease;transition:border-top .3s ease;position:relative}._20-cXID6_0 ._1qhD3bdE_0 h2{color:#404040;position:relative;z-index:1;margin-bottom:1rem;font-weight:700;font-size:19px}._20-cXID6_0 ._1qhD3bdE_0 ._2FC_cD1O_0{font-size:16px;margin-left:5px}._20-cXID6_0 ._2-nZIZjB_0{position:absolute;z-index:2;background:#fa8919;font-size:13px;color:#fff;text-align:center;height:28px;width:80px;line-height:28px;-webkit-box-shadow:4px 5px 20px 1px rgba(250,137,25,.24);box-shadow:4px 5px 20px 1px rgba(250,137,25,.24);border-radius:28px;right:22px;top:32px}._20-cXID6_0 .YGjSYR8B_0{z-index:10;cursor:pointer}._20-cXID6_0 ._2DmyW7ex_0{cursor:pointer;padding-top:24px;padding-bottom:24px;position:relative}._20-cXID6_0 ._2DmyW7ex_0:before{content:" ";height:.5px;background:#e8e8e8;position:absolute;top:0;left:0;-webkit-box-sizing:border-box;box-sizing:border-box;left:22px;right:22px}._20-cXID6_0 ._2DmyW7ex_0 ._1M5b-cvc_0{height:38px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center}._20-cXID6_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3l55W_ak_0{-webkit-box-flex:0;-ms-flex:0 0 62px;flex:0 0 62px;text-align:center;color:#888;font-size:14px;border-radius:10px;height:22px;line-height:22px;background:#f6f7fb;font-weight:400}._20-cXID6_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3Ov-zF0e_0{margin-left:10px;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;color:#888;font-size:15px;height:22px;line-height:22px;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;font-weight:400}.ZphmEful_0{height:60px;background:transparent}._2zq_fmRg_0{font-size:15px;color:#888;line-height:24px;border-left:3px solid #e8e8e8;padding-left:15px}._3uTMOfKI_0,._24nFYvU9_0{-webkit-transition:all .3s ease;transition:all .3s ease}._3WwMT2EY_0 ._1uEolA82_0,._9b3gTd1B_0 ._2NnvkXgw_0{-webkit-transform:translateX(-508px);transform:translateX(-508px)}._3WwMT2EY_0 ._2NnvkXgw_0,._9b3gTd1B_0 ._1uEolA82_0{-webkit-transform:translateX(508px);transform:translateX(508px)}._3BZBHEhm_0 ._2LbT9q3y_0{font-weight:700}._3BZBHEhm_0 ._2DmyW7ex_0:before{height:1px}@media only screen and (max-width:769px){._15u7cU5H_0{display:none!important}}@media only screen and (min-width:740px){._3ADRghFH_0{background:#fff}}.g78dTtKm_0{background:#f6f0e0}.g78dTtKm_0 ._1qhD3bdE_0{border-top:10px solid #efe6cf}.g78dTtKm_0 ._2DmyW7ex_0:before{background:#e5d8b5}.g78dTtKm_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3l55W_ak_0{background:#efe6cf}.g78dTtKm_0 ._3lTiSebX_0{background-color:#efe6cf}._3uMzBYfb_0{background:#353535}._3uMzBYfb_0 ._2LbT9q3y_0,._3uMzBYfb_0 .vJXgmLTi_0{color:silver}._3uMzBYfb_0 ._1qhD3bdE_0{border-top:10px solid #3e3e3e}._3uMzBYfb_0 ._2DmyW7ex_0:before{background:#4c4c4c}._3uMzBYfb_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3l55W_ak_0{background:#3e3e3e;color:silver}._3uMzBYfb_0 ._1qhD3bdE_0 h2,._3uMzBYfb_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3Ov-zF0e_0{color:silver}._3uMzBYfb_0 ._3lTiSebX_0{background-color:#3e3e3e}._25ls2Q2l_0{margin-bottom:24px}._4ikL8tnR_0{padding-top:40px!important}.gpDqvVI7_0{position:fixed;top:0;bottom:0;width:100%;z-index:-1}</style><style type="text/css">._352wsGxH_0{height:63px}.Wz6esVdU_0{width:100%;height:63px;background:#fff;position:fixed;top:0;left:0;z-index:20;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 13px;-webkit-box-shadow:0 2px 3px 0 hsla(0,0%,89%,.38);box-shadow:0 2px 3px 0 hsla(0,0%,89%,.38)}._28dOln0j_0{height:40px;width:110px;background-size:110px;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;cursor:pointer}._1k9ecCKw_0{width:30px;height:30px;padding-top:4px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:start;-ms-flex-pack:start;justify-content:start;font-size:14px;color:#444;margin-left:10px;cursor:pointer}._1U_jCCZU_0{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}._3oCJiu8W_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:0 13px;background:#fbf5ee;border-radius:15px;height:30px}._7Xrmrbox_0,.gBs4U5qC_0,.JjI7sqpW_0{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;color:#fa8919;font-size:13px;font-weight:500;cursor:pointer}.JjI7sqpW_0{font-size:14px}._3lsV2-l9_0{height:13px;width:1px;background:#fa8919;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;margin-left:10px;margin-right:10px}._1UaW_Eq1_0{position:fixed;top:0;bottom:0;left:0;right:0;z-index:21;background:#fff;-webkit-transform:translateY(-20px);transform:translateY(-20px);opacity:0;visibility:hidden;-webkit-transition:all .3s ease;transition:all .3s ease}._1UaW_Eq1_0._2mIjHHvm_0{-webkit-transform:translateY(0);transform:translateY(0);opacity:1;visibility:visible}._1qHJ5OLn_0{height:63px;-ms-flex-align:center;padding-left:15px;padding-right:15px;-webkit-box-shadow:0 2px 3px 0 hsla(0,0%,89%,.38);box-shadow:0 2px 3px 0 hsla(0,0%,89%,.38)}._1qHJ5OLn_0,._2FYmyQEJ_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;align-items:center}._2FYmyQEJ_0{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;height:35px;-ms-flex-align:center;border-radius:20px;padding-left:20px;padding-right:20px}._1CLulytQ_0{font-size:14px;color:#b2b2b2}._1reF0JJk_0{height:20px;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;margin-left:10px}._1reF0JJk_0 input{background:transparent;border:0;color:#353535;height:20px;line-height:20px;font-size:14px;width:100%;vertical-align:top;outline:none}._33xQ4nNG_0{font-size:16px;font-weight:400;color:#b2b2b2;height:30px;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;margin-left:20px}._1y_WRr3L_0{font-size:18px}._1y_WRr3L_0 ._2HnUZhdg_0{color:#888;font-weight:400;padding-left:28px;height:63px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-bottom:1px solid #eee}._1y_WRr3L_0 ._2HnUZhdg_0._1r7t-t9P_0{color:#fa8919}._3IeMxVb7_0{position:absolute;bottom:40px;left:0;width:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-ms-flex-pack:distribute;justify-content:space-around}._3IeMxVb7_0 ._2HnUZhdg_0{position:relative;padding-top:46px;color:#888}._3IeMxVb7_0 ._339_Pvt6_0{position:absolute;color:#c3c3c3;height:46px;width:100%;display:-webkit-box;display:-ms-flexbox;display:flex;font-size:36px;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;top:0;left:0}</style><style type="text/css">._2SACi4xg_0{line-height:0}._2SACi4xg_0 img{vertical-align:top;margin-left:20px;opacity:.5}</style><style type="text/css">._1Bg5E78Y_0{width:100%;height:60px;background:#fff;-webkit-transition:background-color .3s ease;transition:background-color .3s ease;-webkit-box-sizing:border-box;box-sizing:border-box;padding-left:18px;padding-right:12px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;border-radius:6px 30px 30px 6px;-webkit-box-shadow:0 3px 25px 4px rgba(140,163,191,.14);box-shadow:0 3px 25px 4px rgba(140,163,191,.14)}._1Bg5E78Y_0 ._2Ha38TVL_0{border-radius:50%;width:40px;height:40px;-webkit-box-shadow:0 1px 3px 2px rgba(0,0,0,.1);box-shadow:0 1px 3px 2px rgba(0,0,0,.1);position:relative}._1Bg5E78Y_0 ._1iA2uC1V_0{background-repeat:no-repeat;background-position:0 0;background-size:300px;background-color:#fff;border-radius:50%;width:40px;height:40px;position:absolute;top:0;left:0}._1Bg5E78Y_0 ._1WF5YSBJ_0{background:rgba(0,0,0,.15)}._1Bg5E78Y_0 ._2Kms_g0F_0{width:40px;height:40px;line-height:40px;text-align:center;border-radius:50%;z-index:2;position:relative}._1Bg5E78Y_0 .MH1rcCm7_0 ._2Kms_g0F_0{color:#fff;margin-left:2px}._1Bg5E78Y_0 ._1KuRDTHn_0 ._2Kms_g0F_0{color:#fff}._1Bg5E78Y_0 .MH1rcCm7_0 ._1iA2uC1V_0{-webkit-animation:HvzpPu2i_0 4s linear infinite;animation:HvzpPu2i_0 4s linear infinite;-webkit-animation-play-state:paused;animation-play-state:paused}._1Bg5E78Y_0 ._1KuRDTHn_0 ._1iA2uC1V_0{-webkit-animation:HvzpPu2i_0 4s linear infinite;animation:HvzpPu2i_0 4s linear infinite;-webkit-animation-play-state:running;animation-play-state:running}._1Bg5E78Y_0 ._1qj_iPD7_0{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;overflow:hidden;margin-right:10px}._1Bg5E78Y_0 ._1qj_iPD7_0 h3{color:#404040;font-size:15.25px;margin:0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}._1Bg5E78Y_0 ._1qj_iPD7_0 p{margin:0;margin-top:.125rem;font-size:12px;font-weight:500;line-height:1rem;color:#999}._1Bg5E78Y_0 ._3PhVtlEa_0{width:20px;height:20px;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;position:relative;color:#999;font-size:18px;line-height:20px;text-align:center;margin-right:20px}._1Bg5E78Y_0 ._1l6e3976_0{width:10px;height:10px;line-height:10px;text-align:center;position:absolute;bottom:-3px;right:-5px;color:#6c0;background:#fff;font-size:10px;-webkit-transition:background-color .2s ease;transition:background-color .2s ease}._1W0qSnju_0{-webkit-box-shadow:0 3px 25px 4px hsla(42,28%,65%,.14);box-shadow:0 3px 25px 4px hsla(42,28%,65%,.14)}._1W0qSnju_0,._1W0qSnju_0 ._1l6e3976_0{background:#f6f0e0}._1W0qSnju_0 ._2Ha38TVL_0{-webkit-box-shadow:0 1px 2px 2px hsla(42,28%,65%,.14);box-shadow:0 1px 2px 2px hsla(42,28%,65%,.14)}._2SRR-E_O_0{background:#4d4d4d;-webkit-box-shadow:none;box-shadow:none}._2SRR-E_O_0 ._3PhVtlEa_0{color:#fff}._2SRR-E_O_0 ._1l6e3976_0{background:#4d4d4d}._2SRR-E_O_0 ._1qj_iPD7_0 h3,._2SRR-E_O_0 ._1qj_iPD7_0 p{color:silver}._2vBNygJQ_0 ._1qj_iPD7_0 p{font-weight:700}@-webkit-keyframes HvzpPu2i_0{to{-webkit-transform:rotate(1turn);transform:rotate(1turn)}}@keyframes HvzpPu2i_0{to{-webkit-transform:rotate(1turn);transform:rotate(1turn)}}</style><style type="text/css">._29HP61GA_0{font-weight:400;color:#353535;line-height:1.76;white-space:normal;word-break:normal;font-size:17px;-webkit-transition:background-color .3s ease;transition:background-color .3s ease}._29HP61GA_0 .MathJax_Display{overflow:auto}._29HP61GA_0 .poster{position:fixed;left:-10000px;top:-10000px;overflow:hidden;padding:1rem;background:#ececec}._29HP61GA_0 .richcontent-pre-copy{font-size:13px;color:#888;position:absolute;right:1em;top:.5em;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}._29HP61GA_0 .richcontent-pre-copy .iconfont{font-size:12px;margin-right:.2em}._29HP61GA_0 a{color:#fa8919;border-bottom:1px solid #fa8919}._29HP61GA_0 img{display:block;max-width:100%;position:relative;left:50%;-webkit-transform:translateX(-50%);transform:translateX(-50%);background-color:#eee;vertical-align:top;border-radius:0}._29HP61GA_0 audio,._29HP61GA_0 video{width:100%;background-color:#eee}._29HP61GA_0 pre{margin-top:16px;padding:34px 0 0;margin-bottom:30px;position:relative;border-radius:6px;background:rgba(246,247,251,.749);border:0}._29HP61GA_0 pre code{font-size:12px;font-family:Consolas,Liberation Mono,Menlo,monospace,Courier;display:block;-webkit-box-sizing:border-box;box-sizing:border-box;margin-left:16px;margin-right:16px;overflow-x:scroll}._29HP61GA_0 pre code:after{content:"";height:30px;width:100%;display:block}._29HP61GA_0 hr{border:none;margin-top:1.5rem;margin-bottom:1.5rem;border-top:1px solid #f5f5f5;height:1px;background:none}._29HP61GA_0 h1,._29HP61GA_0 h2,._29HP61GA_0 h3,._29HP61GA_0 h4,._29HP61GA_0 h5{margin-bottom:20px;margin-top:0;font-weight:700;color:#353535}._29HP61GA_0 b,._29HP61GA_0 strong{font-weight:700;color:#353535}._29HP61GA_0 h1{font-size:21px}._29HP61GA_0 h2{font-size:20px}._29HP61GA_0 h3{font-size:19px}._29HP61GA_0 h4{font-size:18px}._29HP61GA_0 h5{font-size:17px}._29HP61GA_0 center,._29HP61GA_0 p{font-weight:400;color:#353535;margin-top:0;margin-bottom:30px;word-break:break-word}._29HP61GA_0 center{text-align:center}._29HP61GA_0 blockquote{margin-top:0;margin-bottom:34px;border-left:3px solid #e8e8e8;padding-left:17px;color:#353535}._29HP61GA_0 blockquote p{margin-top:0;margin-bottom:0}._29HP61GA_0 ol,._29HP61GA_0 ul{margin-bottom:30px}._29HP61GA_0 ol p,._29HP61GA_0 ul p{margin-top:0;margin-bottom:0}._29HP61GA_0 ol{list-style:decimal;margin-left:20px}._29HP61GA_0 ul li{padding-left:17px;position:relative;margin-bottom:10px}._29HP61GA_0 ul li:after{content:"";height:6px;width:6px;border-radius:50%;background:#353535;position:absolute;top:10px;left:0}._29HP61GA_0 .orange{color:#fa8919}._29HP61GA_0 .reference{color:#888}._29HP61GA_0 .m-right{text-align:right}._29HP61GA_0 .m-center{text-align:center;display:block}._29HP61GA_0 .m-gray{color:#888}._29HP61GA_0 .m-small{font-size:15px}._29HP61GA_0 table.hljs-ln{margin-bottom:0;border-spacing:0;border-collapse:collapse}._29HP61GA_0 table.hljs-ln,._29HP61GA_0 table.hljs-ln tbody,._29HP61GA_0 table.hljs-ln td,._29HP61GA_0 table.hljs-ln tr{-webkit-box-sizing:border-box;box-sizing:border-box}._29HP61GA_0 table.hljs-ln td{padding:0;border:0}._29HP61GA_0 table.hljs-ln td.hljs-ln-numbers{min-width:15px;font-size:12px;color:rgba(27,31,35,.3);text-align:right;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}._29HP61GA_0 table.hljs-ln td.hljs-ln-code,._29HP61GA_0 table.hljs-ln td.hljs-ln-numbers{font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;line-height:20px;vertical-align:top}._29HP61GA_0 table.hljs-ln td.hljs-ln-code{position:relative;padding-right:10px;padding-left:10px;overflow:visible;font-size:13px;color:#666;word-wrap:normal;white-space:pre}._2gMcXXSK_0{font-size:15px}._2gMcXXSK_0 h1{font-size:19px}._2gMcXXSK_0 h2{font-size:18px}._2gMcXXSK_0 h3{font-size:17px}._2gMcXXSK_0 h4{font-size:16px}._2gMcXXSK_0 h5{font-size:15px}._2gMcXXSK_0 p{margin-bottom:26px}._2gMcXXSK_0 blockquote{margin-bottom:30px}._2gMcXXSK_0 ol,._2gMcXXSK_0 ul{margin-bottom:26px}._2gMcXXSK_0 .m-small{font-size:13px}._1-IhkAAb_0{font-size:19px}._1-IhkAAb_0 h1{font-size:23px}._1-IhkAAb_0 h2{font-size:22px}._1-IhkAAb_0 h3{font-size:21px}._1-IhkAAb_0 h4{font-size:20px}._1-IhkAAb_0 h5{font-size:19px}._1-IhkAAb_0 .m-small{font-size:17px}._1Xjr5LRK_0 table.hljs-ln td.hljs-ln-code,._1Xjr5LRK_0 table.hljs-ln td.hljs-ln-numbers{font-family:monospace}._1XhbM4Sp_0 pre{background:hsla(43,50%,87%,.749)}._1XhbM4Sp_0 blockquote{border-color:#efe6cf}._2wERfXHe_0 h1,._2wERfXHe_0 h2,._2wERfXHe_0 h3,._2wERfXHe_0 h4,._2wERfXHe_0 h5,._2wERfXHe_0 p{color:silver}._2wERfXHe_0 blockquote{border-color:#3e3e3e}._2wERfXHe_0 li,._2wERfXHe_0 strong{color:silver}._2wERfXHe_0 pre{background:rgba(62,62,62,.749)}._2wERfXHe_0 center{color:silver}._2wERfXHe_0 img{opacity:.9}._2wERfXHe_0 ul li:after{background:silver}._2wERfXHe_0 table.hljs-ln td.hljs-ln-numbers{color:#b2b2b2}._2wERfXHe_0 table.hljs-ln td.hljs-ln-code{color:silver}</style><style type="text/css">.reJj6Thl_0{list-style-position:inside;width:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin-top:40px}.reJj6Thl_0 a{border-bottom:none}.reJj6Thl_0 ._2273kGdT_0{width:35px;height:35px;-ms-flex-negative:0;flex-shrink:0;border-radius:50%}.reJj6Thl_0:last-child ._2CG0SquK_0{border-bottom:none}.reJj6Thl_0 ._2CG0SquK_0{margin-left:.5rem;-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;padding-bottom:25px;border-bottom:.5px solid #e8e8e8;-webkit-transition:border-bottom .3s ease;transition:border-bottom .3s ease;overflow:hidden}.reJj6Thl_0 ._2CG0SquK_0 ._304R4gla_0{width:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;padding-bottom:10px}.reJj6Thl_0 ._2CG0SquK_0 ._3M6kV3zb_0{color:#4c4c4c;font-size:16px;font-weight:400;white-space:normal;word-break:normal;line-height:1.6;overflow:hidden;display:-webkit-box;-webkit-line-clamp:5;-webkit-box-orient:vertical}.reJj6Thl_0 ._2CG0SquK_0 ._3D2NkqD6_0{overflow:auto;-webkit-line-clamp:unset}.reJj6Thl_0 ._2CG0SquK_0 ._1H1Z49Dr_0{color:#888;font-size:11px;line-height:1;margin-top:4px}.reJj6Thl_0 ._2CG0SquK_0 ._18Dng5rT_0{color:#353535;font-size:14px;font-weight:700;height:20px;line-height:20px}.reJj6Thl_0 ._1bkbsnjg_0{height:15px;line-height:15px;width:30px;overflow:hidden;font-size:10px;color:#fff;background:#cbcbcb;text-align:center;display:inline-block;border-radius:3px;vertical-align:top;margin-top:2px}.reJj6Thl_0 ._2eMTs2JE_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:26px}.reJj6Thl_0 ._1YQBH3WC_0{color:#999;font-size:13px;margin-left:42px;width:20px;text-align:center}.reJj6Thl_0 ._13n1j2Zp_0{color:#999;font-size:11px;width:20px;margin-left:38px;text-align:center}.reJj6Thl_0 ._2P4B1Hdm_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;font-size:15.25px;text-decoration:none}.reJj6Thl_0 ._2P4B1Hdm_0 i{color:#999;display:inline-block;font-size:15px;margin-right:4px;height:27px;width:15px;margin-top:-2px}.reJj6Thl_0 ._2P4B1Hdm_0 i._2A421P4G_0background-size:15px}.reJj6Thl_0 ._2P4B1Hdm_0 span{color:#888;font-size:13px;font-weight:400}.reJj6Thl_0 ._2P4B1Hdm_0 span._2A421P4G_0{color:#fa8919}.reJj6Thl_0 ._2r3UB1GX_0{font-size:13px;color:#b2b2b2;height:16px;padding-top:8px}.reJj6Thl_0 ._2r3UB1GX_0 span{font-weight:500}.reJj6Thl_0 ._2r3UB1GX_0 i,.reJj6Thl_0 ._2r3UB1GX_0 span{height:16px;line-height:16px;display:inline-block;vertical-align:top}.reJj6Thl_0 ._2xNIY4NG_0{margin-top:10px}.reJj6Thl_0 ._2xNIY4NG_0 ._33BLbmw4_0{color:#888;font-size:14px;font-weight:400;white-space:normal;word-break:normal;background:#f6f7fb;-webkit-transition:background .3s ease;transition:background .3s ease;border-radius:10px;padding:18px;overflow-x:scroll}.reJj6Thl_0 ._2xNIY4NG_0 ._1H1Z49Dr_0{color:#888;font-size:9px}._0X_LEcd_0 ._2xNIY4NG_0 ._33BLbmw4_0{background:#efe6cf}.cGm0Q9aA_0 ._2CG0SquK_0{border-bottom:1px solid #4c4c4c}.cGm0Q9aA_0 ._2CG0SquK_0 ._1H1Z49Dr_0,.cGm0Q9aA_0 ._2CG0SquK_0 ._3M6kV3zb_0,.cGm0Q9aA_0 ._2CG0SquK_0 ._18Dng5rT_0{color:silver}.cGm0Q9aA_0 ._2xNIY4NG_0 ._33BLbmw4_0{color:silver;background:#3e3e3e}.cGm0Q9aA_0 ._1YQBH3WC_0,.cGm0Q9aA_0 ._2P4B1Hdm_0 i,.cGm0Q9aA_0 ._2P4B1Hdm_0 span,.cGm0Q9aA_0 ._13n1j2Zp_0{color:#999}._2Gn7zqLg_0 ._1bkbsnjg_0{line-height:18px}</style>
    <script id="savepage-contentloaders" type="application/javascript">
      "use strict"
      savepage_ContentLoaders();
      function savepage_ContentLoaders()
      {
        var resourceMimeType = new Array();
        var resourceBase64Data = new Array();
        var resourceBlobUrl = new Array();
        window.addEventListener("DOMContentLoaded",
        function(event)
        {
          savepage_ShadowLoader(5);
          savepage_ResourceLoader(5);
          document.getElementById('savepage-contentloaders').remove();
        },false);
        function savepage_ShadowLoader(c){createShadowDOMs(0,document.documentElement);function createShadowDOMs(a,b){var i;if(b.localName=="iframe"||b.localName=="frame"){if(a<c){try{if(b.contentDocument.documentElement!=null){createShadowDOMs(a+1,b.contentDocument.documentElement)}}catch(e){}}}else{if(b.children.length>=1&&b.children[0].localName=="template"&&b.children[0].hasAttribute("data-savepage-shadowroot")){b.attachShadow({mode:"open"}).appendChild(b.children[0].content);b.removeChild(b.children[0]);for(i=0;i<b.shadowRoot.children.length;i++)if(b.shadowRoot.children[i]!=null)createShadowDOMs(a,b.shadowRoot.children[i])}for(i=0;i<b.children.length;i++)if(b.children[i]!=null)createShadowDOMs(a,b.children[i])}}}
        function savepage_ResourceLoader(f){createBlobURLs();replaceReferences(0,document.documentElement);function createBlobURLs(){var i,j,binaryString,blobData;var a=new Array();for(i=0;i<resourceMimeType.length;i++){if(typeof resourceMimeType[i]!="undefined"){binaryString=atob(resourceBase64Data[i]);resourceBase64Data[i]="";a.length=0;for(j=0;j<binaryString.length;j++){a[j]=binaryString.charCodeAt(j)}blobData=new Blob([new Uint8Array(a)],{type:resourceMimeType[i]});resourceMimeType[i]="";resourceBlobUrl[i]=window.URL.createObjectURL(blobData)}}}function replaceReferences(a,b){var i,regex1,regex2,csstext,blobData;regex1=/url\(\s*((?:"[^"]+")|(?:'[^']+')|(?:[^\s)]+))\s*\)/gi;regex2=/data:[^;]*;if(b.hasAttribute("style")){csstext=b.style.cssText;b.style.cssText=csstext.replace(regex1,replaceCSSRef)}if(b.localName=="style"){csstext=b.textContent;b.textContent=csstext.replace(regex1,replaceCSSRef)}else if(b.localName=="link"&&(b.rel.toLowerCase()=="icon"||b.rel.toLowerCase()=="shortcut icon")){if(b.href!="")b.href=b.href.replace(regex2,replaceRef)}else if(b.localName=="body"){if(b.background!="")b.background=b.background.replace(regex2,replaceRef)}else if(b.localName=="img"){if(b.src!="")b.src=b.src.replace(regex2,replaceRef)}else if(b.localName=="input"&&b.type.toLowerCase()=="image"){if(b.src!="")b.src=b.src.replace(regex2,replaceRef)}else if(b.localName=="audio"){if(b.src!=""){b.src=b.src.replace(regex2,replaceRef);b.load()}}else if(b.localName=="video"){if(b.src!=""){b.src=b.src.replace(regex2,replaceRef);b.load()}if(b.poster!="")b.poster=b.poster.replace(regex2,replaceRef)}else if(b.localName=="source"){if(b.src!=""){b.src=b.src.replace(regex2,replaceRef);b.parentElement.load()}}else if(b.localName=="track"){if(b.src!="")b.src=b.src.replace(regex2,replaceRef)}else if(b.localName=="object"){if(b.data!="")b.data=b.data.replace(regex2,replaceRef)}else if(b.localName=="embed"){if(b.src!="")b.src=b.src.replace(regex2,replaceRef)}if(b.localName=="iframe"||b.localName=="frame"){if(a<f){if(b.hasAttribute("data-savepage-sameorigin")){blobData=new Blob([decodeURIComponent(b.src.substr(29))],{type:"text/html;charset=utf-8"});b.onload=function(){try{if(b.contentDocument.documentElement!=null){replaceReferences(a+1,b.contentDocument.documentElement)}}catch(e){}};b.src=window.URL.createObjectURL(blobData)}}}else{if(b.shadowRoot!=null){for(i=0;i<b.shadowRoot.children.length;i++)if(b.shadowRoot.children[i]!=null)replaceReferences(a,b.shadowRoot.children[i])}for(i=0;i<b.children.length;i++)if(b.children[i]!=null)replaceReferences(a,b.children[i])}}function replaceCSSRef(a,b,c,d){var e=new Array();e=b.match(/data:[^;]*;resource=(\d+);base64,/i);if(e!=null)return"url("+resourceBlobUrl[+e[1]]+")";else return a}function replaceRef(a,b,c,d){return resourceBlobUrl[+b]}}
        
      }
    </script>
    
    <meta name="savepage-title" content="极客时间 | 数据分析实战45讲">
    <meta name="savepage-date" content="Wed Jun 05 2019 03:50:12 GMT+0800 (中国标准时间)">
    <meta name="savepage-state" content="Standard Items; Used resource loader; Retained cross-origin frames; Removed unsaved URLs; Max frame depth = 5; Max resource size = 50MB; Max resource time = 10s;">
    <meta name="savepage-version" content="15.0">
    <meta name="savepage-comments" content="">
    <meta name="savepage-resourceloader" content=""></head><body><div id="app"><div class="_3ADRghFH_0" style="background-color: rgb(255, 255, 255);"><div class="gpDqvVI7_0" style="background-color: rgb(255, 255, 255);"></div> <div class="_20-cXID6_0" style="opacity: 1;"><div class="_3O_7qs2p_0 _2q1SuvsS_0"> <!----> <div class="_50pDbNcP_0"><h1 class="vJXgmLTi_0 _2QmGFWqF_0">
        35丨AdaBoost（下）：如何使用AdaBoost对房价进行预测？
      </h1> <div class="_2LbT9q3y_0 _2QmGFWqF_0"><span>2019-03-04</span> <span>陈旸</span> <div class="_3FoXPaWx_0"><span class="YLYfWxsg_0">数据分析实战45讲</span> <div class="nJKayDbe_0"><span>进入课程</span> <div class="_2k8p2GLU_0 iconfont"></div></div></div></div> <div class="_3Jbcj4Iu_0 _2QmGFWqF_0"><img src="https://static001.geekbang.org/resource/image/9d/f9/9ddbc3ac41c6e22c857c9ce2cfeb47f9.jpg"  class="_1-ZfmNK8_0"> <div class="_2SACi4xg_0"></div> <!----> <div class="_1Bg5E78Y_0 _25ls2Q2l_0"><div class="_1qj_iPD7_0"><h3>讲述：陈旸</h3> <p><span style="margin-right: 3px;">时长</span><span style="margin-right: 10px;">08:37</span><span style="margin-right: 3px;">大小</span><span>7.90M</span></p></div> <!----> <div class="_2Ha38TVL_0 MH1rcCm7_0"> <div class="_1iA2uC1V_0 _1WF5YSBJ_0"></div> <div class="iconfont _2Kms_g0F_0"></div></div> <audio title="35丨AdaBoost（下）：如何使用AdaBoost对房价进行预测？" src="https://res001.geekbang.org//media/audio/f8/be/f843e0c85e8c96488000c2c6a0ffffbe/ld/ld.m3u8" ></audio></div> <div class="_3IatBmhv_0"><div class="_29HP61GA_0"><p>今天我带你用 AdaBoost 算法做一个实战项目。AdaBoost 不仅可以用于分类问题，还可以用于回归分析。</p><p>我们先做个简单回忆，什么是分类，什么是回归呢？实际上分类和回归的本质是一样的，都是对未知事物做预测。不同之处在于输出结果的类型，分类输出的是一个离散值，因为物体的分类数有限的，而回归输出的是连续值，也就是在一个区间范围内任何取值都有可能。</p><p>这次我们的主要目标是使用 AdaBoost 预测房价，这是一个回归问题。除了对项目进行编码实战外，我希望你能掌握：</p><ol>
<li>
<p>AdaBoost 工具的使用，包括使用 AdaBoost 进行分类，以及回归分析。</p>
</li>
<li>
<p>使用其他的回归工具，比如决策树回归，对比 AdaBoost 回归和决策树回归的结果。</p>
</li>
</ol><h2>如何使用 AdaBoost 工具</h2><p>我们可以直接在 sklearn 中使用 AdaBoost。如果我们要用 AdaBoost 进行分类，需要在使用前引用代码：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.ensemble import AdaBoostClassifier</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>我们之前讲到过，如果你看到了 Classifier 这个类，一般都会对应着 Regressor 类。AdaBoost 也不例外，回归工具包的引用代码如下：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.ensemble import AdaBoostRegressor</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>我们先看下如何在 sklearn 中创建 AdaBoost 分类器。</p><!-- [[[read_end]]] --><p>我们需要使用 AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm=’SAMME.R’, random_state=None) 这个函数，其中有几个比较主要的参数，我分别来讲解下：</p><ol>
<li>
<p>base_estimator：代表的是弱分类器。在 AdaBoost 的分类器和回归器中都有这个参数，在 AdaBoost 中默认使用的是决策树，一般我们不需要修改这个参数，当然你也可以指定具体的分类器。</p>
</li>
<li>
<p>n_estimators：算法的最大迭代次数，也是分类器的个数，每一次迭代都会引入一个新的弱分类器来增加原有的分类器的组合能力。默认是 50。</p>
</li>
<li>
<p>learning_rate：代表学习率，取值在 0-1 之间，默认是 1.0。如果学习率较小，就需要比较多的迭代次数才能收敛，也就是说学习率和迭代次数是有相关性的。当你调整 learning_rate 的时候，往往也需要调整 n_estimators 这个参数。</p>
</li>
<li>
<p>algorithm：代表我们要采用哪种 boosting 算法，一共有两种选择：SAMME 和 SAMME.R。默认是 SAMME.R。这两者之间的区别在于对弱分类权重的计算方式不同。</p>
</li>
<li>
<p>random_state：代表随机数种子的设置，默认是 None。随机种子是用来控制随机模式的，当随机种子取了一个值，也就确定了一种随机规则，其他人取这个值可以得到同样的结果。如果不设置随机种子，每次得到的随机数也就不同。</p>
</li>
</ol><p>那么如何创建 AdaBoost 回归呢？</p><p>我们可以使用 AdaBoostRegressor(base_estimator=None, n_estimators=50, learning_rate=1.0, loss=‘linear’, random_state=None) 这个函数。</p><p>你能看出来回归和分类的参数基本是一致的，不同点在于回归算法里没有 algorithm 这个参数，但多了一个 loss 参数。</p><p>loss 代表损失函数的设置，一共有 3 种选择，分别为 linear、square 和 exponential，它们的含义分别是线性、平方和指数。默认是线性。一般采用线性就可以得到不错的效果。</p><p>创建好 AdaBoost 分类器或回归器之后，我们就可以输入训练集对它进行训练。我们使用 fit 函数，传入训练集中的样本特征值 train_X 和结果 train_y，模型会自动拟合。使用 predict 函数进行预测，传入测试集中的样本特征值 test_X，然后就可以得到预测结果。</p><h2>如何用 AdaBoost 对房价进行预测</h2><p>了解了 AdaBoost 工具包之后，我们看下 sklearn 中自带的波士顿房价数据集。</p><p>这个数据集一共包括了 506 条房屋信息数据，每一条数据都包括了 13 个指标，以及一个房屋价位。</p><p>13 个指标的含义，可以参考下面的表格：</p><p><img src="https://static001.geekbang.org/resource/image/42/b7/426dec532f34d7f458e36ee59a6617b7.png"  alt=""><br>
这些指标分析得还是挺细的，但实际上，我们不用关心具体的含义，要做的就是如何通过这 13 个指标推导出最终的房价结果。</p><p>如果你学习了之前的算法实战，这个数据集的预测并不复杂。</p><p>首先加载数据，将数据分割成训练集和测试集，然后创建 AdaBoost 回归模型，传入训练集数据进行拟合，再传入测试集数据进行预测，就可以得到预测结果。最后将预测的结果与实际结果进行对比，得到两者之间的误差。具体代码如下：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.model_selection import train_test_split</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.metrics import mean_squared_error</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.datasets import load_boston</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.ensemble import AdaBoostRegressor</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 加载数据</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">data=load_boston()</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 分割数据</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">train_x, test_x, train_y, test_y = train_test_split(data.data, data.target, test_size=0.25, random_state=33)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 使用 AdaBoost 回归模型</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">regressor=AdaBoostRegressor()</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">regressor.fit(train_x,train_y)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">pred_y = regressor.predict(test_x)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">mse = mean_squared_error(test_y, pred_y)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">print(" 房价预测结果 ", pred_y)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">print(" 均方误差 = ",round(mse,2))</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>运行结果：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">房价预测结果  [20.2        10.4137931  14.63820225 17.80322581 24.58931298 21.25076923</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 27.52222222 17.8372093  31.79642857 20.86428571 27.87431694 31.09142857</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 12.81666667 24.13131313 12.81666667 24.58931298 17.80322581 17.66333333</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 27.83       24.58931298 17.66333333 20.90823529 20.10555556 20.90823529</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 28.20877193 20.10555556 21.16882129 24.58931298 13.27619048 31.09142857</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 17.08095238 26.19217391  9.975      21.03404255 26.74583333 31.09142857</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 25.83960396 11.859375   13.38235294 24.58931298 14.97931034 14.46699029</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 30.12777778 17.66333333 26.19217391 20.10206186 17.70540541 18.45909091</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 26.19217391 20.10555556 17.66333333 33.31025641 14.97931034 17.70540541</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 24.64421053 20.90823529 25.83960396 17.08095238 24.58931298 21.43571429</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 19.31617647 16.33733333 46.04888889 21.25076923 17.08095238 25.83960396</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 24.64421053 11.81470588 17.80322581 27.63636364 23.59731183 17.94444444</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 17.66333333 27.7253886  20.21465517 46.04888889 14.97931034  9.975</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 17.08095238 24.13131313 21.03404255 13.4        11.859375   26.19214286</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 21.25076923 21.03404255 47.11395349 16.33733333 43.21111111 31.65730337</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 30.12777778 20.10555556 17.8372093  18.40833333 14.97931034 33.31025641</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 24.58931298 22.88813559 18.27179487 17.80322581 14.63820225 21.16882129</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 26.91538462 24.64421053 13.05       14.97931034  9.975      26.19217391</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 12.81666667 26.19214286 49.46511628 13.27619048 17.70540541 25.83960396</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 31.09142857 24.13131313 21.25076923 21.03404255 26.91538462 21.03404255</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 21.16882129 17.8372093  12.81666667 21.03404255 21.03404255 17.08095238</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"> 45.16666667]</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">均方误差 =  18.05</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>这个数据集是比较规范的，我们并不需要在数据清洗，数据规范化上花太多精力，代码编写起来比较简单。</p><p>同样，我们可以使用不同的回归分析模型分析这个数据集，比如使用决策树回归和 KNN 回归。</p><p>编写代码如下：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 使用决策树回归模型</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">dec_regressor=DecisionTreeRegressor()</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">dec_regressor.fit(train_x,train_y)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">pred_y = dec_regressor.predict(test_x)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">mse = mean_squared_error(test_y, pred_y)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">print(" 决策树均方误差 = ",round(mse,2))</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 使用 KNN 回归模型</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">knn_regressor=KNeighborsRegressor()</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">knn_regressor.fit(train_x,train_y)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">pred_y = knn_regressor.predict(test_x)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">mse = mean_squared_error(test_y, pred_y)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">print("KNN 均方误差 = ",round(mse,2))</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>运行结果：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">决策树均方误差 =  23.84</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">KNN 均方误差 =  27.87</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>你能看到相比之下，AdaBoost 的均方误差更小，也就是结果更优。虽然 AdaBoost 使用了弱分类器，但是通过 50 个甚至更多的弱分类器组合起来而形成的强分类器，在很多情况下结果都优于其他算法。因此 AdaBoost 也是常用的分类和回归算法之一。</p><h2>AdaBoost 与决策树模型的比较</h2><p>在 sklearn 中 AdaBoost 默认采用的是决策树模型，我们可以随机生成一些数据，然后对比下 AdaBoost 中的弱分类器（也就是决策树弱分类器）、决策树分类器和 AdaBoost 模型在分类准确率上的表现。</p><p>如果想要随机生成数据，我们可以使用 sklearn 中的 make_hastie_10_2 函数生成二分类数据。假设我们生成 12000 个数据，取前 2000 个作为测试集，其余作为训练集。</p><p>有了数据和训练模型后，我们就可以编写代码。我设置了 AdaBoost 的迭代次数为 200，代表 AdaBoost 由 200 个弱分类器组成。针对训练集，我们用三种模型分别进行训练，然后用测试集进行预测，并将三个分类器的错误率进行可视化对比，可以看到这三者之间的区别：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">import numpy as np</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">import matplotlib.pyplot as plt</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn import datasets</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.metrics import zero_one_loss</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.tree import DecisionTreeClassifier</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.ensemble import  AdaBoostClassifier</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 设置 AdaBoost 迭代次数</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">n_estimators=200</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 使用</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">X,y=datasets.make_hastie_10_2(n_samples=12000,random_state=1)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 从 12000 个数据中取前 2000 行作为测试集，其余作为训练集</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">test_x, test_y = X[2000:],y[2000:]</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">train_x, train_y = X[:2000],y[:2000]</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 弱分类器</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">dt_stump = DecisionTreeClassifier(max_depth=1,min_samples_leaf=1)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">dt_stump.fit(train_x, train_y)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">dt_stump_err = 1.0-dt_stump.score(test_x, test_y)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 决策树分类器</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">dt = DecisionTreeClassifier()</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">dt.fit(train_x,  train_y)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">dt_err = 1.0-dt.score(test_x, test_y)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># AdaBoost 分类器</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">ada = AdaBoostClassifier(base_estimator=dt_stump,n_estimators=n_estimators)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">ada.fit(train_x,  train_y)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 三个分类器的错误率可视化</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">fig = plt.figure()</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 设置 plt 正确显示中文</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">plt.rcParams['font.sans-serif'] = ['SimHei']</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">ax = fig.add_subplot(111)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">ax.plot([1,n_estimators],[dt_stump_err]*2, 'k-', label=u'决策树弱分类器 错误率')</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">ax.plot([1,n_estimators],[dt_err]*2,'k--', label=u'决策树模型 错误率')</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">ada_err = np.zeros((n_estimators,))</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 遍历每次迭代的结果 i 为迭代次数, pred_y 为预测结果</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">for i,pred_y in enumerate(ada.staged_predict(test_x)):</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">     # 统计错误率</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">    ada_err[i]=zero_one_loss(pred_y, test_y)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 绘制每次迭代的 AdaBoost 错误率 </div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">ax.plot(np.arange(n_estimators)+1, ada_err, label='AdaBoost Test 错误率', color='orange')</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">ax.set_xlabel('迭代次数')</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">ax.set_ylabel('错误率')</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">leg=ax.legend(loc='upper right',fancybox=True)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">plt.show()</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>运行结果：</p><p><img src="https://static001.geekbang.org/resource/image/a6/78/a63212757f4791239831e090f95ad478.png"  alt=""><br>
从图中你能看出来，弱分类器的错误率最高，只比随机分类结果略好，准确率稍微大于 50%。决策树模型的错误率明显要低很多。而 AdaBoost 模型在迭代次数超过 25 次之后，错误率有了明显下降，经过 125 次迭代之后错误率的变化形势趋于平缓。</p><p>因此我们能看出，虽然单独的一个决策树弱分类器效果不好，但是多个决策树弱分类器组合起来形成的 AdaBoost 分类器，分类效果要好于决策树模型。</p><h2>总结</h2><p>今天我带你用 AdaBoost 回归分析对波士顿房价进行了预测。因为这是个回归分析的问题，我们直接使用 sklearn 中的 AdaBoostRegressor 即可。如果是分类，我们使用 AdaBoostClassifier。</p><p>另外我们将 AdaBoost 分类器、弱分类器和决策树分类器做了对比，可以看出经过多个弱分类器组合形成的 AdaBoost 强分类器，准确率要明显高于决策树算法。所以 AdaBoost 的优势在于框架本身，它通过一种迭代机制让原本性能不强的分类器组合起来，形成一个强分类器。</p><p>其实在现实工作中，我们也能找到类似的案例。IBM 服务器追求的是单个服务器性能的强大，比如打造超级服务器。而 Google 在创建集群的时候，利用了很多 PC 级的服务器，将它们组成集群，整体性能远比一个超级服务器的性能强大。</p><p>再比如我们讲的“三个臭皮匠，顶个诸葛亮”，也就是 AdaBoost 的价值所在。</p><p><img src="https://static001.geekbang.org/resource/image/6c/17/6c4fcd75a65dc354bc65590c18e77d17.png"  alt=""><br>
今天我们用 AdaBoost 分类器与决策树分类做对比的时候，使用到了 sklearn 中的 make_hastie_10_2 函数生成数据。实际上在<a href="http://time.geekbang.org/column/article/79072">第 19 篇</a>，我们对泰坦尼克号的乘客做生存预测的时候，也讲到了决策树工具的使用。你能不能编写代码，使用 AdaBoost 算法对泰坦尼克号乘客的生存做预测，看看它和决策树模型，谁的准确率更高？</p><p>你也可以把这篇文章分享给你的朋友或者同事，一起切磋一下。</p><p><img src="https://static001.geekbang.org/resource/image/48/96/48cb89aa8c4858bbc18df3b3ac414496.jpg"  alt=""></p></div></div> <!----> <div class="_22WJb59B_0">
        </div></div> <div class="_2DmyW7ex_0 _2QmGFWqF_0"><div class="_1M5b-cvc_0"><div class="_3l55W_ak_0">上一篇</div> <div class="_3Ov-zF0e_0">34丨AdaBoost（上）：如何使用AdaBoost提升分类器性能？</div></div> <div class="_1M5b-cvc_0"><div class="_3l55W_ak_0">下一篇</div> <div class="_3Ov-zF0e_0">36丨数据分析算法篇答疑</div></div></div> <div class="_1qhD3bdE_0 _2QmGFWqF_0"><div class="iconfont _2-nZIZjB_0"> 写留言</div> <h2><span>精选留言</span><span class="_2FC_cD1O_0">(11)</span></h2> <ul><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/10/62/a5/43aa0c27.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>Destroy、</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-05</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">7</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">源代码中：<br># 从 12000 个数据中取前 2000 行作为测试集，其余作为训练集<br>test_x, test_y = X[2000:],y[2000:]<br>train_x, train_y = X[:2000],y[:2000]<br><br>这个部分的代码写错了吧<br>应该是：<br>test_x, test_y = x[: 2000], y[: 2000]<br>train_x, train_y = x[2000:], y[2000:]</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>third</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-04</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">2</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">结果仍然为AdaBoost算法最优。<br>个人发现，前两个分类器出结果很快<br>分析最优：<br>1.AdaBoost算法经过了更多运算，特别是在迭代弱分类器和组合上<br>2.良好组合起来的个体，能够创造更大的价值。<br><br>决策树弱分类器准确率为 0.7867<br>决策树分类器准确率为 0.7891<br>AdaBoost 分类器准确率为 0.8138<br><br>import numpy as np<br>import pandas as pd<br>from sklearn.model_selection import cross_val_score<br>from sklearn.tree import DecisionTreeClassifier<br>from sklearn.ensemble import AdaBoostClassifier<br>from sklearn.feature_extraction import DictVectorizer<br><br># 1.数据加载<br>train_data=pd.read_csv('./Titanic_Data/train.csv')<br>test_data=pd.read_csv('./Titanic_Data/test.csv')<br><br># 2.数据清洗<br># 使用平均年龄来填充年龄中的 NaN 值<br>train_data['Age'].fillna(train_data['Age'].mean(),inplace=True)<br>test_data['Age'].fillna(test_data['Age'].mean(),inplace=True)<br># 均价填充<br>train_data['Fare'].fillna(train_data['Fare'].mean(),inplace=True)<br>test_data['Fare'].fillna(test_data['Fare'].mean(),inplace=True)<br># 使用登陆最多的港口来填充<br>train_data['Embarked'].fillna('S',inplace=True)<br>test_data['Embarked'].fillna('S',inplace=True)<br><br># 特征选择<br>features=['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']<br>train_features=train_data[features]<br>train_labels=train_data['Survived']<br>test_features=test_data[features]<br><br># 将符号化的Embarked对象抽象处理成0/1进行表示<br>dvec=DictVectorizer(sparse=False)<br>train_features=dvec.fit_transform(train_features.to_dict(orient='record'))<br>test_features=dvec.transform(test_features.to_dict(orient='record'))<br><br># 决策树弱分类器<br>dt_stump = DecisionTreeClassifier(max_depth=1,min_samples_leaf=1)<br>dt_stump.fit(train_features, train_labels)<br><br>print(u'决策树弱分类器准确率为 %.4lf' % np.mean(cross_val_score(dt_stump, train_features, train_labels, cv=10)))<br><br># 决策树分类器<br>dt = DecisionTreeClassifier()<br>dt.fit(train_features, train_labels)<br><br>print(u'决策树分类器准确率为 %.4lf' % np.mean(cross_val_score(dt, train_features, train_labels, cv=10)))<br><br># AdaBoost 分类器<br>ada = AdaBoostClassifier(base_estimator=dt_stump,n_estimators=200)<br>ada.fit(train_features, train_labels)<br><br>print(u'AdaBoost 分类器准确率为 %.4lf' % np.mean(cross_val_score(ada, train_features, train_labels, cv=10)))</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>王彬成</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-04</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">1</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">由于乘客测试集缺失真实值，采用 K 折交叉验证准确率<br>--------------------<br>运行结果：<br>决策树弱分类器准确率为 0.7867<br>决策树分类器准确率为 0.7813<br>AdaBoost 分类器准确率为 0.8138<br>-------------------------<br>代码：<br>import numpy as np<br>from sklearn.tree import DecisionTreeClassifier<br>from sklearn.ensemble import  AdaBoostClassifier<br>import pandas as pd<br>from sklearn.feature_extraction import DictVectorizer<br>from sklearn.model_selection import cross_val_score<br><br># 设置 AdaBoost 迭代次数<br>n_estimators=200<br><br># 数据加载<br>train_data=pd.read_csv('./Titanic_Data/train.csv')<br>test_data=pd.read_csv('./Titanic_Data/test.csv')<br><br># 模块 2：数据清洗<br># 使用平均年龄来填充年龄中的 NaN 值<br>train_data['Age'].fillna(train_data['Age'].mean(),inplace=True)<br>test_data['Age'].fillna(test_data['Age'].mean(),inplace=True)<br># 使用票价的均值填充票价中的 nan 值<br>train_data['Fare'].fillna(train_data['Fare'].mean(),inplace=True)<br>test_data['Fare'].fillna(test_data['Fare'].mean(),inplace=True)<br># 使用登录最多的港口来填充登录港口Embarked的 nan 值<br>train_data['Embarked'].fillna('S',inplace=True)<br>test_data['Embarked'].fillna('S',inplace=True)<br><br># 特征选择<br>features=['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']<br>train_features=train_data[features]<br>train_labels=train_data['Survived']<br>test_features=test_data[features]<br><br># 将符号化的Embarked对象处理成0/1进行表示<br>dvec=DictVectorizer(sparse=False)<br>train_features=dvec.fit_transform(train_features.to_dict(orient='record'))<br>test_features=dvec.transform(test_features.to_dict(orient='record'))<br><br># 决策树弱分类器<br>dt_stump = DecisionTreeClassifier(max_depth=1,min_samples_leaf=1)<br>dt_stump.fit(train_features, train_labels)<br><br>print(u'决策树弱分类器准确率为 %.4lf' % np.mean(cross_val_score(dt_stump, train_features, train_labels, cv=10)))<br><br># 决策树分类器<br>dt = DecisionTreeClassifier()<br>dt.fit(train_features, train_labels)<br><br>print(u'决策树分类器准确率为 %.4lf' % np.mean(cross_val_score(dt, train_features, train_labels, cv=10)))<br><br># AdaBoost 分类器<br>ada = AdaBoostClassifier(base_estimator=dt_stump,n_estimators=n_estimators)<br>ada.fit(train_features, train_labels)<br><br>print(u'AdaBoost 分类器准确率为 %.4lf' % np.mean(cross_val_score(ada, train_features, train_labels, cv=10)))</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/12/a3/87/0cb915e2.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>滢</span> <!----></div> <div class="_1H1Z49Dr_0">2019-04-21</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">得到结果：<br>CART决策树K折交叉验证准确率: 0.39480897860892333<br>AdaBoostK折交叉验证准确率: 0.4376641797318339<br><br>from sklearn.tree import DecisionTreeRegressor<br>from sklearn.ensemble import AdaBoostRegressor<br>from sklearn.feature_extraction import DictVectorizer<br>from sklearn.model_selection import cross_val_predict<br>import pandas as pd<br>import numpy as np<br><br>#读取数据<br>path = '/Users/apple/Desktop/GitHubProject/Read mark/数据分析/geekTime/data/'<br>train_data = pd.read_csv(path + 'Titannic_Data_train.csv')<br>test_data = pd.read_csv(path + 'Titannic_Data_test.csv')<br><br>#数据清洗<br>train_data['Age'].fillna(train_data['Age'].mean(),inplace=True)<br>test_data['Age'].fillna(test_data['Age'].mean(), inplace=True)<br>train_data['Embarked'].fillna('S', inplace=True)<br>test_data['Embarked'].fillna('S', inplace=True)<br><br>#特征选择<br>features = ['Pclass','Sex','Age','SibSp','Parch','Embarked']<br>train_features = train_data[features]<br>train_result = train_data['Survived']<br>test_features = test_data[features]<br>devc = DictVectorizer(sparse=False)<br>train_features = devc.fit_transform(train_features.to_dict(orient='record'))<br>test_features = devc.fit_transform(test_features.to_dict(orient='record'))<br><br>#构造决策树，进行预测<br>tree_regressor = DecisionTreeRegressor()<br>tree_regressor.fit(train_features,train_result)<br>predict_tree = tree_regressor.predict(test_features)<br>#交叉验证准确率<br>print('CART决策树K折交叉验证准确率:', np.mean(cross_val_predict(tree_regressor,train_features,train_result,cv=10)))<br><br>#构造AdaBoost<br>ada_regressor = AdaBoostRegressor()<br>ada_regressor.fit(train_features,train_result)<br>predict_ada = ada_regressor.predict(test_features)<br>#交叉验证准确率<br>print('AdaBoostK折交叉验证准确率:',np.mean(cross_val_predict(ada_regressor,train_features,train_result,cv=10)))<br></div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>滨滨</span> <!----></div> <div class="_1H1Z49Dr_0">2019-04-21</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">分类和回归都是做预测，分类是离散值，回归是连续值</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>hlz-123</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-27</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0 _3D2NkqD6_0">老师，在AdaBoost 与决策树模型的比较的例子中，弱分类器<br>dt_stump = DecisionTreeClassfier(max_depth=1,min_samples_leaf=1)<br>为什么两个参数都设置为1，相当于只有1个根节点，2个叶节点？<br>而普通的决策树分类器，没有设置参数，这是什么原因？</div> <!----> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/14/c1/1f/cc77944d.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>叮当猫</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-19</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">fit_transform数据统一处理，求问什么时候需要？<br>在我同时没有进行fit_transform的情况下，准确率：<br>决策树弱分类器的准确率是0.7867<br>决策树分类器的准确率是0.7734<br>AdaBoost分类器的准确率是0.8161<br>在我对数据同时进行fit_transform的情况下，准确率：<br>决策树弱分类器的准确率是0.7867<br>决策树分类器的准确率是0.7745<br>AdaBoost分类器的准确率是0.8138<br><br>以下是第一种情况：<br>train_data['Embarked'] = train_data['Embarked'].map({'S':0, 'C':1, 'Q':2})<br>test_data['Embarked'] = test_data['Embarked'].map({'S':0, 'C':1, 'Q':2})<br>train_data['Sex'] = train_data['Sex'].map({'male':0, 'female':1})<br>test_data['Sex'] = test_data['Sex'].map({'male':0, 'female':1})<br><br>train_data['Age'].fillna(train_data['Age'].mean(), inplace=True)<br>test_data['Age'].fillna(test_data['Age'].mean(), inplace=True)<br>train_data['Fare'].fillna(train_data['Fare'].mean(), inplace=True)<br>test_data['Fare'].fillna(test_data['Fare'].mean(), inplace=True)<br><br>features = ['Pclass', 'Sex','Age','SibSp', 'Parch', 'Fare', 'Embarked']<br>train_features = train_data[features]<br>train_labels = train_data['Survived']<br>test_features = test_data[features]<br><br>#train_features = dvec.fit_transform(train_features.to_dict(orient='record'))<br>#test_features = dvec.transform(test_features.to_dict(orient='record'))<br><br>以下是第二种情况：<br>#train_data['Embarked'] = train_data['Embarked'].map({'S':0, 'C':1, 'Q':2})<br>#test_data['Embarked'] = test_data['Embarked'].map({'S':0, 'C':1, 'Q':2})<br>#train_data['Sex'] = train_data['Sex'].map({'male':0, 'female':1})<br>#test_data['Sex'] = test_data['Sex'].map({'male':0, 'female':1})<br><br>train_data['Age'].fillna(train_data['Age'].mean(), inplace=True)<br>test_data['Age'].fillna(test_data['Age'].mean(), inplace=True)<br>train_data['Fare'].fillna(train_data['Fare'].mean(), inplace=True)<br>test_data['Fare'].fillna(test_data['Fare'].mean(), inplace=True)<br><br>features = ['Pclass', 'Sex','Age','SibSp', 'Parch', 'Fare', 'Embarked']<br>train_features = train_data[features]<br>train_labels = train_data['Survived']<br>test_features = test_data[features]<br><br>train_features = dvec.fit_transform(train_features.to_dict(orient='record'))<br>test_features = dvec.transform(test_features.to_dict(orient='record'))</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/wJphZ3HcvhjVUyTWCIsCugzfQY5NAy6VJ0XoPLibDlcHWMswFmFe678zd0lUjFETia80NQhyQcVnGDlKgKPcRGyw/132"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>JingZ</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-05</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0"># AdaBoost<br>一开始竟然蓦然惯性用了AdaBoostRegressor，得到0.33的准确率，最后看了小伙伴代码，立马修正<br><br>感觉算法代码不复杂，关键要自己从空白开始写，还需多实战<br><br>from sklearn.ensemble import AdaBoostClassifier<br><br># 使用 Adaboost 分类模型<br>ada = AdaBoostClassifier()<br>ada.fit(train_features, train_labels)<br><br>pred_labels = ada.predict(test_features)<br><br>acc_ada_classifier = round(ada.score(train_features, train_labels), 6)<br>print(u'Adaboost score 准确率为 %.4lf' % acc_ada_classifier)<br>print(u'Adaboost cross_val_score 准确率为 %.4lf' % np.mean(cross_val_score(ada, train_features, train_labels, cv=10)))<br><br>运行<br>Adaboost score 准确率为 0.8339<br>Adaboost cross_val_score 准确率为 0.8104</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/14/b8/21/c03839f1.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>FORWARD―M...</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-05</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">老师，房价预测这个算法，50个弱分类器是怎么来的？</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/11/77/be/1f2409e8.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>梁林松</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-04</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">跑第二块代码是需要引入两个模块<br>from sklearn.tree import DecisionTreeRegressor<br>from sklearn.neighbors import KNeighborsRegressor<br></div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/10/83/e2/297518ab.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>佳佳的爸</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-04</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">你好老师，完整的源代码在哪里可以下载到?  我说的是每节课里边的源代码。</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li></ul></div></div> <!----></div> <!----></div></div> </div><!----></body></html>