<!DOCTYPE html><html><head>
    <meta charset="utf-8"><meta name="keywords" content="极客时间,IT,职业教育,知识付费,二叉树,极客Live,极客搜索,互联网,前端开发,后端开发,编程语言,人工智能,区块链,技术大会,技术管理,产品,研发,测试,运维,数据库,架构,微服务,实战,技术专家,Java,iOS,Android,Linux,Go" id="metakeywords"><meta name="description" content="极客时间是一款由极客邦科技倾力打造的面向IT领域的知识服务产品,旨在帮助用户提升技术认知.板块包含专栏文章、视频课程、新闻、资讯、直播、图书、商城等。内容覆盖IT从业者的全生命周期知识技能图谱,邀请左耳朵耗子、王争、杨晓峰、winter,丁奇等顶级技术和行业专家为你讲述技术本质,解读科技动态." id="metadesc"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no,viewport-fit=cover"><meta name="format-detection" content="telephone=no"><title>极客时间 | 数据分析实战45讲</title><style data-savepage-href="https://static001.geekbang.org/static/time/css/app.e30427d82748c1a9d53a048cf510f63c.css">html{color:#333;-webkit-text-size-adjust:100%;-ms-text-size-adjust:100%;text-rendering:optimizelegibility;font-family:Helvetica Neue,PingFang SC,Verdana,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif}html.borderbox *,html.borderbox :after,html.borderbox :before{box-sizing:border-box}article,aside,blockquote,body,button,code,dd,details,dl,dt,fieldset,figcaption,figure,footer,form,h1,h2,h3,h4,h5,h6,header,hr,input,legend,li,menu,nav,ol,p,pre,section,td,textarea,th,ul{margin:0;padding:0}article,aside,details,figcaption,figure,footer,header,menu,nav,section{display:block}audio,canvas,video{display:inline-block}body,button,input,select,textarea{font:300 1em/1.8 PingFang SC,Lantinghei SC,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,Helvetica,sans-serif}button::-moz-focus-inner,input::-moz-focus-inner{padding:0;border:0}table{border-collapse:collapse;border-spacing:0}fieldset,img{border:0}blockquote{position:relative;color:#999;font-weight:400;border-left:1px solid #1abc9c;padding-left:1em;margin:1em 3em 1em 2em}@media only screen and (max-width:640px){blockquote{margin:1em 0}}abbr,acronym{border-bottom:1px dotted;font-variant:normal}abbr{cursor:help}del{text-decoration:line-through}address,caption,cite,code,dfn,em,th,var{font-style:normal;font-weight:400}ol,ul{list-style:none}caption,th{text-align:left}q:after,q:before{content:""}sub,sup{font-size:75%;line-height:0;position:relative}:root sub,:root sup{vertical-align:baseline}sup{top:-.5em}sub{bottom:-.25em}a{color:#1abc9c}a:hover{text-decoration:underline}.typo a{border-bottom:1px solid #1abc9c}.typo a:hover{border-bottom-color:#555;color:#555}.typo a:hover,a,ins{text-decoration:none}.typo-u,u{text-decoration:underline}mark{background:#fffdd1;border-bottom:1px solid #ffedce;padding:2px;margin:0 5px}code,pre,pre tt{font-family:Courier,Courier New,monospace}pre{background:hsla(0,0%,97%,.7);border:1px solid #ddd;padding:1em 1.5em;display:block;-webkit-overflow-scrolling:touch}hr{border:none;border-bottom:1px solid #cfcfcf;margin-bottom:.8em;height:10px}.typo-small,figcaption,small{font-size:.9em;color:#888}b,strong{font-weight:700;color:#000}[draggable]{cursor:move}.clearfix:after,.clearfix:before{content:"";display:table}.clearfix:after{clear:both}.clearfix{zoom:1}.textwrap,.textwrap td,.textwrap th{word-wrap:break-word;word-break:break-all}.textwrap-table{table-layout:fixed}.serif{font-family:Palatino,Optima,Georgia,serif}.typo-dl,.typo-form,.typo-hr,.typo-ol,.typo-p,.typo-pre,.typo-table,.typo-ul,.typo dl,.typo form,.typo hr,.typo ol,.typo p,.typo pre,.typo table,.typo ul,blockquote{margin-bottom:1rem}h1,h2,h3,h4,h5,h6{font-family:PingFang SC,Helvetica Neue,Verdana,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#000;line-height:1.35}.typo-h1,.typo-h2,.typo-h3,.typo-h4,.typo-h5,.typo-h6,.typo h1,.typo h2,.typo h3,.typo h4,.typo h5,.typo h6{margin-top:1.2em;margin-bottom:.6em;line-height:1.35}.typo-h1,.typo h1{font-size:2em}.typo-h2,.typo h2{font-size:1.8em}.typo-h3,.typo h3{font-size:1.6em}.typo-h4,.typo h4{font-size:1.4em}.typo-h5,.typo-h6,.typo h5,.typo h6{font-size:1.2em}.typo-ul,.typo ul{margin-left:1.3em;list-style:disc}.typo-ol,.typo ol{list-style:decimal;margin-left:1.9em}.typo-ol ol,.typo-ol ul,.typo-ul ol,.typo-ul ul,.typo li ol,.typo li ul{margin-bottom:.8em;margin-left:2em}.typo-ol ul,.typo-ul ul,.typo li ul{list-style:circle}.typo-table td,.typo-table th,.typo table caption,.typo table td,.typo table th{border:1px solid #ddd;padding:.5em 1em;color:#666}.typo-table th,.typo table th{background:#fbfbfb}.typo-table thead th,.typo table thead th{background:hsla(0,0%,95%,.7)}.typo table caption{border-bottom:none}.typo-input,.typo-textarea{-webkit-appearance:none;border-radius:0}.typo-em,.typo em,caption,legend{color:#000;font-weight:inherit}.typo-em{position:relative}.typo-em:after{position:absolute;top:.65em;left:0;width:100%;overflow:hidden;white-space:nowrap;content:"\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB\30FB"}.typo img{max-width:100%}.common-content{font-weight:400;color:#353535;line-height:1.75rem;white-space:normal;word-break:normal;font-size:1rem}.common-content img{display:block;max-width:100%;background-color:#eee}.common-content audio,.common-content video{width:100%;background-color:#eee}.common-content center,.common-content font{margin-top:1rem;display:inline-block}.common-content center{width:100%}.common-content pre{margin-top:1rem;padding-left:0;padding-right:0;position:relative;overflow:hidden}.common-content pre code{font-size:.8rem;font-family:Consolas,Liberation Mono,Menlo,monospace,Courier;display:block;width:100%;box-sizing:border-box;padding-left:1rem;padding-right:1rem;overflow-x:auto}.common-content hr{border:none;margin-top:1.5rem;margin-bottom:1.5rem;border-top:1px solid #f5f5f5;height:1px;background:none}.common-content b,.common-content h1,.common-content h2,.common-content h3,.common-content h4,.common-content h5,.common-content strong{font-weight:700}.common-content h1,.common-content h2{font-size:1.125rem;margin-bottom:.45rem}.common-content h3,.common-content h4,.common-content h5{font-size:1rem;margin-bottom:.45rem}.common-content p{font-weight:400;color:#353535;margin-top:.15rem}.common-content .orange{color:#ff5a05}.common-content .reference{font-size:1rem;color:#888}.custom-rich-content h1{margin-top:0;font-weight:400;font-size:15.25px;border-bottom:1px solid #eee;line-height:2.8}.custom-rich-content li,.custom-rich-content p{font-size:14px;color:#888;line-height:1.6}table.hljs-ln{margin-bottom:0;border-spacing:0;border-collapse:collapse}table.hljs-ln,table.hljs-ln tbody,table.hljs-ln td,table.hljs-ln tr{box-sizing:border-box}table.hljs-ln td{padding:0;border:0}table.hljs-ln td.hljs-ln-numbers{min-width:15px;color:rgba(27,31,35,.3);text-align:right;white-space:nowrap;cursor:pointer;user-select:none}table.hljs-ln td.hljs-ln-code,table.hljs-ln td.hljs-ln-numbers{font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;font-size:12px;line-height:20px;vertical-align:top}table.hljs-ln td.hljs-ln-code{position:relative;padding-right:10px;padding-left:10px;overflow:visible;color:#24292e;word-wrap:normal;white-space:pre}video::-webkit-media-controls{overflow:hidden!important}video::-webkit-media-controls-enclosure{width:calc(100% + 32px);margin-left:auto}.button-cancel{color:#888;border:1px solid #888;border-radius:3px;margin-right:12px}.button-cancel,.button-primary{-ms-flex-positive:1;flex-grow:1;height:35px;display:inline-block;font-size:15px;text-align:center;line-height:36px}.button-primary{color:#fff;background-color:#fa8919;border-radius:3px}.gkui-message-content-wrap .gkui-message-close .defaultClose:after,.gkui-message-content-wrap .gkui-message-close .defaultClose:before{transition:all .3s ease}.gkui-message-content-wrap{position:relative;text-align:center}.gkui-message-content-wrap .gkui-message-content{display:inline-block;overflow:hidden;padding:10px 16px;margin-bottom:6px;background:#fff;font-size:14px;line-height:14px;border-radius:3px;box-shadow:0 1px 6px rgba(0,0,0,.2);pointer-events:all}.gkui-message-content-wrap .gkui-message-loading-prefix{display:inline-block;margin-right:4px;transform:translateY(2px)}.gkui-message-content-wrap .gkui-message-close{display:inline-block;margin-left:4px;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.gkui-message-content-wrap .gkui-message-close .defaultClose{display:inline-block;position:relative;width:10px;height:10px}.gkui-message-content-wrap .gkui-message-close .defaultClose:after,.gkui-message-content-wrap .gkui-message-close .defaultClose:before{position:absolute;top:5px;right:0;display:block;content:"";width:12px;height:1px;background:#8a8a8a}.gkui-message-content-wrap .gkui-message-close .defaultClose:before{transform:rotate(45deg)}.gkui-message-content-wrap .gkui-message-close .defaultClose:after{transform:rotate(-45deg)}.gkui-message-content-wrap .gkui-message-close .defaultClose:hover:after,.gkui-message-content-wrap .gkui-message-close .defaultClose:hover:before{background:#333}.fade-up-enter-active,.fade-up-leave-active{transition:all .4s ease}.fade-up-enter,.fade-up-leave-to{opacity:0;transform:translateY(-50%)}.fade-up-leave-to{height:0}.gkui-message-content-wrap .gkui-message-info{border:1px solid #ddd}.gkui-message-content-wrap .gkui-message-success{border:1px solid #666;background:#666;color:#fff}.gkui-message-content-wrap .gkui-message-error{border:1px solid rgba(0,0,0,.7);background-color:rgba(0,0,0,.7);color:#fff}.iconfont{font-family:iconfont!important;font-size:16px;font-style:normal;-webkit-font-smoothing:antialiased;-webkit-text-stroke-width:.2px;-moz-osx-font-smoothing:grayscale}html{background:#fff;min-height:100%;-webkit-tap-highlight-color:rgba(0,0,0,0)}body{width:100%}body.fixed{overflow:hidden;position:fixed;width:100vw;height:100vh}i{font-style:normal}a{word-wrap:break-word;-webkit-tap-highlight-color:rgba(0,0,0,0)}a:hover{text-decoration:none}.fade-enter-active,.fade-leave-active{transition:opacity .3s}.MathJax,.MathJax_CHTML,.MathJax_MathContainer,.MathJax_MathML,.MathJax_PHTML,.MathJax_PlainSource,.MathJax_SVG{outline:0}.ios-app-switch .js-audit{display:none}.gkui--modal-block-scroll{position:absolute;overflow:hidden;width:100vw}#gkui-modal-controller{width:100%}#gkui-modal-controller,.gkui-modal-layer{position:fixed;left:0;top:0;z-index:90000}.gkui-modal-layer{right:0;bottom:0;background-color:rgba(55,55,55,.3)}.fade-enter-active,.fade-leave-active{transition:all .3s ease}.fade-enter,.fade-leave-to{opacity:0}.gkui-message-list[data-v-99cd8b4a]{position:fixed;top:0;left:0;width:100%;pointer-events:none}._2sRsF5RP_0{position:relative}._loading_wrap_{position:fixed;width:100vw;height:100vh;top:50%;left:50%;transform:translate(-50%,-50%);z-index:999}._loading_div_class_,._loading_wrap_{display:-ms-flexbox;display:flex;-ms-flex-pack:center;justify-content:center;-ms-flex-align:center;align-items:center}._loading_div_class_{word-wrap:break-word;padding:.5rem .75rem;text-align:center;z-index:9999;font-size:.6rem;max-width:60%;color:#fff;border-radius:.25rem;-ms-flex-direction:column;flex-direction:column}._loading_div_class_ .message{color:#353535;font-size:16px;line-height:3}.spinner{animation:circle-rotator 1.4s linear infinite}.spinner *{line-height:0;box-sizing:border-box}@keyframes circle-rotator{0%{transform:rotate(0deg)}to{transform:rotate(270deg)}}.path{stroke-dasharray:187;stroke-dashoffset:0;transform-origin:center;animation:circle-dash 1.4s ease-in-out infinite,circle-colors 5.6s ease-in-out infinite}@keyframes circle-colors{0%{stroke:#fa8919}to{stroke:#fa8919}}@keyframes circle-dash{0%{stroke-dashoffset:187}50%{stroke-dashoffset:46.75;transform:rotate(135deg)}to{stroke-dashoffset:187;transform:rotate(450deg)}}.confirm-box-wrapper,.confirm-box-wrapper .mask{position:absolute;top:0;left:0;right:0;bottom:0}.confirm-box-wrapper .mask{background:rgba(0,0,0,.6)}.confirm-box-wrapper .confirm-box{position:fixed;top:50%;left:50%;width:267px;background:#fff;transform:translate(-50%,-50%);border-radius:7px}.confirm-box-wrapper .confirm-box .head{margin:0 18px;font-size:18px;text-align:center;line-height:65px;border-bottom:1px solid #d9d9d9}.confirm-box-wrapper .confirm-box .body{padding:18px;padding-bottom:0;color:#353535;font-size:12.5px;max-height:150px;overflow:auto}.confirm-box-wrapper .confirm-box .foot{display:-ms-flexbox;display:flex;-ms-flex-direction:row;flex-direction:row;padding:18px}.confirm-box-wrapper .confirm-box .foot .button-cancel{border:1px solid #d9d9d9}.hljs{display:block;overflow-x:auto;padding:.5em;color:#333;background:#f8f8f8}.hljs-comment,.hljs-quote{color:#998;font-style:italic}.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#333;font-weight:700}.hljs-literal,.hljs-number,.hljs-tag .hljs-attr,.hljs-template-variable,.hljs-variable{color:teal}.hljs-doctag,.hljs-string{color:#d14}.hljs-section,.hljs-selector-id,.hljs-title{color:#900;font-weight:700}.hljs-subst{font-weight:400}.hljs-class .hljs-title,.hljs-type{color:#458;font-weight:700}.hljs-attribute,.hljs-name,.hljs-tag{color:navy;font-weight:400}.hljs-link,.hljs-regexp{color:#009926}.hljs-bullet,.hljs-symbol{color:#990073}.hljs-built_in,.hljs-builtin-name{color:#0086b3}.hljs-meta{color:#999;font-weight:700}.hljs-deletion{background:#fdd}.hljs-addition{background:#dfd}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}</style><style type="text/css">.hljs-ln{border-collapse:collapse}.hljs-ln td{padding:0}.hljs-ln-n:before{content:attr(data-line-number)}</style><style type="text/css">._3ADRghFH_0{background:#000}._21xvFvr7_0{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}._3O_7qs2p_0{opacity:0}._2q1SuvsS_0{opacity:1}._20-cXID6_0{max-width:46.25rem;min-height:100vh;margin:0 auto;background:#fff;-webkit-transition:background-color .3s ease;transition:background-color .3s ease}._20-cXID6_0 .PYIrCCrf_0{color:#888}._20-cXID6_0 ._1EUVUUrC_0,._20-cXID6_0 .PYIrCCrf_0{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;height:35px;display:inline-block;font-size:15px;text-align:center;line-height:36px}._20-cXID6_0 ._1EUVUUrC_0{color:#fff;background-color:#fa8919;font-weight:500}._20-cXID6_0 ._2QmGFWqF_0{padding-left:22px;padding-right:15px}._20-cXID6_0 ._3lTiSebX_0{color:#fa8919;font-size:15px;font-weight:600;line-height:24px;border-radius:5px;padding:12px;background-color:#f6f7fb;margin-top:20px}._20-cXID6_0 ._3lTiSebX_0 ._7OuU9_xM_0{font-size:12px}._20-cXID6_0 ._50pDbNcP_0{padding-top:22px;padding-bottom:82px}._20-cXID6_0 .vJXgmLTi_0{color:#353535;font-weight:700;line-height:30px;font-size:22px;display:-webkit-box;-webkit-line-clamp:2;-webkit-box-orient:vertical;overflow:hidden;text-overflow:ellipsis}._20-cXID6_0 ._2LbT9q3y_0{color:#888;font-size:13px;font-weight:400;margin-top:4px;margin-bottom:12px}._20-cXID6_0 ._2LbT9q3y_0 ._3FoXPaWx_0{margin-top:10px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;-webkit-box-align:center;-ms-flex-align:center;align-items:center;overflow:hidden}._20-cXID6_0 ._2LbT9q3y_0 ._3FoXPaWx_0 .YLYfWxsg_0{color:#404040;font-size:15px;font-weight:400;min-width:0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}._20-cXID6_0 ._2LbT9q3y_0 ._3FoXPaWx_0 .nJKayDbe_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-left:10px;height:23px;border-radius:23px;font-size:13px;font-weight:400;color:#fa8919;padding-left:10px;padding-right:6px;background:#fbf5ee;white-space:nowrap}._20-cXID6_0 ._2LbT9q3y_0 ._3FoXPaWx_0 .nJKayDbe_0 ._2k8p2GLU_0{margin-left:2px;font-size:12px;-webkit-transform:scale(.7);transform:scale(.7)}._20-cXID6_0 ._3Jbcj4Iu_0._3BZBHEhm_0 video-webkit-media-controls-fullscreen-button{display:none}._20-cXID6_0 ._1-ZfmNK8_0{border-radius:6px;vertical-align:top;margin-bottom:24px;width:100%}._20-cXID6_0 ._3IatBmhv_0{margin-top:0}._20-cXID6_0 ._22WJb59B_0{color:#b2b2b2;padding-bottom:20px;font-size:13px;font-weight:400}._20-cXID6_0 ._22WJb59B_0 ._3ODTLCec_0{font-size:15px}._20-cXID6_0 ._3c2GGLul_0{width:100%;margin:20px 0}._20-cXID6_0 ._3EKy7lL9_0{overflow:hidden;padding-top:10px;margin-bottom:-30px}._20-cXID6_0 ._3EKy7lL9_0 a._1EUVUUrC_0{float:right;height:20px;font-size:12px;line-height:20px;padding:4px 8px;cursor:pointer}._20-cXID6_0 ._1qhD3bdE_0{padding-top:32px;border-top:10px solid #f6f7fb;-webkit-transition:border-top .3s ease;transition:border-top .3s ease;position:relative}._20-cXID6_0 ._1qhD3bdE_0 h2{color:#404040;position:relative;z-index:1;margin-bottom:1rem;font-weight:700;font-size:19px}._20-cXID6_0 ._1qhD3bdE_0 ._2FC_cD1O_0{font-size:16px;margin-left:5px}._20-cXID6_0 ._2-nZIZjB_0{position:absolute;z-index:2;background:#fa8919;font-size:13px;color:#fff;text-align:center;height:28px;width:80px;line-height:28px;-webkit-box-shadow:4px 5px 20px 1px rgba(250,137,25,.24);box-shadow:4px 5px 20px 1px rgba(250,137,25,.24);border-radius:28px;right:22px;top:32px}._20-cXID6_0 .YGjSYR8B_0{z-index:10;cursor:pointer}._20-cXID6_0 ._2DmyW7ex_0{cursor:pointer;padding-top:24px;padding-bottom:24px;position:relative}._20-cXID6_0 ._2DmyW7ex_0:before{content:" ";height:.5px;background:#e8e8e8;position:absolute;top:0;left:0;-webkit-box-sizing:border-box;box-sizing:border-box;left:22px;right:22px}._20-cXID6_0 ._2DmyW7ex_0 ._1M5b-cvc_0{height:38px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center}._20-cXID6_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3l55W_ak_0{-webkit-box-flex:0;-ms-flex:0 0 62px;flex:0 0 62px;text-align:center;color:#888;font-size:14px;border-radius:10px;height:22px;line-height:22px;background:#f6f7fb;font-weight:400}._20-cXID6_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3Ov-zF0e_0{margin-left:10px;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;color:#888;font-size:15px;height:22px;line-height:22px;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;font-weight:400}.ZphmEful_0{height:60px;background:transparent}._2zq_fmRg_0{font-size:15px;color:#888;line-height:24px;border-left:3px solid #e8e8e8;padding-left:15px}._3uTMOfKI_0,._24nFYvU9_0{-webkit-transition:all .3s ease;transition:all .3s ease}._3WwMT2EY_0 ._1uEolA82_0,._9b3gTd1B_0 ._2NnvkXgw_0{-webkit-transform:translateX(-508px);transform:translateX(-508px)}._3WwMT2EY_0 ._2NnvkXgw_0,._9b3gTd1B_0 ._1uEolA82_0{-webkit-transform:translateX(508px);transform:translateX(508px)}._3BZBHEhm_0 ._2LbT9q3y_0{font-weight:700}._3BZBHEhm_0 ._2DmyW7ex_0:before{height:1px}@media only screen and (max-width:769px){._15u7cU5H_0{display:none!important}}@media only screen and (min-width:740px){._3ADRghFH_0{background:#fff}}.g78dTtKm_0{background:#f6f0e0}.g78dTtKm_0 ._1qhD3bdE_0{border-top:10px solid #efe6cf}.g78dTtKm_0 ._2DmyW7ex_0:before{background:#e5d8b5}.g78dTtKm_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3l55W_ak_0{background:#efe6cf}.g78dTtKm_0 ._3lTiSebX_0{background-color:#efe6cf}._3uMzBYfb_0{background:#353535}._3uMzBYfb_0 ._2LbT9q3y_0,._3uMzBYfb_0 .vJXgmLTi_0{color:silver}._3uMzBYfb_0 ._1qhD3bdE_0{border-top:10px solid #3e3e3e}._3uMzBYfb_0 ._2DmyW7ex_0:before{background:#4c4c4c}._3uMzBYfb_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3l55W_ak_0{background:#3e3e3e;color:silver}._3uMzBYfb_0 ._1qhD3bdE_0 h2,._3uMzBYfb_0 ._2DmyW7ex_0 ._1M5b-cvc_0 ._3Ov-zF0e_0{color:silver}._3uMzBYfb_0 ._3lTiSebX_0{background-color:#3e3e3e}._25ls2Q2l_0{margin-bottom:24px}._4ikL8tnR_0{padding-top:40px!important}.gpDqvVI7_0{position:fixed;top:0;bottom:0;width:100%;z-index:-1}</style><style type="text/css">._352wsGxH_0{height:63px}.Wz6esVdU_0{width:100%;height:63px;background:#fff;position:fixed;top:0;left:0;z-index:20;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 13px;-webkit-box-shadow:0 2px 3px 0 hsla(0,0%,89%,.38);box-shadow:0 2px 3px 0 hsla(0,0%,89%,.38)}._28dOln0j_0{height:40px;width:110px;background-size:110px;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;cursor:pointer}._1k9ecCKw_0{width:30px;height:30px;padding-top:4px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:start;-ms-flex-pack:start;justify-content:start;font-size:14px;color:#444;margin-left:10px;cursor:pointer}._1U_jCCZU_0{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}._3oCJiu8W_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:0 13px;background:#fbf5ee;border-radius:15px;height:30px}._7Xrmrbox_0,.gBs4U5qC_0,.JjI7sqpW_0{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;color:#fa8919;font-size:13px;font-weight:500;cursor:pointer}.JjI7sqpW_0{font-size:14px}._3lsV2-l9_0{height:13px;width:1px;background:#fa8919;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;margin-left:10px;margin-right:10px}._1UaW_Eq1_0{position:fixed;top:0;bottom:0;left:0;right:0;z-index:21;background:#fff;-webkit-transform:translateY(-20px);transform:translateY(-20px);opacity:0;visibility:hidden;-webkit-transition:all .3s ease;transition:all .3s ease}._1UaW_Eq1_0._2mIjHHvm_0{-webkit-transform:translateY(0);transform:translateY(0);opacity:1;visibility:visible}._1qHJ5OLn_0{height:63px;-ms-flex-align:center;padding-left:15px;padding-right:15px;-webkit-box-shadow:0 2px 3px 0 hsla(0,0%,89%,.38);box-shadow:0 2px 3px 0 hsla(0,0%,89%,.38)}._1qHJ5OLn_0,._2FYmyQEJ_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;align-items:center}._2FYmyQEJ_0{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;height:35px;-ms-flex-align:center;border-radius:20px;padding-left:20px;padding-right:20px}._1CLulytQ_0{font-size:14px;color:#b2b2b2}._1reF0JJk_0{height:20px;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;margin-left:10px}._1reF0JJk_0 input{background:transparent;border:0;color:#353535;height:20px;line-height:20px;font-size:14px;width:100%;vertical-align:top;outline:none}._33xQ4nNG_0{font-size:16px;font-weight:400;color:#b2b2b2;height:30px;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;margin-left:20px}._1y_WRr3L_0{font-size:18px}._1y_WRr3L_0 ._2HnUZhdg_0{color:#888;font-weight:400;padding-left:28px;height:63px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-bottom:1px solid #eee}._1y_WRr3L_0 ._2HnUZhdg_0._1r7t-t9P_0{color:#fa8919}._3IeMxVb7_0{position:absolute;bottom:40px;left:0;width:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-ms-flex-pack:distribute;justify-content:space-around}._3IeMxVb7_0 ._2HnUZhdg_0{position:relative;padding-top:46px;color:#888}._3IeMxVb7_0 ._339_Pvt6_0{position:absolute;color:#c3c3c3;height:46px;width:100%;display:-webkit-box;display:-ms-flexbox;display:flex;font-size:36px;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;top:0;left:0}</style><style type="text/css">._2SACi4xg_0{line-height:0}._2SACi4xg_0 img{vertical-align:top;margin-left:20px;opacity:.5}</style><style type="text/css">._1Bg5E78Y_0{width:100%;height:60px;background:#fff;-webkit-transition:background-color .3s ease;transition:background-color .3s ease;-webkit-box-sizing:border-box;box-sizing:border-box;padding-left:18px;padding-right:12px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;border-radius:6px 30px 30px 6px;-webkit-box-shadow:0 3px 25px 4px rgba(140,163,191,.14);box-shadow:0 3px 25px 4px rgba(140,163,191,.14)}._1Bg5E78Y_0 ._2Ha38TVL_0{border-radius:50%;width:40px;height:40px;-webkit-box-shadow:0 1px 3px 2px rgba(0,0,0,.1);box-shadow:0 1px 3px 2px rgba(0,0,0,.1);position:relative}._1Bg5E78Y_0 ._1iA2uC1V_0{background-repeat:no-repeat;background-position:0 0;background-size:300px;background-color:#fff;border-radius:50%;width:40px;height:40px;position:absolute;top:0;left:0}._1Bg5E78Y_0 ._1WF5YSBJ_0{background:rgba(0,0,0,.15)}._1Bg5E78Y_0 ._2Kms_g0F_0{width:40px;height:40px;line-height:40px;text-align:center;border-radius:50%;z-index:2;position:relative}._1Bg5E78Y_0 .MH1rcCm7_0 ._2Kms_g0F_0{color:#fff;margin-left:2px}._1Bg5E78Y_0 ._1KuRDTHn_0 ._2Kms_g0F_0{color:#fff}._1Bg5E78Y_0 .MH1rcCm7_0 ._1iA2uC1V_0{-webkit-animation:HvzpPu2i_0 4s linear infinite;animation:HvzpPu2i_0 4s linear infinite;-webkit-animation-play-state:paused;animation-play-state:paused}._1Bg5E78Y_0 ._1KuRDTHn_0 ._1iA2uC1V_0{-webkit-animation:HvzpPu2i_0 4s linear infinite;animation:HvzpPu2i_0 4s linear infinite;-webkit-animation-play-state:running;animation-play-state:running}._1Bg5E78Y_0 ._1qj_iPD7_0{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;overflow:hidden;margin-right:10px}._1Bg5E78Y_0 ._1qj_iPD7_0 h3{color:#404040;font-size:15.25px;margin:0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}._1Bg5E78Y_0 ._1qj_iPD7_0 p{margin:0;margin-top:.125rem;font-size:12px;font-weight:500;line-height:1rem;color:#999}._1Bg5E78Y_0 ._3PhVtlEa_0{width:20px;height:20px;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;position:relative;color:#999;font-size:18px;line-height:20px;text-align:center;margin-right:20px}._1Bg5E78Y_0 ._1l6e3976_0{width:10px;height:10px;line-height:10px;text-align:center;position:absolute;bottom:-3px;right:-5px;color:#6c0;background:#fff;font-size:10px;-webkit-transition:background-color .2s ease;transition:background-color .2s ease}._1W0qSnju_0{-webkit-box-shadow:0 3px 25px 4px hsla(42,28%,65%,.14);box-shadow:0 3px 25px 4px hsla(42,28%,65%,.14)}._1W0qSnju_0,._1W0qSnju_0 ._1l6e3976_0{background:#f6f0e0}._1W0qSnju_0 ._2Ha38TVL_0{-webkit-box-shadow:0 1px 2px 2px hsla(42,28%,65%,.14);box-shadow:0 1px 2px 2px hsla(42,28%,65%,.14)}._2SRR-E_O_0{background:#4d4d4d;-webkit-box-shadow:none;box-shadow:none}._2SRR-E_O_0 ._3PhVtlEa_0{color:#fff}._2SRR-E_O_0 ._1l6e3976_0{background:#4d4d4d}._2SRR-E_O_0 ._1qj_iPD7_0 h3,._2SRR-E_O_0 ._1qj_iPD7_0 p{color:silver}._2vBNygJQ_0 ._1qj_iPD7_0 p{font-weight:700}@-webkit-keyframes HvzpPu2i_0{to{-webkit-transform:rotate(1turn);transform:rotate(1turn)}}@keyframes HvzpPu2i_0{to{-webkit-transform:rotate(1turn);transform:rotate(1turn)}}</style><style type="text/css">._29HP61GA_0{font-weight:400;color:#353535;line-height:1.76;white-space:normal;word-break:normal;font-size:17px;-webkit-transition:background-color .3s ease;transition:background-color .3s ease}._29HP61GA_0 .MathJax_Display{overflow:auto}._29HP61GA_0 .poster{position:fixed;left:-10000px;top:-10000px;overflow:hidden;padding:1rem;background:#ececec}._29HP61GA_0 .richcontent-pre-copy{font-size:13px;color:#888;position:absolute;right:1em;top:.5em;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}._29HP61GA_0 .richcontent-pre-copy .iconfont{font-size:12px;margin-right:.2em}._29HP61GA_0 a{color:#fa8919;border-bottom:1px solid #fa8919}._29HP61GA_0 img{display:block;max-width:100%;position:relative;left:50%;-webkit-transform:translateX(-50%);transform:translateX(-50%);background-color:#eee;vertical-align:top;border-radius:0}._29HP61GA_0 audio,._29HP61GA_0 video{width:100%;background-color:#eee}._29HP61GA_0 pre{margin-top:16px;padding:34px 0 0;margin-bottom:30px;position:relative;border-radius:6px;background:rgba(246,247,251,.749);border:0}._29HP61GA_0 pre code{font-size:12px;font-family:Consolas,Liberation Mono,Menlo,monospace,Courier;display:block;-webkit-box-sizing:border-box;box-sizing:border-box;margin-left:16px;margin-right:16px;overflow-x:scroll}._29HP61GA_0 pre code:after{content:"";height:30px;width:100%;display:block}._29HP61GA_0 hr{border:none;margin-top:1.5rem;margin-bottom:1.5rem;border-top:1px solid #f5f5f5;height:1px;background:none}._29HP61GA_0 h1,._29HP61GA_0 h2,._29HP61GA_0 h3,._29HP61GA_0 h4,._29HP61GA_0 h5{margin-bottom:20px;margin-top:0;font-weight:700;color:#353535}._29HP61GA_0 b,._29HP61GA_0 strong{font-weight:700;color:#353535}._29HP61GA_0 h1{font-size:21px}._29HP61GA_0 h2{font-size:20px}._29HP61GA_0 h3{font-size:19px}._29HP61GA_0 h4{font-size:18px}._29HP61GA_0 h5{font-size:17px}._29HP61GA_0 center,._29HP61GA_0 p{font-weight:400;color:#353535;margin-top:0;margin-bottom:30px;word-break:break-word}._29HP61GA_0 center{text-align:center}._29HP61GA_0 blockquote{margin-top:0;margin-bottom:34px;border-left:3px solid #e8e8e8;padding-left:17px;color:#353535}._29HP61GA_0 blockquote p{margin-top:0;margin-bottom:0}._29HP61GA_0 ol,._29HP61GA_0 ul{margin-bottom:30px}._29HP61GA_0 ol p,._29HP61GA_0 ul p{margin-top:0;margin-bottom:0}._29HP61GA_0 ol{list-style:decimal;margin-left:20px}._29HP61GA_0 ul li{padding-left:17px;position:relative;margin-bottom:10px}._29HP61GA_0 ul li:after{content:"";height:6px;width:6px;border-radius:50%;background:#353535;position:absolute;top:10px;left:0}._29HP61GA_0 .orange{color:#fa8919}._29HP61GA_0 .reference{color:#888}._29HP61GA_0 .m-right{text-align:right}._29HP61GA_0 .m-center{text-align:center;display:block}._29HP61GA_0 .m-gray{color:#888}._29HP61GA_0 .m-small{font-size:15px}._29HP61GA_0 table.hljs-ln{margin-bottom:0;border-spacing:0;border-collapse:collapse}._29HP61GA_0 table.hljs-ln,._29HP61GA_0 table.hljs-ln tbody,._29HP61GA_0 table.hljs-ln td,._29HP61GA_0 table.hljs-ln tr{-webkit-box-sizing:border-box;box-sizing:border-box}._29HP61GA_0 table.hljs-ln td{padding:0;border:0}._29HP61GA_0 table.hljs-ln td.hljs-ln-numbers{min-width:15px;font-size:12px;color:rgba(27,31,35,.3);text-align:right;white-space:nowrap;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}._29HP61GA_0 table.hljs-ln td.hljs-ln-code,._29HP61GA_0 table.hljs-ln td.hljs-ln-numbers{font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;line-height:20px;vertical-align:top}._29HP61GA_0 table.hljs-ln td.hljs-ln-code{position:relative;padding-right:10px;padding-left:10px;overflow:visible;font-size:13px;color:#666;word-wrap:normal;white-space:pre}._2gMcXXSK_0{font-size:15px}._2gMcXXSK_0 h1{font-size:19px}._2gMcXXSK_0 h2{font-size:18px}._2gMcXXSK_0 h3{font-size:17px}._2gMcXXSK_0 h4{font-size:16px}._2gMcXXSK_0 h5{font-size:15px}._2gMcXXSK_0 p{margin-bottom:26px}._2gMcXXSK_0 blockquote{margin-bottom:30px}._2gMcXXSK_0 ol,._2gMcXXSK_0 ul{margin-bottom:26px}._2gMcXXSK_0 .m-small{font-size:13px}._1-IhkAAb_0{font-size:19px}._1-IhkAAb_0 h1{font-size:23px}._1-IhkAAb_0 h2{font-size:22px}._1-IhkAAb_0 h3{font-size:21px}._1-IhkAAb_0 h4{font-size:20px}._1-IhkAAb_0 h5{font-size:19px}._1-IhkAAb_0 .m-small{font-size:17px}._1Xjr5LRK_0 table.hljs-ln td.hljs-ln-code,._1Xjr5LRK_0 table.hljs-ln td.hljs-ln-numbers{font-family:monospace}._1XhbM4Sp_0 pre{background:hsla(43,50%,87%,.749)}._1XhbM4Sp_0 blockquote{border-color:#efe6cf}._2wERfXHe_0 h1,._2wERfXHe_0 h2,._2wERfXHe_0 h3,._2wERfXHe_0 h4,._2wERfXHe_0 h5,._2wERfXHe_0 p{color:silver}._2wERfXHe_0 blockquote{border-color:#3e3e3e}._2wERfXHe_0 li,._2wERfXHe_0 strong{color:silver}._2wERfXHe_0 pre{background:rgba(62,62,62,.749)}._2wERfXHe_0 center{color:silver}._2wERfXHe_0 img{opacity:.9}._2wERfXHe_0 ul li:after{background:silver}._2wERfXHe_0 table.hljs-ln td.hljs-ln-numbers{color:#b2b2b2}._2wERfXHe_0 table.hljs-ln td.hljs-ln-code{color:silver}</style><style type="text/css">.reJj6Thl_0{list-style-position:inside;width:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin-top:40px}.reJj6Thl_0 a{border-bottom:none}.reJj6Thl_0 ._2273kGdT_0{width:35px;height:35px;-ms-flex-negative:0;flex-shrink:0;border-radius:50%}.reJj6Thl_0:last-child ._2CG0SquK_0{border-bottom:none}.reJj6Thl_0 ._2CG0SquK_0{margin-left:.5rem;-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;padding-bottom:25px;border-bottom:.5px solid #e8e8e8;-webkit-transition:border-bottom .3s ease;transition:border-bottom .3s ease;overflow:hidden}.reJj6Thl_0 ._2CG0SquK_0 ._304R4gla_0{width:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;padding-bottom:10px}.reJj6Thl_0 ._2CG0SquK_0 ._3M6kV3zb_0{color:#4c4c4c;font-size:16px;font-weight:400;white-space:normal;word-break:normal;line-height:1.6;overflow:hidden;display:-webkit-box;-webkit-line-clamp:5;-webkit-box-orient:vertical}.reJj6Thl_0 ._2CG0SquK_0 ._3D2NkqD6_0{overflow:auto;-webkit-line-clamp:unset}.reJj6Thl_0 ._2CG0SquK_0 ._1H1Z49Dr_0{color:#888;font-size:11px;line-height:1;margin-top:4px}.reJj6Thl_0 ._2CG0SquK_0 ._18Dng5rT_0{color:#353535;font-size:14px;font-weight:700;height:20px;line-height:20px}.reJj6Thl_0 ._1bkbsnjg_0{height:15px;line-height:15px;width:30px;overflow:hidden;font-size:10px;color:#fff;background:#cbcbcb;text-align:center;display:inline-block;border-radius:3px;vertical-align:top;margin-top:2px}.reJj6Thl_0 ._2eMTs2JE_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:26px}.reJj6Thl_0 ._1YQBH3WC_0{color:#999;font-size:13px;margin-left:42px;width:20px;text-align:center}.reJj6Thl_0 ._13n1j2Zp_0{color:#999;font-size:11px;width:20px;margin-left:38px;text-align:center}.reJj6Thl_0 ._2P4B1Hdm_0{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;font-size:15.25px;text-decoration:none}.reJj6Thl_0 ._2P4B1Hdm_0 i{color:#999;display:inline-block;font-size:15px;margin-right:4px;height:27px;width:15px;margin-top:-2px}.reJj6Thl_0 ._2P4B1Hdm_0 i._2A421P4G_0background-size:15px}.reJj6Thl_0 ._2P4B1Hdm_0 span{color:#888;font-size:13px;font-weight:400}.reJj6Thl_0 ._2P4B1Hdm_0 span._2A421P4G_0{color:#fa8919}.reJj6Thl_0 ._2r3UB1GX_0{font-size:13px;color:#b2b2b2;height:16px;padding-top:8px}.reJj6Thl_0 ._2r3UB1GX_0 span{font-weight:500}.reJj6Thl_0 ._2r3UB1GX_0 i,.reJj6Thl_0 ._2r3UB1GX_0 span{height:16px;line-height:16px;display:inline-block;vertical-align:top}.reJj6Thl_0 ._2xNIY4NG_0{margin-top:10px}.reJj6Thl_0 ._2xNIY4NG_0 ._33BLbmw4_0{color:#888;font-size:14px;font-weight:400;white-space:normal;word-break:normal;background:#f6f7fb;-webkit-transition:background .3s ease;transition:background .3s ease;border-radius:10px;padding:18px;overflow-x:scroll}.reJj6Thl_0 ._2xNIY4NG_0 ._1H1Z49Dr_0{color:#888;font-size:9px}._0X_LEcd_0 ._2xNIY4NG_0 ._33BLbmw4_0{background:#efe6cf}.cGm0Q9aA_0 ._2CG0SquK_0{border-bottom:1px solid #4c4c4c}.cGm0Q9aA_0 ._2CG0SquK_0 ._1H1Z49Dr_0,.cGm0Q9aA_0 ._2CG0SquK_0 ._3M6kV3zb_0,.cGm0Q9aA_0 ._2CG0SquK_0 ._18Dng5rT_0{color:silver}.cGm0Q9aA_0 ._2xNIY4NG_0 ._33BLbmw4_0{color:silver;background:#3e3e3e}.cGm0Q9aA_0 ._1YQBH3WC_0,.cGm0Q9aA_0 ._2P4B1Hdm_0 i,.cGm0Q9aA_0 ._2P4B1Hdm_0 span,.cGm0Q9aA_0 ._13n1j2Zp_0{color:#999}._2Gn7zqLg_0 ._1bkbsnjg_0{line-height:18px}</style>
    <script id="savepage-contentloaders" type="application/javascript">
      "use strict"
      savepage_ContentLoaders();
      function savepage_ContentLoaders()
      {
        var resourceMimeType = new Array();
        var resourceBase64Data = new Array();
        var resourceBlobUrl = new Array();
        window.addEventListener("DOMContentLoaded",
        function(event)
        {
          savepage_ShadowLoader(5);
          savepage_ResourceLoader(5);
          document.getElementById('savepage-contentloaders').remove();
        },false);
        function savepage_ShadowLoader(c){createShadowDOMs(0,document.documentElement);function createShadowDOMs(a,b){var i;if(b.localName=="iframe"||b.localName=="frame"){if(a<c){try{if(b.contentDocument.documentElement!=null){createShadowDOMs(a+1,b.contentDocument.documentElement)}}catch(e){}}}else{if(b.children.length>=1&&b.children[0].localName=="template"&&b.children[0].hasAttribute("data-savepage-shadowroot")){b.attachShadow({mode:"open"}).appendChild(b.children[0].content);b.removeChild(b.children[0]);for(i=0;i<b.shadowRoot.children.length;i++)if(b.shadowRoot.children[i]!=null)createShadowDOMs(a,b.shadowRoot.children[i])}for(i=0;i<b.children.length;i++)if(b.children[i]!=null)createShadowDOMs(a,b.children[i])}}}
        function savepage_ResourceLoader(f){createBlobURLs();replaceReferences(0,document.documentElement);function createBlobURLs(){var i,j,binaryString,blobData;var a=new Array();for(i=0;i<resourceMimeType.length;i++){if(typeof resourceMimeType[i]!="undefined"){binaryString=atob(resourceBase64Data[i]);resourceBase64Data[i]="";a.length=0;for(j=0;j<binaryString.length;j++){a[j]=binaryString.charCodeAt(j)}blobData=new Blob([new Uint8Array(a)],{type:resourceMimeType[i]});resourceMimeType[i]="";resourceBlobUrl[i]=window.URL.createObjectURL(blobData)}}}function replaceReferences(a,b){var i,regex1,regex2,csstext,blobData;regex1=/url\(\s*((?:"[^"]+")|(?:'[^']+')|(?:[^\s)]+))\s*\)/gi;regex2=/data:[^;]*;if(b.hasAttribute("style")){csstext=b.style.cssText;b.style.cssText=csstext.replace(regex1,replaceCSSRef)}if(b.localName=="style"){csstext=b.textContent;b.textContent=csstext.replace(regex1,replaceCSSRef)}else if(b.localName=="link"&&(b.rel.toLowerCase()=="icon"||b.rel.toLowerCase()=="shortcut icon")){if(b.href!="")b.href=b.href.replace(regex2,replaceRef)}else if(b.localName=="body"){if(b.background!="")b.background=b.background.replace(regex2,replaceRef)}else if(b.localName=="img"){if(b.src!="")b.src=b.src.replace(regex2,replaceRef)}else if(b.localName=="input"&&b.type.toLowerCase()=="image"){if(b.src!="")b.src=b.src.replace(regex2,replaceRef)}else if(b.localName=="audio"){if(b.src!=""){b.src=b.src.replace(regex2,replaceRef);b.load()}}else if(b.localName=="video"){if(b.src!=""){b.src=b.src.replace(regex2,replaceRef);b.load()}if(b.poster!="")b.poster=b.poster.replace(regex2,replaceRef)}else if(b.localName=="source"){if(b.src!=""){b.src=b.src.replace(regex2,replaceRef);b.parentElement.load()}}else if(b.localName=="track"){if(b.src!="")b.src=b.src.replace(regex2,replaceRef)}else if(b.localName=="object"){if(b.data!="")b.data=b.data.replace(regex2,replaceRef)}else if(b.localName=="embed"){if(b.src!="")b.src=b.src.replace(regex2,replaceRef)}if(b.localName=="iframe"||b.localName=="frame"){if(a<f){if(b.hasAttribute("data-savepage-sameorigin")){blobData=new Blob([decodeURIComponent(b.src.substr(29))],{type:"text/html;charset=utf-8"});b.onload=function(){try{if(b.contentDocument.documentElement!=null){replaceReferences(a+1,b.contentDocument.documentElement)}}catch(e){}};b.src=window.URL.createObjectURL(blobData)}}}else{if(b.shadowRoot!=null){for(i=0;i<b.shadowRoot.children.length;i++)if(b.shadowRoot.children[i]!=null)replaceReferences(a,b.shadowRoot.children[i])}for(i=0;i<b.children.length;i++)if(b.children[i]!=null)replaceReferences(a,b.children[i])}}function replaceCSSRef(a,b,c,d){var e=new Array();e=b.match(/data:[^;]*;resource=(\d+);base64,/i);if(e!=null)return"url("+resourceBlobUrl[+e[1]]+")";else return a}function replaceRef(a,b,c,d){return resourceBlobUrl[+b]}}
        
      }
    </script>
    
    <meta name="savepage-title" content="极客时间 | 数据分析实战45讲">
    <meta name="savepage-date" content="Wed Jun 05 2019 03:30:15 GMT+0800 (中国标准时间)">
    <meta name="savepage-state" content="Standard Items; Used resource loader; Retained cross-origin frames; Removed unsaved URLs; Max frame depth = 5; Max resource size = 50MB; Max resource time = 10s;">
    <meta name="savepage-version" content="15.0">
    <meta name="savepage-comments" content="">
    <meta name="savepage-resourceloader" content=""></head><body><div id="app"><div class="_3ADRghFH_0" style="background-color: rgb(255, 255, 255);"><div class="gpDqvVI7_0" style="background-color: rgb(255, 255, 255);"></div> <div class="_20-cXID6_0" style="opacity: 1;"><div class="_3O_7qs2p_0 _2q1SuvsS_0"> <!----> <div class="_50pDbNcP_0"><h1 class="vJXgmLTi_0 _2QmGFWqF_0">
        18丨决策树（中）：CART，一棵是回归树，另一棵是分类树
      </h1> <div class="_2LbT9q3y_0 _2QmGFWqF_0"><span>2019-01-23</span> <span>陈旸</span> <div class="_3FoXPaWx_0"><span class="YLYfWxsg_0">数据分析实战45讲</span> <div class="nJKayDbe_0"><span>进入课程</span> <div class="_2k8p2GLU_0 iconfont"></div></div></div></div> <div class="_3Jbcj4Iu_0 _2QmGFWqF_0"><img src="https://static001.geekbang.org/resource/image/e7/7f/e7ebf8c2cbda7afae59fcac0d9314b7f.jpg"  class="_1-ZfmNK8_0"> <div class="_2SACi4xg_0"></div> <!----> <div class="_1Bg5E78Y_0 _25ls2Q2l_0"><div class="_1qj_iPD7_0"><h3>讲述：陈旸</h3> <p><span style="margin-right: 3px;">时长</span><span style="margin-right: 10px;">11:24</span><span style="margin-right: 3px;">大小</span><span>26.13M</span></p></div> <!----> <div class="_2Ha38TVL_0 MH1rcCm7_0"> <div class="_1iA2uC1V_0 _1WF5YSBJ_0"></div> <div class="iconfont _2Kms_g0F_0"></div></div> <audio title="18丨决策树（中）：CART，一棵是回归树，另一棵是分类树" src="https://res001.geekbang.org//media/audio/2c/d6/2cc78634b5338a0be9a52d53f0e2d4d6/ld/ld.m3u8" ></audio></div> <div class="_3IatBmhv_0"><div class="_29HP61GA_0"><p>上节课我们讲了决策树，基于信息度量的不同方式，我们可以把决策树分为 ID3 算法、C4.5 算法和 CART 算法。今天我来带你学习 CART 算法。CART 算法，英文全称叫做 Classification And Regression Tree，中文叫做分类回归树。ID3 和 C4.5 算法可以生成二叉树或多叉树，而 CART 只支持二叉树。同时 CART 决策树比较特殊，既可以作分类树，又可以作回归树。</p><p>那么你首先需要了解的是，什么是分类树，什么是回归树呢？</p><p>我用下面的训练数据举个例子，你能看到不同职业的人，他们的年龄不同，学习时间也不同。如果我构造了一棵决策树，想要基于数据判断这个人的职业身份，这个就属于分类树，因为是从几个分类中来做选择。如果是给定了数据，想要预测这个人的年龄，那就属于回归树。</p><p><img src="https://static001.geekbang.org/resource/image/af/cf/af89317aa55ac3b9f068b0f370fcb9cf.png"  alt=""><br>
分类树可以处理离散数据，也就是数据种类有限的数据，它输出的是样本的类别，而回归树可以对连续型的数值进行预测，也就是数据在某个区间内都有取值的可能，它输出的是一个数值。</p><h2>CART 分类树的工作流程</h2><p>通过上一讲，我们知道决策树的核心就是寻找纯净的划分，因此引入了纯度的概念。在属性选择上，我们是通过统计“不纯度”来做判断的，ID3 是基于信息增益做判断，C4.5 在 ID3 的基础上做了改进，提出了信息增益率的概念。实际上 CART 分类树与 C4.5 算法类似，只是属性选择的指标采用的是基尼系数。</p><!-- [[[read_end]]] --><p>你可能在经济学中听过说基尼系数，它是用来衡量一个国家收入差距的常用指标。当基尼系数大于 0.4 的时候，说明财富差异悬殊。基尼系数在 0.2-0.4 之间说明分配合理，财富差距不大。</p><p>基尼系数本身反应了样本的不确定度。当基尼系数越小的时候，说明样本之间的差异性小，不确定程度低。分类的过程本身是一个不确定度降低的过程，即纯度的提升过程。所以 CART 算法在构造分类树的时候，会选择基尼系数最小的属性作为属性的划分。</p><p>我们接下来详解了解一下基尼系数。基尼系数不好懂，你最好跟着例子一起手动计算下。</p><p>假设 t 为节点，那么该节点的 GINI 系数的计算公式为：</p><p><img src="https://static001.geekbang.org/resource/image/f9/89/f9bb4cce5b895499cabc714eb372b089.png"  alt=""><br>
这里 p(Ck|t) 表示节点 t 属于类别 Ck 的概率，节点 t 的基尼系数为 1 减去各类别 Ck 概率平方和。</p><p>通过下面这个例子，我们计算一下两个集合的基尼系数分别为多少：</p><p>集合 1：6 个都去打篮球；</p><p>集合 2：3 个去打篮球，3 个不去打篮球。</p><p>针对集合 1，所有人都去打篮球，所以 p(Ck|t)=1，因此 GINI(t)=1-1=0。</p><p>针对集合 2，有一半人去打篮球，而另一半不去打篮球，所以，p(C1|t)=0.5，p(C2|t)=0.5，GINI(t)=1-（0.5*0.5+0.5*0.5）=0.5。</p><p>通过两个基尼系数你可以看出，集合 1 的基尼系数最小，也证明样本最稳定，而集合 2 的样本不稳定性更大。</p><p>在 CART 算法中，基于基尼系数对特征属性进行二元分裂，假设属性 A 将节点 D 划分成了 D1 和 D2，如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/69/9a/69a90a43146898150a0de0811c6fef9a.jpg"  alt=""><br>
节点 D 的基尼系数等于子节点 D1 和 D2 的归一化基尼系数之和，用公式表示为：</p><p><img src="https://static001.geekbang.org/resource/image/10/1e/107fed838cb75df62eb149499db20c1e.png"  alt=""><br>
归一化基尼系数代表的是每个子节点的基尼系数乘以该节点占整体父亲节点 D 中的比例。</p><p>上面我们已经计算了集合 D1 和集合 D2 的 GINI 系数，得到：<br>
<img src="https://static001.geekbang.org/resource/image/aa/0c/aa423c65b32bded13212b7e20fb65a0c.png"  alt=""><br>
<img src="https://static001.geekbang.org/resource/image/09/77/092a0ea87aabc5da482ff8a992691b77.png"  alt=""></p><p>所以节点 D 的基尼系数为：</p><p><img src="https://static001.geekbang.org/resource/image/3c/f8/3c08d5cd66a8ea098c397e14f1469ff8.png"  alt=""></p><p>节点 D 被属性 A 划分后的基尼系数越大，样本集合的不确定性越大，也就是不纯度越高。</p><h2>如何使用 CART 算法来创建分类树</h2><p>通过上面的讲解你可以知道，CART 分类树实际上是基于基尼系数来做属性划分的。在 Python 的 sklearn 中，如果我们想要创建 CART 分类树，可以直接使用 DecisionTreeClassifier 这个类。创建这个类的时候，默认情况下 criterion 这个参数等于 gini，也就是按照基尼系数来选择属性划分，即默认采用的是 CART 分类树。</p><p>下面，我们来用 CART 分类树，给 iris 数据集构造一棵分类决策树。iris 这个数据集，我在 Python 可视化中讲到过，实际上在 sklearn 中也自带了这个数据集。基于 iris 数据集，构造 CART 分类树的代码如下：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># encoding=utf-8</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.model_selection import train_test_split</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.metrics import accuracy_score</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.tree import DecisionTreeClassifier</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.datasets import load_iris</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 准备数据集</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">iris=load_iris()</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 获取特征集和分类标识</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">features = iris.data</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">labels = iris.target</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 随机抽取 33% 的数据作为测试集，其余为训练集</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=0)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 创建 CART 分类树</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">clf = DecisionTreeClassifier(criterion='gini')</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 拟合构造 CART 分类树</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">clf = clf.fit(train_features, train_labels)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 用 CART 分类树做预测</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">test_predict = clf.predict(test_features)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 预测结果与测试集结果作比对</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">score = accuracy_score(test_labels, test_predict)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">print("CART 分类树准确率 %.4lf" % score)</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>运行结果：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">CART 分类树准确率 0.9600</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>如果我们把决策树画出来，可以得到下面的图示：</p><p><img src="https://static001.geekbang.org/resource/image/c1/40/c1e2f9e4a299789bb6cc23afc6fd3140.png"  alt=""><br>
首先 train_test_split 可以帮助我们把数据集抽取一部分作为测试集，这样我们就可以得到训练集和测试集。</p><p>使用 clf = DecisionTreeClassifier(criterion=‘gini’) 初始化一棵 CART 分类树。这样你就可以对 CART 分类树进行训练。</p><p>使用 clf.fit(train_features, train_labels) 函数，将训练集的特征值和分类标识作为参数进行拟合，得到 CART 分类树。</p><p>使用 clf.predict(test_features) 函数进行预测，传入测试集的特征值，可以得到测试结果 test_predict。</p><p>最后使用 accuracy_score(test_labels, test_predict) 函数，传入测试集的预测结果与实际的结果作为参数，得到准确率 score。</p><p>我们能看到 sklearn 帮我们做了 CART 分类树的使用封装，使用起来还是很方便的。</p><p><strong>CART 回归树的工作流程</strong></p><p>CART 回归树划分数据集的过程和分类树的过程是一样的，只是回归树得到的预测结果是连续值，而且评判“不纯度”的指标不同。在 CART 分类树中采用的是基尼系数作为标准，那么在 CART 回归树中，如何评价“不纯度”呢？实际上我们要根据样本的混乱程度，也就是样本的离散程度来评价“不纯度”。</p><p>样本的离散程度具体的计算方式是，先计算所有样本的均值，然后计算每个样本值到均值的差值。我们假设 x 为样本的个体，均值为 u。为了统计样本的离散程度，我们可以取差值的绝对值，或者方差。</p><p>其中差值的绝对值为样本值减去样本均值的绝对值：</p><p><img src="https://static001.geekbang.org/resource/image/6f/97/6f9677a70b1edff85e9e467f3e52bd97.png"  alt=""><br>
方差为每个样本值减去样本均值的平方和除以样本个数：</p><p><img src="https://static001.geekbang.org/resource/image/04/c1/045fd5afb7b53f17a8accd6f337f63c1.png"  alt=""><br>
所以这两种节点划分的标准，分别对应着两种目标函数最优化的标准，即用最小绝对偏差（LAD），或者使用最小二乘偏差（LSD）。这两种方式都可以让我们找到节点划分的方法，通常使用最小二乘偏差的情况更常见一些。</p><p>我们可以通过一个例子来看下如何创建一棵 CART 回归树来做预测。</p><h2>如何使用 CART 回归树做预测</h2><p>这里我们使用到 sklearn 自带的波士顿房价数据集，该数据集给出了影响房价的一些指标，比如犯罪率，房产税等，最后给出了房价。</p><p>根据这些指标，我们使用 CART 回归树对波士顿房价进行预测，代码如下：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># encoding=utf-8</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.metrics import mean_squared_error</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.model_selection import train_test_split</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.datasets import load_boston</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">from sklearn.tree import DecisionTreeRegressor</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 准备数据集</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">boston=load_boston()</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 探索数据</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">print(boston.feature_names)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 获取特征集和房价</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">features = boston.data</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">prices = boston.target</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 随机抽取 33% 的数据作为测试集，其余为训练集</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">train_features, test_features, train_price, test_price = train_test_split(features, prices, test_size=0.33)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 创建 CART 回归树</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">dtr=DecisionTreeRegressor()</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 拟合构造 CART 回归树</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">dtr.fit(train_features, train_price)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 预测测试集中的房价</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">predict_price = dtr.predict(test_features)</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line"># 测试集的结果评价</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">print('回归树二乘偏差均值:', mean_squared_error(test_price, predict_price))</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">print('回归树绝对值偏差均值:', mean_absolute_error(test_price, predict_price)) </div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>运行结果（每次运行结果可能会有不同）：</p><pre style="position: relative;"><code><table class="hljs-ln"><tbody><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO' 'B' 'LSTAT']</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">回归树二乘偏差均值: 23.80784431137724</div></td></tr><tr><td class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></td><td class="hljs-ln-code"><div class="hljs-ln-line">回归树绝对值偏差均值: 3.040119760479042</div></td></tr></tbody></table></code><div class="richcontent-pre-copy"><span class="iconfont"></span>复制代码</div></pre><p>如果把回归树画出来，可以得到下面的图示（波士顿房价数据集的指标有些多，所以树比较大）：</p><p><img src="https://static001.geekbang.org/resource/image/65/61/65a3855aed648b32994b808296a40b61.png"  alt=""></p><p>你可以在<a href="https://pan.baidu.com/s/1RKD6-IwAzL--cL0jt4GPiQ">这里</a>下载完整 PDF 文件。</p><p>我们来看下这个例子，首先加载了波士顿房价数据集，得到特征集和房价。然后通过 train_test_split 帮助我们把数据集抽取一部分作为测试集，其余作为训练集。</p><p>使用 dtr=DecisionTreeRegressor() 初始化一棵 CART 回归树。</p><p>使用 dtr.fit(train_features, train_price) 函数，将训练集的特征值和结果作为参数进行拟合，得到 CART 回归树。</p><p>使用 dtr.predict(test_features) 函数进行预测，传入测试集的特征值，可以得到预测结果 predict_price。</p><p>最后我们可以求得这棵回归树的二乘偏差均值，以及绝对值偏差均值。</p><p>我们能看到 CART 回归树的使用和分类树类似，只是最后求得的预测值是个连续值。</p><h2>CART 决策树的剪枝</h2><p>CART 决策树的剪枝主要采用的是 CCP 方法，它是一种后剪枝的方法，英文全称叫做 cost-complexity prune，中文叫做代价复杂度。这种剪枝方式用到一个指标叫做节点的表面误差率增益值，以此作为剪枝前后误差的定义。用公式表示则是：</p><p><img src="https://static001.geekbang.org/resource/image/6b/95/6b9735123d45e58f0b0afc7c3f68cd95.png"  alt=""><br>
其中 Tt 代表以 t 为根节点的子树，C(Tt) 表示节点 t 的子树没被裁剪时子树 Tt 的误差，C(t) 表示节点 t 的子树被剪枝后节点 t 的误差，|Tt|代子树 Tt 的叶子数，剪枝后，T 的叶子数减少了|Tt|-1。</p><p>所以节点的表面误差率增益值等于节点 t 的子树被剪枝后的误差变化除以剪掉的叶子数量。</p><p>因为我们希望剪枝前后误差最小，所以我们要寻找的就是最小α值对应的节点，把它剪掉。这时候生成了第一个子树。重复上面的过程，继续剪枝，直到最后只剩下根节点，即为最后一个子树。</p><p>得到了剪枝后的子树集合后，我们需要用验证集对所有子树的误差计算一遍。可以通过计算每个子树的基尼指数或者平方误差，取误差最小的那个树，得到我们想要的结果。</p><h2>总结</h2><p>今天我给你讲了 CART 决策树，它是一棵决策二叉树，既可以做分类树，也可以做回归树。你需要记住的是，作为分类树，CART 采用基尼系数作为节点划分的依据，得到的是离散的结果，也就是分类结果；作为回归树，CART 可以采用最小绝对偏差（LAD），或者最小二乘偏差（LSD）作为节点划分的依据，得到的是连续值，即回归预测结果。</p><p>最后我们来整理下三种决策树之间在属性选择标准上的差异：</p><ul>
<li>
<p>ID3 算法，基于信息增益做判断；</p>
</li>
<li>
<p>C4.5 算法，基于信息增益率做判断；</p>
</li>
<li>
<p>CART 算法，分类树是基于基尼系数做判断。回归树是基于偏差做判断。</p>
</li>
</ul><p>实际上这三个指标也是计算“不纯度”的三种计算方式。</p><p>在工具使用上，我们可以使用 sklearn 中的 DecisionTreeClassifier 创建 CART 分类树，通过 DecisionTreeRegressor 创建 CART 回归树。</p><p>你可以用代码自己跑一遍我在文稿中举到的例子。</p><p><img src="https://static001.geekbang.org/resource/image/5c/84/5cfe1151f88befc1178eca3252890f84.png"  alt=""><br>
最后给你留两道思考题吧，你能说下 ID3，C4.5，以及 CART 分类树在做节点划分时的区别吗？第二个问题是，sklearn 中有个手写数字数据集，调用的方法是 load_digits()，你能否创建一个 CART 分类树，对手写数字数据集做分类？另外选取一部分测试集，统计下分类树的准确率？</p><p>欢迎你在评论下面留言，与我分享你的答案。也欢迎点击“请朋友读”，把这篇文章分享给你的朋友或者同事，一起交流。</p><p><img src="https://static001.geekbang.org/resource/image/48/96/48cb89aa8c4858bbc18df3b3ac414496.jpg"  alt=""></p></div></div> <!----> <div class="_22WJb59B_0">
        </div></div> <div class="_2DmyW7ex_0 _2QmGFWqF_0"><div class="_1M5b-cvc_0"><div class="_3l55W_ak_0">上一篇</div> <div class="_3Ov-zF0e_0">17 丨决策树（上）：要不要去打篮球？决策树来告诉你</div></div> <div class="_1M5b-cvc_0"><div class="_3l55W_ak_0">下一篇</div> <div class="_3Ov-zF0e_0">19丨决策树（下）：泰坦尼克乘客生存预测</div></div></div> <div class="_1qhD3bdE_0 _2QmGFWqF_0"><div class="iconfont _2-nZIZjB_0"> 写留言</div> <h2><span>精选留言</span><span class="_2FC_cD1O_0">(25)</span></h2> <ul><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/14/a7/f0/e3212f18.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>胡</span> <!----></div> <div class="_1H1Z49Dr_0">2019-01-31</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">13</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">cart分类树的决策树那副图看不懂。</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>王彬成</span> <!----></div> <div class="_1H1Z49Dr_0">2019-02-17</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">7</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">1、ID3，C4.5，以及 CART 分类树在做节点划分时的区别吗？<br>ID3是基于信息增益来判断，信息增益最大的，选取作为根节点。<br>C4.5采用信息增益率来判断，信息增益率最大的，选取作为根节点。<br>CART分类树采用基尼系数最小的属性作为属性划分<br>2、sklearn 中有个手写数字数据集，调用的方法是 load_digits()，你能否创建一个 CART 分类树，对手写数字数据集做分类？另外选取一部分测试集，统计下分类树的准确率？<br># 手写数据集load_digits()建立CART分类树<br># encoding= utf-8<br>from sklearn.model_selection import train_test_split<br>from sklearn.metrics import accuracy_score<br>from sklearn.tree import DecisionTreeClassifier<br>from sklearn.datasets import load_digits<br><br>#准备数据<br>digits=load_digits()<br>#获取特征集和分类标识<br>features=digits.data<br>labels=digits.target<br>#随机抽取33%的数据作为测试集，其余为训练集<br>train_features,test_features,train_labels,test_labels=train_test_split(features,labels,test_size=0.33,random_state=0)<br>#创建cart分类树<br>clf=DecisionTreeClassifier(criterion='gini')<br>#拟合构造cart分类树<br>clf=clf.fit(train_features,train_labels)<br># 用cart分类树做预测<br>test_predict=clf.predict(test_features)<br>#预测结果与测试集结果做比对<br>score=accuracy_score(test_labels,test_predict)<br>print("CART 分类树准确率 %.4lf"%score)<br>-----------<br>运算结果：CART 分类树准确率 0.8603</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/11/77/be/1f2409e8.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>梁林松</span> <!----></div> <div class="_1H1Z49Dr_0">2019-01-23</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">4</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0 _3D2NkqD6_0">老师 那个打篮球的例子里 D1/D和D2/D为什么是6/9和2/9呢？如果是子节点占父节点的比例不是应该是各1/2吗？</div> <!----> <!----></div></li><li class="reJj6Thl_0"><img  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>jake</span> <!----></div> <div class="_1H1Z49Dr_0">2019-02-24</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">3</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0"><br>首先想问一个问题 就是在讲到基尼系数那里 有一个图那里的例子 什么D: 9个打篮球 3个不打篮球那里<br>那里的D的基尼系数用到了子节点归一化基尼系数之和这个方法求 请问D的基尼系数不能直接用 上面那个公式 也就是"1 - [p(ck|t)]^2"那个公式计算吗 我用这个公式计算出D的基尼系数为 1 - (9/12 * 9/12 + 3/12 * 3/12) = 6/16。 我也想问一下上面那个同学提的这个问题</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/11/3c/4c/cd7c8019.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>make some...</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-01</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">2</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">老师你好，决策的数是怎么生成的？</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/14/0a/eb/6d6a94d2.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>Lee</span> <!----></div> <div class="_1H1Z49Dr_0">2019-01-24</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">2</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0"># encoding=utf-8<br>from sklearn.model_selection import train_test_split<br>from sklearn.metrics import accuracy_score<br>from sklearn.tree import DecisionTreeClassifier<br>from sklearn.datasets import load_digits<br><br># 准备数据集<br>digits=load_digits()<br># 获取特征集和分类标识<br>features = digits.data<br>labels = digits.target<br># 随机抽取 33% 的数据作为测试集，其余为训练集<br>train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=0)<br># 创建 CART 分类树<br>clf = DecisionTreeClassifier(criterion='gini')<br># 拟合构造 CART 分类树<br>clf = clf.fit(train_features, train_labels)<br># 用 CART 分类树做预测<br>test_predict = clf.predict(test_features)<br># 预测结果与测试集结果作比对<br>score = accuracy_score(test_labels, test_predict)<br>print("CART 分类树准确率 %.4lf" % score)<br><br>CART 分类树准确率 0.8620</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erBSoNm28CNCYpvytDbhfSYpgCo6T9vuzKkSoflr3sX8VucMz8ykrichKDY9vVoMVomUIakXSQq9icw/132" src="" class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>xfoolin</span> <!----></div> <div class="_1H1Z49Dr_0">2019-02-19</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">1</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">ID3 是通过信息增益，选取信息增益最大的特征；C4.5 是通过信息增益率，选取，CART 是通过基尼系数，选取基尼系数最小的特征。<br><br><br>from sklearn.model_selection import train_test_split#训练集和测试集<br>from sklearn.metrics import mean_squared_error#二乘偏差均值<br>from sklearn.metrics import mean_absolute_error#绝对值偏差均值<br>from sklearn.datasets import load_digits#引入 digits 数据集<br>from sklearn.metrics import accuracy_score#测试结果的准确性<br>from sklearn import tree<br>import graphviz<br>#准备数据集<br>digits = load_digits()<br>#获取数据集的特征集和分类标识<br>features = digits.data<br>labels = digits.target<br>#随机抽取 33% 的数据作为测试集，其余为训练集<br>train_features,test_features,train_labels,test_labels = \<br>train_test_split(features,labels,test_size = 0.33,random_state = 0)<br>#创建 CART 分类树<br>clf = tree.DecisionTreeClassifier(criterion = 'gini')<br>#拟合构造分类树<br>clf = clf.fit(train_features,train_labels)<br>#用 CART 分类树做预测<br>test_predict = clf.predict(test_features)<br>#预测结果与测试集作对比<br>score = accuracy_score(test_labels,test_predict)<br>#输出准确率<br>print('准确率 %.4f'%score)<br>dot_data = tree.export_graphviz(clf,out_file = None)<br>graph = graphviz.Source(dot_data)<br>#输出分类树图示<br>graph.view()<br></div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/13/2f/e2/58ae492c.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>小熊猫</span> <!----></div> <div class="_1H1Z49Dr_0">2019-02-15</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">1</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">ID3：以信息增益作为判断标准，计算每个特征的信息增益，选取信息增益最大的特征，但是容易选取到取值较多的特征<br>C4.5：以信息增益比作为判断标准，计算每个特征的信息增益比，选取信息增益比最大的特征<br>CART：分类树以基尼系数为标准，选取基尼系数小的的特征<br>            回归树以均方误差或绝对值误差为标准，选取均方误差或绝对值误差最小的特征<br><br>练习题：<br>from sklearn import datasets<br>from sklearn.model_selection import train_test_split<br>from sklearn import tree<br>from sklearn.metrics import accuracy_score<br>import graphviz <br><br># 准备手写数字数据集<br>digits = datasets.load_digits()<br># 获取特征和标识<br>features = digits.data<br>labels = digits.target<br># 选取数据集的33%为测试集，其余为训练集<br>train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.33)<br># 创建CART分类树<br>clf = tree.DecisionTreeClassifier()<br># 拟合构造CART分类树<br>clf.fit(train_features, train_labels)<br># 预测测试集结果<br>test_predict = clf.predict(test_features)<br># 测试集结果评价<br>print('CART分类树准确率:', accuracy_score(test_labels, test_predict))<br># 画决策树<br>dot_data = tree.export_graphviz(clf, out_file=None)<br>graph = graphviz.Source(dot_data)<br>graph.render('CART//CART_practice_digits')<br><br>CART分类树准确率: 0.8636363636363636</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/13/8c/3d/77b9abbb.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>rainman</span> <!----></div> <div class="_1H1Z49Dr_0">2019-02-15</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">1</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">对于 CART 回归树的可视化，可以先在电脑上安装 graphviz；然后 pip install graphviz，这是安装python的库，需要依赖前面安装的 graphviz。可视化代码如下：<br><br>----<br>from sklearn.tree import export_graphviz<br>import graphviz<br><br># 参数是回归树模型名称，不输出文件。<br>dot_data = export_graphviz(dtr, out_file=None)<br>graph = graphviz.Source(dot_data)<br># render 方法会在同级目录下生成 Boston PDF文件，内容就是回归树。<br>graph.render('Boston')<br>----<br><br>具体内容可以去 sklearn(https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html)<br>和 graphviz(https://graphviz.readthedocs.io/en/stable/) 看看。</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/14/8e/6d/c68e07ef.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>Chino</span> <!----></div> <div class="_1H1Z49Dr_0">2019-02-01</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">1</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">首先想问一个问题 就是在讲到基尼系数那里 有一个图那里的例子 什么D: 9个打篮球 3个不打篮球那里<br>那里的D的基尼系数用到了子节点归一化基尼系数之和这个方法求 请问D的基尼系数不能直接用 上面那个公式 也就是"1 - [p(ck|t)]^2"那个公式计算吗  我用这个公式计算出D的基尼系数为 1 - (9/12 * 9/12 + 3/12 * 3/12) = 6/16<br><br># ID3,C4.5,CART在做节点划分的区别<br># 我认为是三者的共同之处就是得出每个类别的某个属性值 然后根据这个属性值<br># 来选取哪个类型当节点 因此不同之处就是这个属性值.<br># ID3 根据 信息增益 判断 哪个节点的信息增益最大就当节点<br># C4.5 根据 信息增益率 判断 跟ID3相似<br># CART分类树 根据 基尼系数 判断 越小代表越稳定<br><br>from sklearn.datasets import load_digits<br>from sklearn.tree import DecisionTreeClassifier<br>from sklearn.metrics import accuracy_score<br>from sklearn.model_selection import train_test_split<br><br><br>digit = load_digits()<br><br># 把数据集中的数据和结果拿出来<br>features = digit.data<br>target = digit.target<br><br># 把数据集中的数据分33%当作测试数据 其他用来训练<br>train_features,test_features,train_target,test_target = train_test_split(features,target,test_size=0.33)<br><br># 定义CART分类树<br>clf = DecisionTreeClassifier()<br><br># 把训练数据弄到分类数中 构造树<br>clf = clf.fit(train_features,train_target)<br><br># 把测试数据放进树中得出预测结果<br>predict_target = clf.predict(test_features)<br><br># 对比预测出来的数据和实际结果<br>score = accuracy_score(predict_target,test_target)<br><br>print(score)<br><br></div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/13/03/3f/09308258.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>雨先生的晴...</span> <!----></div> <div class="_1H1Z49Dr_0">2019-01-27</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class="">1</span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0 _3D2NkqD6_0">scikit learn package 确实非常好用，很简洁。推荐大家也去官网看一看，请问一下怎样可以把decision tree 可视化呀？ </div> <!----> <!----></div></li><li class="reJj6Thl_0"><img  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>羊小看</span> <!----></div> <div class="_1H1Z49Dr_0">2019-05-10</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">1、为什么CRAT的基尼系数比C4.5的信息增益率好呢？既然sklearn库默认用的基尼系数，应该是这个好一些吧？<br>2、from sklearn.model_selection import train_test_split<br>from sklearn.metrics import accuracy_score<br>from sklearn.tree import DecisionTreeClassifier<br>#from sklearn.datasets import load_iris<br>from sklearn.datasets import load_digits<br><br># 准备数据集<br>#iris=load_iris()<br>digits=load_digits()<br># 获取特征集和分类标识<br>#features = iris.data<br>#labels = iris.target<br>features = digits.data<br>labels = digits.target<br># 随机抽取 33% 的数据作为测试集，其余为训练集<br>train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=0)<br># 创建 CART 分类树<br>clf = DecisionTreeClassifier(criterion='gini')<br># 拟合构造 CART 分类树<br>clf = clf.fit(train_features, train_labels)<br># 用 CART 分类树做预测<br>test_predict = clf.predict(test_features)<br># 预测结果与测试集结果作比对<br>score = accuracy_score(test_labels, test_predict)<br>print("CART 分类树准确率 %.4lf" % score)<br><br>CART 分类树准确率 0.8636</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/10/8e/76/6d55e26f.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>张晓辉</span> <!----></div> <div class="_1H1Z49Dr_0">2019-05-09</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">#encoding=utf-8<br>from sklearn.datasets import load_digits<br>from sklearn.tree import DecisionTreeClassifier<br>from sklearn.metrics import accuracy_score<br>from sklearn.model_selection import train_test_split<br><br>digits = load_digits()<br>features = digits.data <br>targets = digits.target <br>train_features, test_features, train_digits, test_digits = train_test_split(features, targets, test_size = 0.33)<br>clf = DecisionTreeClassifier()<br>clf = clf.fit(train_features, train_digits)<br>predict_digits = clf.predict(test_features)<br>print("The predict accuracy is:", accuracy_score(test_digits, predict_digits))</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/12/a3/87/0cb915e2.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>滢</span> <!----></div> <div class="_1H1Z49Dr_0">2019-04-17</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">语言版本：Python 3.6 环境：IDLE<br><br>&gt;&gt;&gt;from sklearn.model_selection import train_test_split<br>&gt;&gt;&gt;from sklearn.metrics import accuracy_score<br>&gt;&gt;&gt;from sklearn.tree import DecisionTreeClassifier<br>&gt;&gt;&gt;from sklearn.datasets import load_digits<br>&gt;&gt;&gt;import ssl<br>&gt;&gt;&gt;ssl._create_default_https_context = ssl._create_unverified_context<br>&gt;&gt;&gt;#准备数据<br>&gt;&gt;&gt;digits = load_gigits()<br>&gt;&gt;&gt;#获取特征集和分类标识<br>&gt;&gt;&gt;features = digits.data<br>&gt;&gt;&gt;labels = digits.target<br>&gt;&gt;&gt; #随机抽取40%作为测试数据，其余作为训练集<br>&gt;&gt;&gt;train_features,test_features,train_labels,test_labels = train_test_split(features,labels, test_size = 0.40, random_state = 0)<br>&gt;&gt;&gt;#创建CART分类树<br>&gt;&gt;&gt;clf = DecisionTreeClassifier(criterion='gini')<br>&gt;&gt;&gt;#拟合构建CART分类树<br>&gt;&gt;&gt;clf.fit(train_features, train_labels)<br>&gt;&gt;&gt;#用CART分类树做预测<br>&gt;&gt;&gt;test_predic = clf.predict(test_features)<br>&gt;&gt;&gt;#预测结果与测试结果做比对<br>&gt;&gt;&gt;score = accuracy_score(test_labels, test_predic)<br>&gt;&gt;&gt;print ('CART分类树准确率%.4lf', %score)<br>CART分类树准确率0.8164</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/12/f9/38/faec874e.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>郑志宾</span> <!----></div> <div class="_1H1Z49Dr_0">2019-04-07</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">CART 剪枝算法中，是将剪掉的子树组成子树序列，然后进行测试？<br>还是将剪去后剩下的子树组成子树序列进行测试呢？<br><br>还有最后取得的误差最小的那个子树为什么是我们想要的结果？<br>剪枝后的决策树不是我们想要的吗？为什么还要测试子树序列？<br><br></div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/11/8e/0a/31ec5392.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>挠头侠</span> <!----></div> <div class="_1H1Z49Dr_0">2019-04-05</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">老师 能不能分析一下决策数图里面的内容分别是什么和如何算出来的呀。</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/14/72/cb/5d58f190.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>Linus</span> <!----></div> <div class="_1H1Z49Dr_0">2019-03-06</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">X[2] &lt;= 5.415<br>mse = 0.955<br>samples = 27<br>value = 23.785<br>老师能不能解释一下x[2]&lt;=5.415 是不是过滤了小于5.415的数字 再进行算gini系数</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/12/f9/81/8b190e97.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>littlePerf...</span> <!----></div> <div class="_1H1Z49Dr_0">2019-02-21</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0 _3D2NkqD6_0">探索数据那一行代码有什么作用?<br>print(boston.feature_names)</div> <!----> <!----></div></li><li class="reJj6Thl_0"><img  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>柚子</span> <!----></div> <div class="_1H1Z49Dr_0">2019-02-15</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">from sklearn.model_selection import train_test_split<br>from sklearn.datasets import load_digits<br>from sklearn.tree import DecisionTreeClassifier<br>from sklearn.metrics import accuracy_score<br><br>digits = load_digits()     #准备数据集<br>features = digits.data   #获取特征值<br>labels = digits.target    #获取分类类别<br><br>train_features,test_features,train_labels,test_labels = train_test_split(features,labels,test_size = 0.33,random_state = 0)     #随机抽取33%作为测试集<br><br>dig = DecisionTreeClassifier(criterion='gini')            #创建决策树<br>dig.fit(train_features,train_labels)                             #拟合构造决策树<br>test_predict = dig.predict(test_features)                  #预测<br>score = accuracy_score(test_labels,test_predict)      #测试集结果评价<br>print('决策树准确率：%.4lf'% score)</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li><li class="reJj6Thl_0"><img src="https://static001.geekbang.org/account/avatar/00/14/c7/a3/1e2f9f5a.jpg"  class="_2273kGdT_0"> <div class="_2CG0SquK_0"><div class="_304R4gla_0"><div><div class="_18Dng5rT_0"><span>圆圆的大食...</span> <!----></div> <div class="_1H1Z49Dr_0">2019-02-02</div></div> <div class="_2eMTs2JE_0"><div class="_2P4B1Hdm_0"><i class="iconfont"></i> <span class=""></span></div> <!----> <!----></div></div> <div class="_3M6kV3zb_0">from sklearn.model_selection import train_test_split<br>from sklearn.metrics import accuracy_score<br>from sklearn.tree import DecisionTreeClassifier<br>from sklearn.datasets import load_digits<br>#准备数据集<br>digits=load_digits()<br>#获取特征集和分类标识<br>features = digits.data<br>labels = digits.target<br>#随机抽取33%的数据作为测试集，其余为训练集<br>train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=0)<br>#创建CART分类树<br>clf = DecisionTreeClassifier(criterion='gini')<br>#拟合构造CART分类树<br>clf = clf.fit(train_features, train_labels)<br>#用CART分类树做预测<br>test_predict = clf.predict(test_features)<br>#预测结果与测试集结果作对比 <br>score = accuracy_score(test_labels, test_predict)<br>print ("CART分类树准确率%.4lf"% score)</div> <div class="_2r3UB1GX_0"><span>展开</span><i class="iconfont"></i></div> <!----></div></li></ul></div></div> <!----></div> <!----></div></div> </div><!----></body></html>